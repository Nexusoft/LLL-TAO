/*
 * Falcon key pair generation.
 *
 * ==========================(LICENSE BEGIN)============================
 *
 * Copyright (c) 2017  Falcon Project
 *
 * Permission is hereby granted, free of charge, to any person obtaining
 * a copy of this software and associated documentation files (the
 * "Software"), to deal in the Software without restriction, including
 * without limitation the rights to use, copy, modify, merge, publish,
 * distribute, sublicense, and/or sell copies of the Software, and to
 * permit persons to whom the Software is furnished to do so, subject to
 * the following conditions:
 *
 * The above copyright notice and this permission notice shall be
 * included in all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
 * IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
 * CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
 * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
 * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 *
 * ===========================(LICENSE END)=============================
 *
 * @author   Thomas Pornin <thomas.pornin@nccgroup.trust>
 */

#include <stddef.h>
#include "internal.h"

/*
 * If CLEANSE is non-zero, then temporary areas obtained with malloc()
 * and used to contain secret values are explicitly cleared before
 * deallocation with free(). This is the default behaviour; use
 * -DCLEANSE=0 to disable cleansing.
 */
#ifndef CLEANSE
#define CLEANSE   1
#endif

/*
 * If MEMCHECK is non-zero, then a few extra bytes will be allocated
 * at the end of the main buffer, and filled with a specific pattern
 * which is checked upon exit. This implies a dependency to some extra
 * libc facilities (stderr, fprintf, abort). Overflows may occur only
 * if the computation in temp_size() is wrong.
 */
#ifndef MEMCHECK
#define MEMCHECK   1
#endif

#if MEMCHECK
#include <stdio.h>
#include <stdlib.h>
#endif

#define MKN(logn, full)   ((size_t)(1 + ((full) << 1)) << ((logn) - (full)))

#if CLEANSE
/*
 * Cleanse a memory region by overwriting it with zeros.
 */
static void
cleanse(void *data, size_t len)
{
	volatile unsigned char *p;

	p = (volatile unsigned char *)data;
	while (len -- > 0) {
		*p ++ = 0;
	}
}
#endif

/* ==================================================================== */
/*
 * Compute resultant of polynomial f with phi, modulo 2. This function
 * is for phi = X^N-X(N/2)+1, where N = 1.5*2^logn.
 */
static unsigned
mod2_res_ternary(const int16_t *f, unsigned logn)
{
	/*
	 * We lower down the degree to 6, by successive degree halving:
	 * we replace f with N(f). If:
	 *   f = f0(x^2) + x*f1(x^2)
	 * with f0 and f1 taken modulo X^(N/2)-(X^N/4)+1, then:
	 *   N(f) = f0^2 - x*f1^2
	 *
	 * From f expressed as an array of bits:
	 *   - f0 and f1 are obtained by extracting bits at even and
	 *     odd indexes, respectively;
	 *   - the "holes" are squeezed out to get down to degree N/2;
	 *   - squarings (f0^2 and f1^2) compute the exact opposite of
	 *     that "squeezing out", so in practice we skip both; but
	 *     we must reduce modulo X^(N/2)-X^(N/4)+1.
	 */

	uint32_t b[24];
	size_t u, n;

	/*
	 * Extract bits into an array of 32-bit words.
	 */
	n = MKN(logn, 1);
	memset(b, 0, sizeof b);
	for (u = 0; u < n; u ++) {
		uint32_t bit;

		bit = (uint32_t)f[u] & 1;
		b[u >> 5] |= bit << (u & 31);
	}

	/*
	 * Halve the degree repeatedly.
	 *
	 * If the input is: a0 || a1 || a2 || a3
	 * Then we must compute: (a0 XOR a2 XOR a3) || (a1 XOR a2)
	 */
	switch (logn) {
	case 9:
		/*
		 * a0 = b[0..5]
		 * a1 = b[6..11]
		 * a2 = b[12..17]
		 * a3 = b[18..23]
		 */
		b[0] ^= b[12] ^ b[18];
		b[1] ^= b[13] ^ b[19];
		b[2] ^= b[14] ^ b[20];
		b[3] ^= b[15] ^ b[21];
		b[4] ^= b[16] ^ b[22];
		b[5] ^= b[17] ^ b[23];
		b[6] ^= b[12];
		b[7] ^= b[13];
		b[8] ^= b[14];
		b[9] ^= b[15];
		b[10] ^= b[16];
		b[11] ^= b[17];
		/* fall through */
	case 8:
		/*
		 * a0 = b[0..2]
		 * a1 = b[3..5]
		 * a2 = b[6..8]
		 * a3 = b[9..11]
		 */
		b[0] ^= b[6] ^ b[9];
		b[1] ^= b[7] ^ b[10];
		b[2] ^= b[8] ^ b[11];
		b[3] ^= b[6];
		b[4] ^= b[7];
		b[5] ^= b[8];
		/* fall through */
	case 7:
		/*
		 * a0 = b[0] || b[1](0..15)
		 * a1 = b[1](16..31) || b[2]
		 * a2 = b[3] || b[4](0..15)
		 * a3 = b[4](16..31) || b[5]
		 */
		b[0] ^= b[3] ^ (b[4] >> 16) ^ (b[5] << 16);
		b[1] ^= (b[4] & 0xFFFF) ^ (b[5] >> 16);
		b[1] ^= (b[3] << 16);
		b[2] ^= (b[3] >> 16) ^ (b[4] << 16);
		/* fall through */
	case 6:
		/*
		 * a0 = b[0](0..23)
		 * a1 = b[0](24..31) || b[1](0..15)
		 * a2 = b[1](16..31) || b[2](0..7)
		 * a3 = b[2](8..31)
		 */
		b[0] ^= (b[1] >> 16) ^ ((b[2] & 0xFF) << 16) ^ (b[2] >> 8);
		b[0] ^= ((b[1] << 8) & 0xFF000000);
		b[1] ^= (b[1] >> 24) ^ ((b[2] & 0xFF) << 8);
		b[1] &= 0xFFFF;
		/* fall through */
	case 5:
		/*
		 * a0 = b[0](0..11)
		 * a1 = b[0](12..23)
		 * a2 = b[0](24..31) || b[1](0..3)
		 * a3 = b[1](4..15)
		 */
		b[0] ^= (b[0] >> 24) ^ ((b[1] & 0x0F) << 8) ^ (b[1] >> 4);
		b[0] ^= ((b[0] >> 12) & 0xFF000) ^ ((b[1] & 0x0F) << 20);
		b[0] &= 0xFFFFFF;
		/* fall through */
	case 4:
		/*
		 * a0 = b[0](0..5)
		 * a1 = b[0](6..11)
		 * a2 = b[0](12..17)
		 * a3 = b[0](18..23)
		 */
		b[0] ^= ((b[0] >> 12) & 0x3F) ^ ((b[0] >> 18) & 0x3F);
		b[0] ^= ((b[0] >> 6) & 0xFC0);
		b[0] &= 0xFFF;
		/* fall through */
	case 3:
		/*
		 * a0 = b[0](0..2)
		 * a1 = b[0](3..5)
		 * a2 = b[0](6..8)
		 * a3 = b[0](9..11)
		 */
		b[0] ^= ((b[0] >> 6) & 0x7) ^ ((b[0] >> 9) & 0x7);
		b[0] ^= ((b[0] >> 3) & 0x38);
		b[0] &= 0x3F;
		/* fall through */
	case 2:
		break;
	}

	/*
	 * When we are done to phi = X^6-X^3+1, we have only 64
	 * possibilities. It turns out that all of them except 0 yield
	 * a resultant of value 1 with phi (modulo 2).
	 */
	return b[0] != 0;
}

/* ==================================================================== */
/*
 * Modular arithmetics.
 *
 * We implement a few functions for computing modulo a small integer p.
 *
 * All functions require that 2^30 < p < 2^31. Moreover, operands must
 * be in the 0..p-1 range.
 *
 * Modular addition and subtraction work for all such p.
 *
 * Montgomery multiplication requires that p is odd, and must be provided
 * with an additional value p0i = -1/p mod 2^31. See below for some basics
 * on Montgomery multiplication.
 *
 * Division computes an inverse modulo p by an exponentiation (with
 * exponent p-2): this works only if p is prime. Multiplication
 * requirements also apply, i.e. p must be odd and p0i must be provided.
 *
 * The NTT and inverse NTT need all of the above, and also that
 * p = 1 mod 2048 (binary case) or p = 1 mod 2304 (ternary case).
 *
 * -----------------------------------------------------------------------
 *
 * We use Montgomery representation with 31-bit values:
 *
 *   Let R = 2^31 mod p. When p > 2^30, R = 2^31 - p.
 *   Montgomery representation of an integer x modulo p is x*R mod p.
 *
 *   Montgomery multiplication computes (x*y)/R mod p for
 *   operands x and y. Therefore:
 *
 *    - if operands are x*R and y*R (Montgomery representations of x and y),
 *      then Montgomery multiplication computes (x*R*y*R)/R = (x*y)*R mod p,
 *      which is the Montgomery representation of the product x*y;
 *
 *    - if operands are x*R and y (or x and y*R), then Montgomery
 *      representation returns x*y mod p: mixed-representation
 *      multiplications yield results in normal representation.
 *
 * To convert to Montgomery representation, we multiply by R, which is done
 * by Montgomery-multiplying by R^2. Stand-alone conversion back from
 * Montgomery representation is Montgomery-multiplication by 1.
 */

/*
 * Precomputed small primes. Each element contains the following:
 *
 *  p   The prime itself.
 *
 *  g   A primitive root of phi = X^N+1 or phi = X^N-X^(N/2)+1.
 *
 *  s   The inverse of the product of all previous primes in the array,
 *      computed modulo p and in Montgomery representation.
 *
 * All primes are such that p = 1 mod 2048, and are lower than 2^31. They
 * are listed in decreasing order.
 */

typedef struct {
	uint32_t p;
	uint32_t g;
	uint32_t s;
} small_prime;

static const small_prime PRIMES2[] = {
	{ 2147473409,  383167813,      10239 },
	{ 2147389441,  211808905,  471403745 },
	{ 2147387393,   37672282, 1329335065 },
	{ 2147377153, 1977035326,  968223422 },
	{ 2147358721, 1067163706,  132460015 },
	{ 2147352577, 1606082042,  598693809 },
	{ 2147346433, 2033915641, 1056257184 },
	{ 2147338241, 1653770625,  421286710 },
	{ 2147309569,  631200819, 1111201074 },
	{ 2147297281, 2038364663, 1042003613 },
	{ 2147295233, 1962540515,   19440033 },
	{ 2147239937, 2100082663,  353296760 },
	{ 2147235841, 1991153006, 1703918027 },
	{ 2147217409,  516405114, 1258919613 },
	{ 2147205121,  409347988, 1089726929 },
	{ 2147196929,  927788991, 1946238668 },
	{ 2147178497, 1136922411, 1347028164 },
	{ 2147100673,  868626236,  701164723 },
	{ 2147082241, 1897279176,  617820870 },
	{ 2147074049, 1888819123,  158382189 },
	{ 2147051521,   25006327,  522758543 },
	{ 2147043329,  327546255,   37227845 },
	{ 2147039233,  766324424, 1133356428 },
	{ 2146988033, 1862817362,   73861329 },
	{ 2146963457,  404622040,  653019435 },
	{ 2146959361, 1936581214,  995143093 },
	{ 2146938881, 1559770096,  634921513 },
	{ 2146908161,  422623708, 1985060172 },
	{ 2146885633, 1751189170,  298238186 },
	{ 2146871297,  578919515,  291810829 },
	{ 2146846721, 1114060353,  915902322 },
	{ 2146834433, 2069565474,   47859524 },
	{ 2146818049, 1552824584,  646281055 },
	{ 2146775041, 1906267847, 1597832891 },
	{ 2146756609, 1847414714, 1228090888 },
	{ 2146744321, 1818792070, 1176377637 },
	{ 2146738177, 1118066398, 1054971214 },
	{ 2146736129,   52057278,  933422153 },
	{ 2146713601,  592259376, 1406621510 },
	{ 2146695169,  263161877, 1514178701 },
	{ 2146656257,  685363115,  384505091 },
	{ 2146650113,  927727032,  537575289 },
	{ 2146646017,   52575506, 1799464037 },
	{ 2146643969, 1276803876, 1348954416 },
	{ 2146603009,  814028633, 1521547704 },
	{ 2146572289, 1846678872, 1310832121 },
	{ 2146547713,  919368090, 1019041349 },
	{ 2146508801,  671847612,   38582496 },
	{ 2146492417,  283911680,  532424562 },
	{ 2146490369, 1780044827,  896447978 },
	{ 2146459649,  327980850, 1327906900 },
	{ 2146447361, 1310561493,  958645253 },
	{ 2146441217,  412148926,  287271128 },
	{ 2146437121,  293186449, 2009822534 },
	{ 2146430977,  179034356, 1359155584 },
	{ 2146418689, 1517345488, 1790248672 },
	{ 2146406401, 1615820390, 1584833571 },
	{ 2146404353,  826651445,  607120498 },
	{ 2146379777,    3816988, 1897049071 },
	{ 2146363393, 1221409784, 1986921567 },
	{ 2146355201, 1388081168,  849968120 },
	{ 2146336769, 1803473237, 1655544036 },
	{ 2146312193, 1023484977,  273671831 },
	{ 2146293761, 1074591448,  467406983 },
	{ 2146283521,  831604668, 1523950494 },
	{ 2146203649,  712865423, 1170834574 },
	{ 2146154497, 1764991362, 1064856763 },
	{ 2146142209,  627386213, 1406840151 },
	{ 2146127873, 1638674429, 2088393537 },
	{ 2146099201, 1516001018,  690673370 },
	{ 2146093057, 1294931393,  315136610 },
	{ 2146091009, 1942399533,  973539425 },
	{ 2146078721, 1843461814, 2132275436 },
	{ 2146060289, 1098740778,  360423481 },
	{ 2146048001, 1617213232, 1951981294 },
	{ 2146041857, 1805783169, 2075683489 },
	{ 2146019329,  272027909, 1753219918 },
	{ 2145986561, 1206530344, 2034028118 },
	{ 2145976321, 1243769360, 1173377644 },
	{ 2145964033,  887200839, 1281344586 },
	{ 2145906689, 1651026455,  906178216 },
	{ 2145875969, 1673238256, 1043521212 },
	{ 2145871873, 1226591210, 1399796492 },
	{ 2145841153, 1465353397, 1324527802 },
	{ 2145832961, 1150638905,  554084759 },
	{ 2145816577,  221601706,  427340863 },
	{ 2145785857,  608896761,  316590738 },
	{ 2145755137, 1712054942, 1684294304 },
	{ 2145742849, 1302302867,  724873116 },
	{ 2145728513,  516717693,  431671476 },
	{ 2145699841,  524575579, 1619722537 },
	{ 2145691649, 1925625239,  982974435 },
	{ 2145687553,  463795662, 1293154300 },
	{ 2145673217,  771716636,  881778029 },
	{ 2145630209, 1509556977,  837364988 },
	{ 2145595393,  229091856,  851648427 },
	{ 2145587201, 1796903241,  635342424 },
	{ 2145525761,  715310882, 1677228081 },
	{ 2145495041, 1040930522,  200685896 },
	{ 2145466369,  949804237, 1809146322 },
	{ 2145445889, 1673903706,   95316881 },
	{ 2145390593,  806941852, 1428671135 },
	{ 2145372161, 1402525292,  159350694 },
	{ 2145361921, 2124760298, 1589134749 },
	{ 2145359873, 1217503067, 1561543010 },
	{ 2145355777,  338341402,   83865711 },
	{ 2145343489, 1381532164,  641430002 },
	{ 2145325057, 1883895478, 1528469895 },
	{ 2145318913, 1335370424,   65809740 },
	{ 2145312769, 2000008042, 1919775760 },
	{ 2145300481,  961450962, 1229540578 },
	{ 2145282049,  910466767, 1964062701 },
	{ 2145232897,  816527501,  450152063 },
	{ 2145218561, 1435128058, 1794509700 },
	{ 2145187841,   33505311, 1272467582 },
	{ 2145181697,  269767433, 1380363849 },
	{ 2145175553,   56386299, 1316870546 },
	{ 2145079297, 2106880293, 1391797340 },
	{ 2145021953, 1347906152,  720510798 },
	{ 2145015809,  206769262, 1651459955 },
	{ 2145003521, 1885513236, 1393381284 },
	{ 2144960513, 1810381315,   31937275 },
	{ 2144944129, 1306487838, 2019419520 },
	{ 2144935937,   37304730, 1841489054 },
	{ 2144894977, 1601434616,  157985831 },
	{ 2144888833,   98749330, 2128592228 },
	{ 2144880641, 1772327002, 2076128344 },
	{ 2144864257, 1404514762, 2029969964 },
	{ 2144827393,  801236594,  406627220 },
	{ 2144806913,  349217443, 1501080290 },
	{ 2144796673, 1542656776, 2084736519 },
	{ 2144778241, 1210734884, 1746416203 },
	{ 2144759809, 1146598851,  716464489 },
	{ 2144757761,  286328400, 1823728177 },
	{ 2144729089, 1347555695, 1836644881 },
	{ 2144727041, 1795703790,  520296412 },
	{ 2144696321, 1302475157,  852964281 },
	{ 2144667649, 1075877614,  504992927 },
	{ 2144573441,  198765808, 1617144982 },
	{ 2144555009,  321528767,  155821259 },
	{ 2144550913,  814139516, 1819937644 },
	{ 2144536577,  571143206,  962942255 },
	{ 2144524289, 1746733766,    2471321 },
	{ 2144512001, 1821415077,  124190939 },
	{ 2144468993,  917871546, 1260072806 },
	{ 2144458753,  378417981, 1569240563 },
	{ 2144421889,  175229668, 1825620763 },
	{ 2144409601, 1699216963,  351648117 },
	{ 2144370689, 1071885991,  958186029 },
	{ 2144348161, 1763151227,  540353574 },
	{ 2144335873, 1060214804,  919598847 },
	{ 2144329729,  663515846, 1448552668 },
	{ 2144327681, 1057776305,  590222840 },
	{ 2144309249, 1705149168, 1459294624 },
	{ 2144296961,  325823721, 1649016934 },
	{ 2144290817,  738775789,  447427206 },
	{ 2144243713,  962347618,  893050215 },
	{ 2144237569, 1655257077,  900860862 },
	{ 2144161793,  242206694, 1567868672 },
	{ 2144155649,  769415308, 1247993134 },
	{ 2144137217,  320492023,  515841070 },
	{ 2144120833, 1639388522,  770877302 },
	{ 2144071681, 1761785233,  964296120 },
	{ 2144065537,  419817825,  204564472 },
	{ 2144028673,  666050597, 2091019760 },
	{ 2144010241, 1413657615, 1518702610 },
	{ 2143952897, 1238327946,  475672271 },
	{ 2143940609,  307063413, 1176750846 },
	{ 2143918081, 2062905559,  786785803 },
	{ 2143899649, 1338112849, 1562292083 },
	{ 2143891457,   68149545,   87166451 },
	{ 2143885313,  921750778,  394460854 },
	{ 2143854593,  719766593,  133877196 },
	{ 2143836161, 1149399850, 1861591875 },
	{ 2143762433, 1848739366, 1335934145 },
	{ 2143756289, 1326674710,  102999236 },
	{ 2143713281,  808061791, 1156900308 },
	{ 2143690753,  388399459, 1926468019 },
	{ 2143670273, 1427891374, 1756689401 },
	{ 2143666177, 1912173949,  986629565 },
	{ 2143645697, 2041160111,  371842865 },
	{ 2143641601, 1279906897, 2023974350 },
	{ 2143635457,  720473174, 1389027526 },
	{ 2143621121, 1298309455, 1732632006 },
	{ 2143598593, 1548762216, 1825417506 },
	{ 2143567873,  620475784, 1073787233 },
	{ 2143561729, 1932954575,  949167309 },
	{ 2143553537,  354315656, 1652037534 },
	{ 2143541249,  577424288, 1097027618 },
	{ 2143531009,  357862822,  478640055 },
	{ 2143522817, 2017706025, 1550531668 },
	{ 2143506433, 2078127419, 1824320165 },
	{ 2143488001,  613475285, 1604011510 },
	{ 2143469569, 1466594987,  502095196 },
	{ 2143426561, 1115430331, 1044637111 },
	{ 2143383553,    9778045, 1902463734 },
	{ 2143377409, 1557401276, 2056861771 },
	{ 2143363073,  652036455, 1965915971 },
	{ 2143260673, 1464581171, 1523257541 },
	{ 2143246337, 1876119649,  764541916 },
	{ 2143209473, 1614992673, 1920672844 },
	{ 2143203329,  981052047, 2049774209 },
	{ 2143160321, 1847355533,  728535665 },
	{ 2143129601,  965558457,  603052992 },
	{ 2143123457, 2140817191,    8348679 },
	{ 2143100929, 1547263683,  694209023 },
	{ 2143092737,  643459066, 1979934533 },
	{ 2143082497,  188603778, 2026175670 },
	{ 2143062017, 1657329695,  377451099 },
	{ 2143051777,  114967950,  979255473 },
	{ 2143025153, 1698431342, 1449196896 },
	{ 2143006721, 1862741675, 1739650365 },
	{ 2142996481,  756660457,  996160050 },
	{ 2142976001,  927864010, 1166847574 },
	{ 2142965761,  905070557,  661974566 },
	{ 2142916609,   40932754, 1787161127 },
	{ 2142892033, 1987985648,  675335382 },
	{ 2142885889,  797497211, 1323096997 },
	{ 2142871553, 2068025830, 1411877159 },
	{ 2142861313, 1217177090, 1438410687 },
	{ 2142830593,  409906375, 1767860634 },
	{ 2142803969, 1197788993,  359782919 },
	{ 2142785537,  643817365,  513932862 },
	{ 2142779393, 1717046338,  218943121 },
	{ 2142724097,   89336830,  416687049 },
	{ 2142707713,    5944581, 1356813523 },
	{ 2142658561,  887942135, 2074011722 },
	{ 2142638081,  151851972, 1647339939 },
	{ 2142564353, 1691505537, 1483107336 },
	{ 2142533633, 1989920200, 1135938817 },
	{ 2142529537,  959263126, 1531961857 },
	{ 2142527489,  453251129, 1725566162 },
	{ 2142502913, 1536028102,  182053257 },
	{ 2142498817,  570138730,  701443447 },
	{ 2142416897,  326965800,  411931819 },
	{ 2142363649, 1675665410, 1517191733 },
	{ 2142351361,  968529566, 1575712703 },
	{ 2142330881, 1384953238, 1769087884 },
	{ 2142314497, 1977173242, 1833745524 },
	{ 2142289921,   95082313, 1714775493 },
	{ 2142283777,  109377615, 1070584533 },
	{ 2142277633,   16960510,  702157145 },
	{ 2142263297,  553850819,  431364395 },
	{ 2142208001,  241466367, 2053967982 },
	{ 2142164993, 1795661326, 1031836848 },
	{ 2142097409, 1212530046,  712772031 },
	{ 2142087169, 1763869720,  822276067 },
	{ 2142078977,  644065713, 1765268066 },
	{ 2142074881,  112671944,  643204925 },
	{ 2142044161, 1387785471, 1297890174 },
	{ 2142025729,  783885537, 1000425730 },
	{ 2142011393,  905662232, 1679401033 },
	{ 2141974529,  799788433,  468119557 },
	{ 2141943809, 1932544124,  449305555 },
	{ 2141933569, 1527403256,  841867925 },
	{ 2141931521, 1247076451,  743823916 },
	{ 2141902849, 1199660531,  401687910 },
	{ 2141890561,  150132350, 1720336972 },
	{ 2141857793, 1287438162,  663880489 },
	{ 2141833217,  618017731, 1819208266 },
	{ 2141820929,  999578638, 1403090096 },
	{ 2141786113,   81834325, 1523542501 },
	{ 2141771777,  120001928,  463556492 },
	{ 2141759489,  122455485, 2124928282 },
	{ 2141749249,  141986041,  940339153 },
	{ 2141685761,  889088734,  477141499 },
	{ 2141673473,  324212681, 1122558298 },
	{ 2141669377, 1175806187, 1373818177 },
	{ 2141655041, 1113654822,  296887082 },
	{ 2141587457,  991103258, 1585913875 },
	{ 2141583361, 1401451409, 1802457360 },
	{ 2141575169, 1571977166,  712760980 },
	{ 2141546497, 1107849376, 1250270109 },
	{ 2141515777,  196544219,  356001130 },
	{ 2141495297, 1733571506, 1060744866 },
	{ 2141483009,  321552363, 1168297026 },
	{ 2141458433,  505818251,  733225819 },
	{ 2141360129, 1026840098,  948342276 },
	{ 2141325313,  945133744, 2129965998 },
	{ 2141317121, 1871100260, 1843844634 },
	{ 2141286401, 1790639498, 1750465696 },
	{ 2141267969, 1376858592,  186160720 },
	{ 2141255681, 2129698296, 1876677959 },
	{ 2141243393, 2138900688, 1340009628 },
	{ 2141214721, 1933049835, 1087819477 },
	{ 2141212673, 1898664939, 1786328049 },
	{ 2141202433,  990234828,  940682169 },
	{ 2141175809, 1406392421,  993089586 },
	{ 2141165569, 1263518371,  289019479 },
	{ 2141073409, 1485624211,  507864514 },
	{ 2141052929, 1885134788,  311252465 },
	{ 2141040641, 1285021247,  280941862 },
	{ 2141028353, 1527610374,  375035110 },
	{ 2141011969, 1400626168,  164696620 },
	{ 2140999681,  632959608,  966175067 },
	{ 2140997633, 2045628978, 1290889438 },
	{ 2140993537, 1412755491,  375366253 },
	{ 2140942337,  719477232,  785367828 },
	{ 2140925953,   45224252,  836552317 },
	{ 2140917761, 1157376588, 1001839569 },
	{ 2140887041,  278480752, 2098732796 },
	{ 2140837889, 1663139953,  924094810 },
	{ 2140788737,  802501511, 2045368990 },
	{ 2140766209, 1820083885, 1800295504 },
	{ 2140764161, 1169561905, 2106792035 },
	{ 2140696577,  127781498, 1885987531 },
	{ 2140684289,   16014477, 1098116827 },
	{ 2140653569,  665960598, 1796728247 },
	{ 2140594177, 1043085491,  377310938 },
	{ 2140579841, 1732838211, 1504505945 },
	{ 2140569601,  302071939,  358291016 },
	{ 2140567553,  192393733, 1909137143 },
	{ 2140557313,  406595731, 1175330270 },
	{ 2140549121, 1748850918,  525007007 },
	{ 2140477441,  499436566, 1031159814 },
	{ 2140469249, 1886004401, 1029951320 },
	{ 2140426241, 1483168100, 1676273461 },
	{ 2140420097, 1779917297,  846024476 },
	{ 2140413953,  522948893, 1816354149 },
	{ 2140383233, 1931364473, 1296921241 },
	{ 2140366849, 1917356555,  147196204 },
	{ 2140354561,   16466177, 1349052107 },
	{ 2140348417, 1875366972, 1860485634 },
	{ 2140323841,  456498717, 1790256483 },
	{ 2140321793, 1629493973,  150031888 },
	{ 2140315649, 1904063898,  395510935 },
	{ 2140280833, 1784104328,  831417909 },
	{ 2140250113,  256087139,  697349101 },
	{ 2140229633,  388553070,  243875754 },
	{ 2140223489,  747459608, 1396270850 },
	{ 2140200961,  507423743, 1895572209 },
	{ 2140162049,  580106016, 2045297469 },
	{ 2140149761,  712426444,  785217995 },
	{ 2140137473, 1441607584,  536866543 },
	{ 2140119041,  346538902, 1740434653 },
	{ 2140090369,  282642885,   21051094 },
	{ 2140076033, 1407456228,  319910029 },
	{ 2140047361, 1619330500, 1488632070 },
	{ 2140041217, 2089408064, 2012026134 },
	{ 2140008449, 1705524800, 1613440760 },
	{ 2139924481, 1846208233, 1280649481 },
	{ 2139906049,  989438755, 1185646076 },
	{ 2139867137, 1522314850,  372783595 },
	{ 2139842561, 1681587377,  216848235 },
	{ 2139826177, 2066284988, 1784999464 },
	{ 2139824129,  480888214, 1513323027 },
	{ 2139789313,  847937200,  858192859 },
	{ 2139783169, 1642000434, 1583261448 },
	{ 2139770881,  940699589,  179702100 },
	{ 2139768833,  315623242,  964612676 },
	{ 2139666433,  331649203,  764666914 },
	{ 2139641857, 2118730799, 1313764644 },
	{ 2139635713,  519149027,  519212449 },
	{ 2139598849, 1526413634, 1769667104 },
	{ 2139574273,  551148610,  820739925 },
	{ 2139568129, 1386800242,  472447405 },
	{ 2139549697,  813760130, 1412328531 },
	{ 2139537409, 1615286260, 1609362979 },
	{ 2139475969, 1352559299, 1696720421 },
	{ 2139455489, 1048691649, 1584935400 },
	{ 2139432961,  836025845,  950121150 },
	{ 2139424769, 1558281165, 1635486858 },
	{ 2139406337, 1728402143, 1674423301 },
	{ 2139396097, 1727715782, 1483470544 },
	{ 2139383809, 1092853491, 1741699084 },
	{ 2139369473,  690776899, 1242798709 },
	{ 2139351041, 1768782380, 2120712049 },
	{ 2139334657, 1739968247, 1427249225 },
	{ 2139332609, 1547189119,  623011170 },
	{ 2139310081, 1346827917, 1605466350 },
	{ 2139303937,  369317948,  828392831 },
	{ 2139301889, 1560417239, 1788073219 },
	{ 2139283457, 1303121623,  595079358 },
	{ 2139248641, 1354555286,  573424177 },
	{ 2139240449,   60974056,  885781403 },
	{ 2139222017,  355573421, 1221054839 },
	{ 2139215873,  566477826, 1724006500 },
	{ 2139150337,  871437673, 1609133294 },
	{ 2139144193, 1478130914, 1137491905 },
	{ 2139117569, 1854880922,  964728507 },
	{ 2139076609,  202405335,  756508944 },
	{ 2139062273, 1399715741,  884826059 },
	{ 2139045889, 1051045798, 1202295476 },
	{ 2139033601, 1707715206,  632234634 },
	{ 2139006977, 2035853139,  231626690 },
	{ 2138951681,  183867876,  838350879 },
	{ 2138945537, 1403254661,  404460202 },
	{ 2138920961,  310865011, 1282911681 },
	{ 2138910721, 1328496553,  103472415 },
	{ 2138904577,   78831681,  993513549 },
	{ 2138902529, 1319697451, 1055904361 },
	{ 2138816513,  384338872, 1706202469 },
	{ 2138810369, 1084868275,  405677177 },
	{ 2138787841,  401181788, 1964773901 },
	{ 2138775553, 1850532988, 1247087473 },
	{ 2138767361,  874261901, 1576073565 },
	{ 2138757121, 1187474742,  993541415 },
	{ 2138748929, 1782458888, 1043206483 },
	{ 2138744833, 1221500487,  800141243 },
	{ 2138738689,  413465368, 1450660558 },
	{ 2138695681,  739045140,  342611472 },
	{ 2138658817, 1355845756,  672674190 },
	{ 2138644481,  608379162, 1538874380 },
	{ 2138632193, 1444914034,  686911254 },
	{ 2138607617,  484707818, 1435142134 },
	{ 2138591233,  539460669, 1290458549 },
	{ 2138572801, 2093538990, 2011138646 },
	{ 2138552321, 1149786988, 1076414907 },
	{ 2138546177,  840688206, 2108985273 },
	{ 2138533889,  209669619,  198172413 },
	{ 2138523649, 1975879426, 1277003968 },
	{ 2138490881, 1351891144, 1976858109 },
	{ 2138460161, 1817321013, 1979278293 },
	{ 2138429441, 1950077177,  203441928 },
	{ 2138400769,  908970113,  628395069 },
	{ 2138398721,  219890864,  758486760 },
	{ 2138376193, 1306654379,  977554090 },
	{ 2138351617,  298822498, 2004708503 },
	{ 2138337281,  441457816, 1049002108 },
	{ 2138320897, 1517731724, 1442269609 },
	{ 2138290177, 1355911197, 1647139103 },
	{ 2138234881,  531313247, 1746591962 },
	{ 2138214401, 1899410930,  781416444 },
	{ 2138202113, 1813477173, 1622508515 },
	{ 2138191873, 1086458299, 1025408615 },
	{ 2138183681, 1998800427,  827063290 },
	{ 2138173441, 1921308898,  749670117 },
	{ 2138103809, 1620902804, 2126787647 },
	{ 2138099713,  828647069, 1892961817 },
	{ 2138085377,  179405355, 1525506535 },
	{ 2138060801,  615683235, 1259580138 },
	{ 2138044417, 2030277840, 1731266562 },
	{ 2138042369, 2087222316, 1627902259 },
	{ 2138032129,  126388712, 1108640984 },
	{ 2138011649,  715026550, 1017980050 },
	{ 2137993217, 1693714349, 1351778704 },
	{ 2137888769, 1289762259, 1053090405 },
	{ 2137853953,  199991890, 1254192789 },
	{ 2137833473,  941421685,  896995556 },
	{ 2137817089,  750416446, 1251031181 },
	{ 2137792513,  798075119,  368077456 },
	{ 2137786369,  878543495, 1035375025 },
	{ 2137767937,    9351178, 1156563902 },
	{ 2137755649, 1382297614, 1686559583 },
	{ 2137724929, 1345472850, 1681096331 },
	{ 2137704449,  834666929,  630551727 },
	{ 2137673729, 1646165729, 1892091571 },
	{ 2137620481,  778943821,   48456461 },
	{ 2137618433, 1730837875, 1713336725 },
	{ 2137581569,  805610339, 1378891359 },
	{ 2137538561,  204342388, 1950165220 },
	{ 2137526273, 1947629754, 1500789441 },
	{ 2137516033,  719902645, 1499525372 },
	{ 2137491457,  230451261,  556382829 },
	{ 2137440257,  979573541,  412760291 },
	{ 2137374721,  927841248, 1954137185 },
	{ 2137362433, 1243778559,  861024672 },
	{ 2137313281, 1341338501,  980638386 },
	{ 2137311233,  937415182, 1793212117 },
	{ 2137255937,  795331324, 1410253405 },
	{ 2137243649,  150756339, 1966999887 },
	{ 2137182209,  163346914, 1939301431 },
	{ 2137171969, 1952552395,  758913141 },
	{ 2137159681,  570788721,  218668666 },
	{ 2137147393, 1896656810, 2045670345 },
	{ 2137141249,  358493842,  518199643 },
	{ 2137139201, 1505023029,  674695848 },
	{ 2137133057,   27911103,  830956306 },
	{ 2137122817,  439771337, 1555268614 },
	{ 2137116673,  790988579, 1871449599 },
	{ 2137110529,  432109234,  811805080 },
	{ 2137102337, 1357900653, 1184997641 },
	{ 2137098241,  515119035, 1715693095 },
	{ 2137090049,  408575203, 2085660657 },
	{ 2137085953, 2097793407, 1349626963 },
	{ 2137055233, 1556739954, 1449960883 },
	{ 2137030657, 1545758650, 1369303716 },
	{ 2136987649,  332602570,  103875114 },
	{ 2136969217, 1499989506, 1662964115 },
	{ 2136924161,  857040753,    4738842 },
	{ 2136895489, 1948872712,  570436091 },
	{ 2136893441,   58969960, 1568349634 },
	{ 2136887297, 2127193379,  273612548 },
	{ 2136850433,  111208983, 1181257116 },
	{ 2136809473, 1627275942, 1680317971 },
	{ 2136764417, 1574888217,   14011331 },
	{ 2136741889,   14011055, 1129154251 },
	{ 2136727553,   35862563, 1838555253 },
	{ 2136721409,  310235666, 1363928244 },
	{ 2136698881, 1612429202, 1560383828 },
	{ 2136649729, 1138540131,  800014364 },
	{ 2136606721,  602323503, 1433096652 },
	{ 2136563713,  182209265, 1919611038 },
	{ 2136555521,  324156477,  165591039 },
	{ 2136549377,  195513113,  217165345 },
	{ 2136526849, 1050768046,  939647887 },
	{ 2136508417, 1886286237, 1619926572 },
	{ 2136477697,  609647664,   35065157 },
	{ 2136471553,  679352216, 1452259468 },
	{ 2136457217,  128630031,  824816521 },
	{ 2136422401,   19787464, 1526049830 },
	{ 2136420353,  698316836, 1530623527 },
	{ 2136371201, 1651862373, 1804812805 },
	{ 2136334337,  326596005,  336977082 },
	{ 2136322049,   63253370, 1904972151 },
	{ 2136297473,  312176076,  172182411 },
	{ 2136248321,  381261841,  369032670 },
	{ 2136242177,  358688773, 1640007994 },
	{ 2136229889,  512677188,   75585225 },
	{ 2136219649, 2095003250, 1970086149 },
	{ 2136207361, 1909650722,  537760675 },
	{ 2136176641, 1334616195, 1533487619 },
	{ 2136158209, 2096285632, 1793285210 },
	{ 2136143873, 1897347517,  293843959 },
	{ 2136133633,  923586222, 1022655978 },
	{ 2136096769, 1464868191, 1515074410 },
	{ 2136094721, 2020679520, 2061636104 },
	{ 2136076289,  290798503, 1814726809 },
	{ 2136041473,  156415894, 1250757633 },
	{ 2135996417,  297459940, 1132158924 },
	{ 2135955457,  538755304, 1688831340 },
	{ 0, 0, 0 }
};

/*
 * Prime moduli for the ternary case. Each prime p is such that
 * p = 1 mod 2304. Generator g is a primitive 2304-th root of 1.
 */
static const small_prime PRIMES3[] = {
	{ 2147450113, 1822830492,      33535 },
	{ 2147431681,  424626201, 1193134109 },
	{ 2147415553, 1454863251, 1663647397 },
	{ 2147390209, 1762035773, 1387046861 },
	{ 2147385601, 1517680363, 1106952843 },
	{ 2147362561, 1025814050,  440476355 },
	{ 2147355649,  865455738,  854658425 },
	{ 2147346433, 1321425846,  224103891 },
	{ 2147339521, 1474981691,  599730472 },
	{ 2147332609, 1864656042, 1545592206 },
	{ 2147316481, 1890505928,  421789636 },
	{ 2147309569,  906570069, 1610828544 },
	{ 2147304961, 1403818598, 1990856782 },
	{ 2147281921,   71783863,  956869830 },
	{ 2147258881, 1036649303,  396683436 },
	{ 2147242753,  467401799, 1773880773 },
	{ 2147235841, 1453821700,  461674371 },
	{ 2147233537,  598421725, 1689622480 },
	{ 2147217409, 1761254347,  688859791 },
	{ 2147212801, 1327730595, 1887769026 },
	{ 2147164417, 1258121641,  366578724 },
	{ 2147141377, 1777466165,  171390629 },
	{ 2147139073, 1984146916,  328716798 },
	{ 2147136769, 1765129553,  767922350 },
	{ 2147129857, 1514145184, 1081034369 },
	{ 2147104513, 1951719537,  733036907 },
	{ 2147095297,  682785034,  373776370 },
	{ 2147079169, 1820310317, 1807535939 },
	{ 2147051521,  458986762,  590428790 },
	{ 2147049217, 1038363684,  877203562 },
	{ 2147026177, 1326504697,  643505453 },
	{ 2147003137, 1170185764, 1319639833 },
	{ 2146966273,  114827812, 1294985554 },
	{ 2146959361, 1164199326, 1256988252 },
	{ 2146954753,  486248957,  710359258 },
	{ 2146947841, 2000149550,  918021771 },
	{ 2146936321,  942091103,  108081081 },
	{ 2146906369,  271696604,  608809917 },
	{ 2146887937, 1511165281,  369139633 },
	{ 2146885633,  441164610,  926260308 },
	{ 2146883329, 1085986991,  240773649 },
	{ 2146864897,  345552901, 1817459006 },
	{ 2146814209,  793155214,  640578693 },
	{ 2146775041, 1675390468,  820220886 },
	{ 2146772737,  730144429,  765352711 },
	{ 2146756609, 1835554388, 1004443916 },
	{ 2146738177,  433272441, 2105099367 },
	{ 2146733569, 1762957593, 1602986233 },
	{ 2146694401,  399612535,  169309537 },
	{ 2146687489,  114105700,  780597858 },
	{ 2146646017, 1434027294,  564442758 },
	{ 2146622977, 1341692395, 2091021085 },
	{ 2146613761,  360157916, 1064050988 },
	{ 2146606849, 1313179470, 1969566727 },
	{ 2146599937, 1706429999,  652421166 },
	{ 2146572289, 1732243288, 1454972738 },
	{ 2146544641,  272853975,  590131110 },
	{ 2146542337,   36418634, 1056975891 },
	{ 2146530817, 2007241330, 1580599978 },
	{ 2146507777, 1995701118, 1014402730 },
	{ 2146493953, 1114934790, 1032062368 },
	{ 2146487041, 1862337352, 1231735150 },
	{ 2146450177,  846834198,  681753242 },
	{ 2146447873, 1227566685,   12770655 },
	{ 2146417921, 1671891715,  794746270 },
	{ 2146406401,  609289185,  630588397 },
	{ 2146381057, 2109266947,  655092508 },
	{ 2146378753,  343938960,  966167795 },
	{ 2146367233,   41811369, 1440184031 },
	{ 2146353409, 1450579491,  183813399 },
	{ 2146348801,    9565898,  526104353 },
	{ 2146330369, 1407087756,  647129879 },
	{ 2146325761,  957276356,  283440898 },
	{ 2146291201,  925507446,  985278760 },
	{ 2146288897,   48605924,  828823151 },
	{ 2146256641,  974604801, 1426305449 },
	{ 2146203649,  977374447, 1007788238 },
	{ 2146192129, 2083411670, 1165914744 },
	{ 2146187521, 1993961053,  795729927 },
	{ 2146180609, 1629167227,  730660993 },
	{ 2146169089,   44701833, 1427754293 },
	{ 2146106881,   16997996,  530746042 },
	{ 2146095361,  264082098,  306963294 },
	{ 2146093057,  662783894, 1341690726 },
	{ 2146090753, 1656443739,   45600745 },
	{ 2146072321, 1430706864, 1210417794 },
	{ 2146067713, 1657990272, 1024407936 },
	{ 2146030849, 1649603809, 2098081629 },
	{ 2146019329,  978947895,  491565736 },
	{ 2146014721,   48551225,   46133079 },
	{ 2145996289, 1832516941,  325405827 },
	{ 2145984769, 1046055041, 1409723796 },
	{ 2145964033,   66156561,  464497063 },
	{ 2145954817,  859915264, 2092994912 },
	{ 2145952513, 1758184581,  956837854 },
	{ 2145943297, 1901395808, 1848403013 },
	{ 2145915649,   30807819, 1059439378 },
	{ 2145904129,  647739402, 1973108753 },
	{ 2145874177, 1869553544,  577659032 },
	{ 2145871873,  337408396, 1872862727 },
	{ 2145864961, 1685455768,  667710631 },
	{ 2145862657, 1532795538, 2070068256 },
	{ 2145851137,  212501100, 1224511404 },
	{ 2145837313, 1358121493, 1848966089 },
	{ 2145825793,  386307300,  449999704 },
	{ 2145823489, 1129365680, 1001085691 },
	{ 2145816577,  551493242, 2119183454 },
	{ 2145807361,  271270756, 1989968022 },
	{ 2145793537,  852239048, 1309749017 },
	{ 2145782017, 1284378810,  311082915 },
	{ 2145777409, 2004177093, 1290706457 },
	{ 2145742849, 2121468587, 1133755266 },
	{ 2145733633, 1260159354, 1951998626 },
	{ 2145722113,  163237044,  594573040 },
	{ 2145689857,  474757169,  834321078 },
	{ 2145687553,   67947935,  828266594 },
	{ 2145664513, 1598442324,  630205829 },
	{ 2145646081,  250505282,  776273401 },
	{ 2145623041, 1703821214,  888409131 },
	{ 2145611521, 1039247338,  228177613 },
	{ 2145609217, 1668731457, 1185982491 },
	{ 2145600001,  857636216,  139252527 },
	{ 2145595393,  400214229,  729082632 },
	{ 2145593089, 1796005933,  550289398 },
	{ 2145588481, 2094475478, 1217287696 },
	{ 2145565441,  426324144, 1312430145 },
	{ 2145563137,   78773460,  169188458 },
	{ 2145549313,  936100306,  757760717 },
	{ 2145542401, 1097930762,  824118991 },
	{ 2145535489, 1983878618, 1042705853 },
	{ 2145528577, 1036190039, 1022323836 },
	{ 2145523969, 1868801802,  416370830 },
	{ 2145491713,  356121488,  543381348 },
	{ 2145480193,  199326412, 1731701467 },
	{ 2145466369, 1830188719,  240239794 },
	{ 2145445633,  351737879, 1506144677 },
	{ 2145443329,  379875076,  475878516 },
	{ 2145434113, 1003996799,  683903694 },
	{ 2145415681, 1035366258, 1531251342 },
	{ 2145401857,  126895727, 1548302219 },
	{ 2145390337,  203720005,  425208191 },
	{ 2145388033, 1347512002,  117858071 },
	{ 2145362689, 1169852366, 1431567820 },
	{ 2145355777, 2110316730, 2086117269 },
	{ 2145353473, 1774773548,  876852201 },
	{ 2145339649,  501723795, 1021106097 },
	{ 2145318913,  418847235, 1160609910 },
	{ 2145300481, 1023331752,  191383930 },
	{ 2145286657, 1280971615,  216845844 },
	{ 2145282049, 1196793073, 1187575821 },
	{ 2145235969,  923496757, 1307358539 },
	{ 2145219841,  519785435, 1626462263 },
	{ 2145185281, 1860630272,  474564844 },
	{ 2145180673, 1834049770,  586172945 },
	{ 2145178369, 1501247472, 1096722774 },
	{ 2145136897,  550810282,   40160384 },
	{ 2145113857, 1296058651,  977708791 },
	{ 2145079297,  955545860,  265600380 },
	{ 2145076993,   79051519, 1039925789 },
	{ 2145067777,  253166375, 1127232024 },
	{ 2145065473, 1026024296,  756613594 },
	{ 2145063169, 1426910002, 1608845610 },
	{ 2145033217,  970758503, 1555852593 },
	{ 2145017089,  347430931,  775368992 },
	{ 2145007873,  914675316, 1297416956 },
	{ 2144975617, 2015869942, 1431118733 },
	{ 2144938753, 1762298335, 1193660775 },
	{ 2144929537, 1449381583, 1771237555 },
	{ 2144920321,  875265402, 2099494532 },
	{ 2144915713,  582439339,  817587747 },
	{ 2144894977,  506160393, 1688289421 },
	{ 2144809729,  734926996, 1704354178 },
	{ 2144793601,  155059687,  171692410 },
	{ 2144777473,  317485600,  874802365 },
	{ 2144775169,  651843170,  473816143 },
	{ 2144759041,  681485475,  464197116 },
	{ 2144733697, 2125180198,   48767965 },
	{ 2144729089, 1478112475, 1355118431 },
	{ 2144712961, 1279790481,  591304708 },
	{ 2144648449, 1335778078, 1098669758 },
	{ 2144630017, 1603567267,  160302246 },
	{ 2144604673, 1175259039,   78203500 },
	{ 2144597761,  620616998, 1515263848 },
	{ 2144579329,  193500483, 1559132057 },
	{ 2144567809, 1946028673, 1581197529 },
	{ 2144558593,  231387691, 1485256545 },
	{ 2144551681,  844374396,   30673778 },
	{ 2144535553,  166176063,  168263365 },
	{ 2144528641,  781790035,  556577063 },
	{ 2144500993,  461561124, 1399755614 },
	{ 2144459521,    2822303,  752681683 },
	{ 2144454913,  274692318,  257668067 },
	{ 2144448001,  716371349,  584223158 },
	{ 2144418049, 1936863174,  540598834 },
	{ 2144388097, 1855586009,  690032843 },
	{ 2144383489,  408100025, 1859550157 },
	{ 2144348929,  122163029, 2060148799 },
	{ 2144337409, 1525008836,  819305252 },
	{ 2144330497, 2024998620, 1611547511 },
	{ 2144275201, 1947760064, 1759305590 },
	{ 2144261377,  468455779, 2046852340 },
	{ 2144256769,  243366493,  207179424 },
	{ 2144236033,  562111014,  536612673 },
	{ 2144229121,  562082296, 1933892350 },
	{ 2144210689, 1057111161,  162239457 },
	{ 2144192257, 1440567493,  907872966 },
	{ 2144160001,  464029916,  319626240 },
	{ 2144136961,  853524564,  297716302 },
	{ 2144120833,  587037095, 1136871325 },
	{ 2144065537,  231183627,  323060764 },
	{ 2144028673,  340762973, 1758401946 },
	{ 2144010241,  593721336,  481717690 },
	{ 2143996417,  743415799,   71802978 },
	{ 2143975681,  403083216,  363908257 },
	{ 2143950337,  854680705, 1615520152 },
	{ 2143948033,  294824006, 1680513832 },
	{ 2143922689,  648528897,  390399209 },
	{ 2143918081, 1755729599,  293848938 },
	{ 2143899649, 1560525715,  670501530 },
	{ 2143867393,  733595942, 1533336387 },
	{ 2143821313, 1550195321,  726145119 },
	{ 2143786753,  856875165,   36866658 },
	{ 2143784449, 1222822055, 1205640485 },
	{ 2143754497,  991548026,  190649322 },
	{ 2143742977, 1756977003,  292977861 },
	{ 2143740673, 1342868950,  176825607 },
	{ 2143708417, 1236271287,  157693291 },
	{ 2143692289, 1746765009, 1168989539 },
	{ 2143685377, 1342856351, 1371059722 },
	{ 2143680769,  273481162, 1775434577 },
	{ 2143641601, 1998453617,  606651047 },
	{ 2143567873,  702418292,  536490409 },
	{ 2143556353, 1662552442, 1276091018 },
	{ 2143535617,  842561199, 1808542507 },
	{ 2143533313,  826061287, 1605713154 },
	{ 2143531009, 1930038526, 2102909123 },
	{ 2143510273,  172073132, 1023337452 },
	{ 2143491841, 1212168134, 1114919776 },
	{ 2143487233, 1779380185, 1831962347 },
	{ 2143480321, 1156632912, 1555759032 },
	{ 2143478017,  622095943,  417269653 },
	{ 2143461889, 1280303071,  153354823 },
	{ 2143431937,  153658480, 1588613191 },
	{ 2143383553,  277427922,   38234351 },
	{ 2143339777,  589784914, 1573224776 },
	{ 2143335169,  922783059,  200661355 },
	{ 2143323649,  302291280, 1138833370 },
	{ 2143277569,  820797102,  854962129 },
	{ 2143213057, 1893415535,  181451477 },
	{ 2143203841, 1088582389,  170356944 },
	{ 2143196929,  291107059,  728824031 },
	{ 2143192321, 1068927089,  373852844 },
	{ 2143187713,  985974306,  668372891 },
	{ 2143173889,  167922091,   50439572 },
	{ 2143130113,  211225918, 1845430847 },
	{ 2143127809,   27582853, 1679634064 },
	{ 2143097857, 1766916709, 1819896188 },
	{ 2143063297,  780824783, 1952357891 },
	{ 2143058689, 1378949832,  756913072 },
	{ 2143051777,  408317329,  443287483 },
	{ 2143047169, 1273910740, 1515393890 },
	{ 2143028737,  996305079,  776734402 },
	{ 2143003393,  993006570, 1390097560 },
	{ 2142996481, 2136513072, 1012671159 },
	{ 2142961921,  891029287,  107949307 },
	{ 2142948097,  844702524,  757623023 },
	{ 2142943489,  783825741,  900340177 },
	{ 2142936577,  674435958,  527289896 },
	{ 2142934273,  823653457,  327447549 },
	{ 2142920449, 1856390383,  273195225 },
	{ 2142911233, 1065735230, 1111511492 },
	{ 2142899713,  852649554, 1319180783 },
	{ 2142897409, 1582470696, 1728311821 },
	{ 2142885889,  875959709, 1969188734 },
	{ 2142851329, 1668580464, 1442501897 },
	{ 2142830593, 1991029339,  713631715 },
	{ 2142807553,   46451453,  209687937 },
	{ 2142786817, 1066849029, 1022563324 },
	{ 2142754561, 1182968060, 1098740072 },
	{ 2142749953,  170870492, 1883579850 },
	{ 2142736129,  885298220,  134381218 },
	{ 2142690049,  257234559,  713466052 },
	{ 2142671617,   16153127,  932308898 },
	{ 2142639361, 1904439789,  232384311 },
	{ 2142623233,  710460071, 1914284724 },
	{ 2142616321, 1384373375, 1948960778 },
	{ 2142614017,  967648016,  687398138 },
	{ 2142579457, 1095246428, 2090495107 },
	{ 2142574849, 1641210381,  638943403 },
	{ 2142556417,  958201775, 1972069612 },
	{ 2142547201,  951709836,  676516709 },
	{ 2142540289, 1374042909,  215502433 },
	{ 2142533377, 1882816694, 2074030459 },
	{ 2142498817, 1504404304, 1972349416 },
	{ 2142471169, 1750000645,  813201047 },
	{ 2142450433,  295533779, 1565446756 },
	{ 2142438913,   10280011,   91646711 },
	{ 2142436609, 1274524844,  162069470 },
	{ 2142429697, 1092732318, 1096144802 },
	{ 2142420481, 1535070609, 1079403268 },
	{ 2142402049, 2005480704,  629779334 },
	{ 2142381313, 2114923039,  648509010 },
	{ 2142379009,  718105805,  536973776 },
	{ 2142374401, 2095587425, 1044147117 },
	{ 2142351361,  439135167, 1502821682 },
	{ 2142349057,  446437191,  530473080 },
	{ 2142323713,  100125463,  992682060 },
	{ 2142316801,  696384453, 1947571491 },
	{ 2142314497, 1453856322, 2001001690 },
	{ 2142277633, 1952977383,  221148682 },
	{ 2142245377, 1644990598, 1408241725 },
	{ 2142229249, 1528562358, 1061142574 },
	{ 2142217729,  510200942, 1943431139 },
	{ 2142208513,  572850506,  958721727 },
	{ 2142178561, 1699015145,  655247881 },
	{ 2142144001,  295258268, 1190693208 },
	{ 2142109441,   13501310, 1444074262 },
	{ 2142097921, 1555745306,  965245540 },
	{ 2142095617,  639823805,  124040022 },
	{ 2142091009,   78431256, 2072711469 },
	{ 2142074881, 1583322983, 1971506113 },
	{ 2142067969, 1985460292,  493290576 },
	{ 2142044929,  964118073, 1818270494 },
	{ 2142040321, 2074619527,   89552074 },
	{ 2142024193,  114755492,  442193256 },
	{ 2142010369, 1379074915, 1941110794 },
	{ 2141932033, 2026935677,  190080015 },
	{ 2141920513,   74333441,  805281961 },
	{ 2141918209, 1775077654,  236453650 },
	{ 2141913601, 1802464945, 1566679036 },
	{ 2141911297,  387494635,  563810545 },
	{ 2141895169, 1172229060, 1528048235 },
	{ 2141890561, 1361767304, 2041867386 },
	{ 2141867521,  533045780,  914774350 },
	{ 2141842177,  437131558,  183042158 },
	{ 2141821441,   39421972, 1331298027 },
	{ 2141814529, 1537989736, 1530178830 },
	{ 2141803009, 1676671105,  515971140 },
	{ 2141791489, 2010187792, 1541172871 },
	{ 2141784577, 1386646410, 1982618979 },
	{ 2141738497,  712677114,   31915251 },
	{ 2141736193, 1274969467,  916301278 },
	{ 2141733889,  116533872, 1715534326 },
	{ 2141694721, 1454976825, 1509954498 },
	{ 2141692417, 1516965569,  642117163 },
	{ 2141671681,  750263061,  316436557 },
	{ 2141669377, 2072414840,  808860641 },
	{ 2141660161,  161141902,  282052692 },
	{ 2141653249, 1463156395,  255786615 },
	{ 2141620993, 1362041953,  229951180 },
	{ 2141591041, 1936223409,  710815623 },
	{ 2141563393, 1302310432, 2126420394 },
	{ 2141542657, 1197316148,    2471210 },
	{ 2141533441, 2086849163, 1253750414 },
	{ 2141526529,  392684861,  291575124 },
	{ 2141475841, 1392668921, 1135731293 },
	{ 2141464321, 1574939096,  682732876 },
	{ 2141450497,  714585706, 2017942072 },
	{ 2141418241, 1697181785, 1091684538 },
	{ 2141406721,  712755841,  661693530 },
	{ 2141404417, 2001939869,   46726158 },
	{ 2141342209,  400626204, 1436047974 },
	{ 2141335297, 1502178162,  413989624 },
	{ 2141332993, 1475685643,  178253589 },
	{ 2141291521,  304189746, 1048860171 },
	{ 2141275393, 2084823014, 1555287725 },
	{ 2141273089, 2119184022,  411567434 },
	{ 2141261569,  178224725,  298057668 },
	{ 2141254657,  677034170, 1139735334 },
	{ 2141238529,  616800485, 1401647061 },
	{ 2141220097,  779544570,  504667947 },
	{ 2141197057,  978744056,  193160486 },
	{ 2141148673, 1163962695, 1287367370 },
	{ 2141137153,  224770889,  980061580 },
	{ 2141123329,  298410621, 1056581872 },
	{ 2141111809,  219751128, 1647153596 },
	{ 2141100289, 1311425207,  724567430 },
	{ 2141088769,  541960942, 1683309546 },
	{ 2141077249, 1907117344, 1956090946 },
	{ 2141044993, 1762133402, 1997717427 },
	{ 2141026561,  929429695, 1693498396 },
	{ 2140980481,  202324091, 1791782539 },
	{ 2140962049,  847752429,  771999167 },
	{ 2140955137,  171581753,  897638410 },
	{ 2140934401, 1561197544, 1785721193 },
	{ 2140927489, 1304799727,  610189109 },
	{ 2140911361,  584407800,  573572391 },
	{ 2140872193,  579572504, 1460985498 },
	{ 2140865281, 2037311399, 1085114600 },
	{ 2140842241, 1464914593,  585074325 },
	{ 2140823809, 1476350636,    6041181 },
	{ 2140814593, 1547025818,  862668427 },
	{ 2140791553,  600414192, 1406967556 },
	{ 2140766209, 1778609535, 1403120148 },
	{ 2140733953, 1320658482, 1879929384 },
	{ 2140713217, 1129185878, 1667839994 },
	{ 2140701697,  296171658, 1309665658 },
	{ 2140664833,  399603307, 1473037276 },
	{ 2140627969, 2072761417,  860933793 },
	{ 2140561153,  859021277, 1227879163 },
	{ 2140547329, 1716541026, 1290146230 },
	{ 2140542721, 1194859500, 1797753332 },
	{ 2140535809,  167714346, 1162981484 },
	{ 2140503553,  370984759,   46309386 },
	{ 2140494337, 1328986356, 1606498728 },
	{ 2140480513,   38230879, 2034344207 },
	{ 2140466689, 1806259424,  362621291 },
	{ 2140427521,  814658758,  825681996 },
	{ 2140404481, 1123614881,  456597404 },
	{ 2140399873, 1573999347, 2109157497 },
	{ 2140365313,  972962485, 1511091337 },
	{ 2140351489,  862138970, 1385361132 },
	{ 2140323841,  925446313,  315386822 },
	{ 2140316929,  327600537, 1432209372 },
	{ 2140300801,  206223333, 1824969389 },
	{ 2140284673,  154825255,  625926281 },
	{ 2140275457, 1268521276, 1039783122 },
	{ 2140270849, 1930935020, 2093846199 },
	{ 2140250113,  293408394,  446043725 },
	{ 2140236289, 1210426371,  927336002 },
	{ 2140224769,  132901891,  584957812 },
	{ 2140220161,  940671602, 1748241255 },
	{ 2140208641,  337534060, 1014808439 },
	{ 2140206337,  707821818,  736128861 },
	{ 2140197121, 1276000052, 1233695606 },
	{ 2140192513, 1586736300, 1734440244 },
	{ 2140185601,  823807555,  861050097 },
	{ 2140171777,  706329492, 1082375865 },
	{ 2140116481, 1812454795, 1369401687 },
	{ 2140104961,  264127389, 1819984006 },
	{ 2140098049, 1965766156,  383515743 },
	{ 2140047361, 1960123302, 1042763142 },
	{ 2140042753, 1687337635,  420287792 },
	{ 2140031233, 1366749250, 1532940500 },
	{ 2139987457, 1912737167, 1404131659 },
	{ 2139964417,  693333303,  177486658 },
	{ 2139952897,  495455314, 1274422832 },
	{ 2139948289,   40363916,  943432746 },
	{ 2139927553,  444424273, 1207981519 },
	{ 2139902209, 1465807360,   92415256 },
	{ 2139872257, 1837154584,  909402842 },
	{ 2139867649,   75059817,  804803785 },
	{ 2139826177, 2015221154,  881164323 },
	{ 2139814657, 1148432315, 1578970409 },
	{ 2139800833, 2088034106,  933005359 },
	{ 2139789313, 1861311437,  177956065 },
	{ 2139770881,  363514308,   25637872 },
	{ 2139766273, 2070991768, 1557275280 },
	{ 2139713281, 1604789895, 1788183740 },
	{ 2139708673, 1845339933,  609946729 },
	{ 2139701761, 1430546144, 1989106525 },
	{ 2139676417,  605392937,  970641834 },
	{ 2139641857, 1165076318,  835985127 },
	{ 2139616513,  283116094,  667711089 },
	{ 2139614209,  646890502, 1209456877 },
	{ 2139598081,  449743376,  718517127 },
	{ 2139593473,  497145855,  394220435 },
	{ 2139572737,  955015696,  294304456 },
	{ 2139568129,  401133955, 1091472607 },
	{ 2139563521, 1735308269, 1691190275 },
	{ 2139556609, 1826473043, 1043649467 },
	{ 2139549697, 1908832672,  377280535 },
	{ 2139535873, 1241741506,  651921754 },
	{ 2139524353, 1923937400, 1353981614 },
	{ 2139492097,  285331406,  802398974 },
	{ 2139475969,  576196150,  429222684 },
	{ 2139466753, 1780761618,  296308885 },
	{ 2139459841,  611500689, 1213639654 },
	{ 2139434497,  148656389, 1051625014 },
	{ 2139413761,  391073297, 2081064242 },
	{ 2139399937, 1065174985,  787712624 },
	{ 2139383809,  788093248, 1111802639 },
	{ 2139356161,  336361251,  319889191 },
	{ 2139333121,  884166060,  509405995 },
	{ 2139321601, 1513473632, 1940111538 },
	{ 2139310081,  900672962, 2071072080 },
	{ 2139303169, 1991620918,  543628217 },
	{ 2139287041,  370425359, 1047050467 },
	{ 2139275521,  713658400, 1797885684 },
	{ 2139268609, 1783527316,  874491612 },
	{ 2139261697,  631837513, 1395044429 },
	{ 2139259393, 1742874935,  508544171 },
	{ 2139252481,  463463038,  737489950 },
	{ 2139204097,  538698195,  604942560 },
	{ 2139201793, 1435754599,   54362978 },
	{ 2139169537, 2012388705,  392083310 },
	{ 2139144193, 1155362435, 1319368247 },
	{ 2139137281,  921952177,   92928882 },
	{ 2139123457, 1506351550,  602798069 },
	{ 2139109633, 1527038848,   48844022 },
	{ 2139095809, 2071318942, 1524340004 },
	{ 2139075073, 1165123429, 1717466457 },
	{ 2139056641, 1776112510,  286710183 },
	{ 2139033601,  980780564, 2116611843 },
	{ 2139028993, 1474450200, 1742934604 },
	{ 2138976001,  428486407, 1580417049 },
	{ 2138969089, 1396721654, 1511256767 },
	{ 2138950657, 1516054630, 2071630098 },
	{ 2138939137, 1078360116,  691835055 },
	{ 2138927617,  425837073,  756872582 },
	{ 2138918401, 1641039620, 1734207081 },
	{ 2138916097, 1017601848, 1142652819 },
	{ 2138913793,  306828523,  191212034 },
	{ 2138904577, 1745075919, 1122876435 },
	{ 2138888449, 1503947447,  951342509 },
	{ 2138837761, 1210620672,  957215442 },
	{ 2138833153,  787109305,  412518979 },
	{ 2138823937,   44637017,  408073095 },
	{ 2138775553,  199446608,  907722635 },
	{ 2138757121, 2081488043, 1042423315 },
	{ 2138738689, 1497686426, 2084550241 },
	{ 2138729473,  608998372, 1206782464 },
	{ 2138717953,  539269185, 2044657934 },
	{ 2138681089,  268630505, 1615466641 },
	{ 2138660353,  582047226,  449049076 },
	{ 2138648833,  926857321, 1056946200 },
	{ 2138639617,  195695324, 2012033442 },
	{ 2138616577, 2068544160, 1896897903 },
	{ 2138605057, 1751671600,  614364881 },
	{ 2138600449,  478123986,  288140368 },
	{ 2138591233,  783785615,  851589578 },
	{ 0, 0, 0 }
};

/*
 * Reduce a small signed integer modulo a small prime. The source
 * value x MUST be such that -p < x < p.
 */
static inline uint32_t
modp_set(int32_t x, uint32_t p)
{
	uint32_t w;

	w = (uint32_t)x;
	w += p & -(w >> 31);
	return w;
}

/*
 * Normalize a modular integer around 0.
 */
static inline int32_t
modp_norm(uint32_t x, uint32_t p)
{
	return x - (p & (((x - ((p + 1) >> 1)) >> 31) - 1));
}

/*
 * Compute -1/p mod 2^31. This works for all odd integers p that fit
 * on 32 bits.
 */
static uint32_t
modp_ninv31(uint32_t p)
{
	uint32_t y;

	y = 2 - p;
	y *= 2 - p * y;
	y *= 2 - p * y;
	y *= 2 - p * y;
	y *= 2 - p * y;
	return (uint32_t)0x7FFFFFFF & -y;
}

/*
 * Compute R = 2^31 mod p.
 */
static inline uint32_t
modp_R(uint32_t p)
{
	/*
	 * Since 2^30 < p < 2^31, we know that 2^31 mod p is simply
	 * 2^31 - p.
	 */
	return ((uint32_t)1 << 31) - p;
}

/*
 * Addition modulo p.
 */
static inline uint32_t
modp_add(uint32_t a, uint32_t b, uint32_t p)
{
	uint32_t d;

	d = a + b - p;
	d += p & -(d >> 31);
	return d;
}

/*
 * Subtraction modulo p.
 */
static inline uint32_t
modp_sub(uint32_t a, uint32_t b, uint32_t p)
{
	uint32_t d;

	d = a - b;
	d += p & -(d >> 31);
	return d;
}

/*
 * Halving modulo p.
 */
static inline uint32_t
modp_half(uint32_t a, uint32_t p)
{
	a += p & -(a & 1);
	return a >> 1;
}

/*
 * Montgomery multiplication modulo p. The 'p0i' value is -1/p mod 2^31.
 * It is required that p is an odd integer.
 */
static inline uint32_t
modp_montymul(uint32_t a, uint32_t b, uint32_t p, uint32_t p0i)
{
	uint64_t z, w;
	uint32_t d;

	z = (uint64_t)a * (uint64_t)b;
	w = ((z * p0i) & (uint64_t)0x7FFFFFFF) * p;
	d = (uint32_t)((z + w) >> 31) - p;
	d += p & -(d >> 31);
	return d;
}

/*
 * Compute R2 = 2^62 mod p.
 */
static uint32_t
modp_R2(uint32_t p, uint32_t p0i)
{
	uint32_t z;

	/*
	 * Compute z = 2^31 mod p (this is the value 1 in Montgomery
	 * representation), then double it with an addition.
	 */
	z = modp_R(p);
	z = modp_add(z, z, p);

	/*
	 * Square it five times to obtain 2^32 in Montgomery representation
	 * (i.e. 2^63 mod p).
	 */
	z = modp_montymul(z, z, p, p0i);
	z = modp_montymul(z, z, p, p0i);
	z = modp_montymul(z, z, p, p0i);
	z = modp_montymul(z, z, p, p0i);
	z = modp_montymul(z, z, p, p0i);

	/*
	 * Halve the value mod p to get 2^62.
	 */
	z = (z + (p & -(z & 1))) >> 1;
	return z;
}

/*
 * Compute 2^(31*x) modulo p. This works for integers x up to 2^11.
 * p must be prime such that 2^30 < p < 2^31; p0i must be equal to
 * -1/p mod 2^31.
 */
static inline uint32_t
modp_Rx(unsigned x, uint32_t p, uint32_t p0i, uint32_t R2)
{
	int i;
	uint32_t r, z;

	/*
	 * 2^(31*x) = (2^31)*(2^(31*(x-1))); i.e. we want the Montgomery
	 * representation of (2^31)^e mod p, where e = x-1.
	 * R2 is 2^31 in Montgomery representation.
	 */
	x --;
	r = R2;
	z = modp_R(p);
	for (i = 0; (1U << i) <= x; i ++) {
		if ((x & (1U << i)) != 0) {
			z = modp_montymul(z, r, p, p0i);
		}
		r = modp_montymul(r, r, p, p0i);
	}
	return z;
}

/*
 * Division modulo p. If the divisor (b) is 0, then 0 is returned.
 * This function computes proper results only when p is prime.
 * Parameters:
 *   a     dividend
 *   b     divisor
 *   p     odd prime modulus
 *   p0i   -1/p mod 2^31
 *   R     2^31 mod R
 */
static uint32_t
modp_div(uint32_t a, uint32_t b, uint32_t p, uint32_t p0i, uint32_t R)
{
	uint32_t z, e;
	int i;

	e = p - 2;
	z = R;
	for (i = 30; i >= 0; i --) {
		uint32_t z2;

		z = modp_montymul(z, z, p, p0i);
		z2 = modp_montymul(z, b, p, p0i);
		z ^= (z ^ z2) & -(uint32_t)((e >> i) & 1);
	}

	/*
	 * The loop above just assumed that b was in Montgomery
	 * representation, i.e. really contained b*R; under that
	 * assumption, it returns 1/b in Montgomery representation,
	 * which is R/b. But we gave it b in normal representation,
	 * so the loop really returned R/(b/R) = R^2/b.
	 *
	 * We want a/b, so we need one Montgomery multiplication with a,
	 * which also remove one of the R factors, and another such
	 * multiplication to remove the second R factor.
	 */
	z = modp_montymul(z, 1, p, p0i);
	return modp_montymul(a, z, p, p0i);
}

/*
 * Bit-reversal index table.
 */
static const uint16_t REV10[] = {
	   0,  512,  256,  768,  128,  640,  384,  896,   64,  576,  320,  832,
	 192,  704,  448,  960,   32,  544,  288,  800,  160,  672,  416,  928,
	  96,  608,  352,  864,  224,  736,  480,  992,   16,  528,  272,  784,
	 144,  656,  400,  912,   80,  592,  336,  848,  208,  720,  464,  976,
	  48,  560,  304,  816,  176,  688,  432,  944,  112,  624,  368,  880,
	 240,  752,  496, 1008,    8,  520,  264,  776,  136,  648,  392,  904,
	  72,  584,  328,  840,  200,  712,  456,  968,   40,  552,  296,  808,
	 168,  680,  424,  936,  104,  616,  360,  872,  232,  744,  488, 1000,
	  24,  536,  280,  792,  152,  664,  408,  920,   88,  600,  344,  856,
	 216,  728,  472,  984,   56,  568,  312,  824,  184,  696,  440,  952,
	 120,  632,  376,  888,  248,  760,  504, 1016,    4,  516,  260,  772,
	 132,  644,  388,  900,   68,  580,  324,  836,  196,  708,  452,  964,
	  36,  548,  292,  804,  164,  676,  420,  932,  100,  612,  356,  868,
	 228,  740,  484,  996,   20,  532,  276,  788,  148,  660,  404,  916,
	  84,  596,  340,  852,  212,  724,  468,  980,   52,  564,  308,  820,
	 180,  692,  436,  948,  116,  628,  372,  884,  244,  756,  500, 1012,
	  12,  524,  268,  780,  140,  652,  396,  908,   76,  588,  332,  844,
	 204,  716,  460,  972,   44,  556,  300,  812,  172,  684,  428,  940,
	 108,  620,  364,  876,  236,  748,  492, 1004,   28,  540,  284,  796,
	 156,  668,  412,  924,   92,  604,  348,  860,  220,  732,  476,  988,
	  60,  572,  316,  828,  188,  700,  444,  956,  124,  636,  380,  892,
	 252,  764,  508, 1020,    2,  514,  258,  770,  130,  642,  386,  898,
	  66,  578,  322,  834,  194,  706,  450,  962,   34,  546,  290,  802,
	 162,  674,  418,  930,   98,  610,  354,  866,  226,  738,  482,  994,
	  18,  530,  274,  786,  146,  658,  402,  914,   82,  594,  338,  850,
	 210,  722,  466,  978,   50,  562,  306,  818,  178,  690,  434,  946,
	 114,  626,  370,  882,  242,  754,  498, 1010,   10,  522,  266,  778,
	 138,  650,  394,  906,   74,  586,  330,  842,  202,  714,  458,  970,
	  42,  554,  298,  810,  170,  682,  426,  938,  106,  618,  362,  874,
	 234,  746,  490, 1002,   26,  538,  282,  794,  154,  666,  410,  922,
	  90,  602,  346,  858,  218,  730,  474,  986,   58,  570,  314,  826,
	 186,  698,  442,  954,  122,  634,  378,  890,  250,  762,  506, 1018,
	   6,  518,  262,  774,  134,  646,  390,  902,   70,  582,  326,  838,
	 198,  710,  454,  966,   38,  550,  294,  806,  166,  678,  422,  934,
	 102,  614,  358,  870,  230,  742,  486,  998,   22,  534,  278,  790,
	 150,  662,  406,  918,   86,  598,  342,  854,  214,  726,  470,  982,
	  54,  566,  310,  822,  182,  694,  438,  950,  118,  630,  374,  886,
	 246,  758,  502, 1014,   14,  526,  270,  782,  142,  654,  398,  910,
	  78,  590,  334,  846,  206,  718,  462,  974,   46,  558,  302,  814,
	 174,  686,  430,  942,  110,  622,  366,  878,  238,  750,  494, 1006,
	  30,  542,  286,  798,  158,  670,  414,  926,   94,  606,  350,  862,
	 222,  734,  478,  990,   62,  574,  318,  830,  190,  702,  446,  958,
	 126,  638,  382,  894,  254,  766,  510, 1022,    1,  513,  257,  769,
	 129,  641,  385,  897,   65,  577,  321,  833,  193,  705,  449,  961,
	  33,  545,  289,  801,  161,  673,  417,  929,   97,  609,  353,  865,
	 225,  737,  481,  993,   17,  529,  273,  785,  145,  657,  401,  913,
	  81,  593,  337,  849,  209,  721,  465,  977,   49,  561,  305,  817,
	 177,  689,  433,  945,  113,  625,  369,  881,  241,  753,  497, 1009,
	   9,  521,  265,  777,  137,  649,  393,  905,   73,  585,  329,  841,
	 201,  713,  457,  969,   41,  553,  297,  809,  169,  681,  425,  937,
	 105,  617,  361,  873,  233,  745,  489, 1001,   25,  537,  281,  793,
	 153,  665,  409,  921,   89,  601,  345,  857,  217,  729,  473,  985,
	  57,  569,  313,  825,  185,  697,  441,  953,  121,  633,  377,  889,
	 249,  761,  505, 1017,    5,  517,  261,  773,  133,  645,  389,  901,
	  69,  581,  325,  837,  197,  709,  453,  965,   37,  549,  293,  805,
	 165,  677,  421,  933,  101,  613,  357,  869,  229,  741,  485,  997,
	  21,  533,  277,  789,  149,  661,  405,  917,   85,  597,  341,  853,
	 213,  725,  469,  981,   53,  565,  309,  821,  181,  693,  437,  949,
	 117,  629,  373,  885,  245,  757,  501, 1013,   13,  525,  269,  781,
	 141,  653,  397,  909,   77,  589,  333,  845,  205,  717,  461,  973,
	  45,  557,  301,  813,  173,  685,  429,  941,  109,  621,  365,  877,
	 237,  749,  493, 1005,   29,  541,  285,  797,  157,  669,  413,  925,
	  93,  605,  349,  861,  221,  733,  477,  989,   61,  573,  317,  829,
	 189,  701,  445,  957,  125,  637,  381,  893,  253,  765,  509, 1021,
	   3,  515,  259,  771,  131,  643,  387,  899,   67,  579,  323,  835,
	 195,  707,  451,  963,   35,  547,  291,  803,  163,  675,  419,  931,
	  99,  611,  355,  867,  227,  739,  483,  995,   19,  531,  275,  787,
	 147,  659,  403,  915,   83,  595,  339,  851,  211,  723,  467,  979,
	  51,  563,  307,  819,  179,  691,  435,  947,  115,  627,  371,  883,
	 243,  755,  499, 1011,   11,  523,  267,  779,  139,  651,  395,  907,
	  75,  587,  331,  843,  203,  715,  459,  971,   43,  555,  299,  811,
	 171,  683,  427,  939,  107,  619,  363,  875,  235,  747,  491, 1003,
	  27,  539,  283,  795,  155,  667,  411,  923,   91,  603,  347,  859,
	 219,  731,  475,  987,   59,  571,  315,  827,  187,  699,  443,  955,
	 123,  635,  379,  891,  251,  763,  507, 1019,    7,  519,  263,  775,
	 135,  647,  391,  903,   71,  583,  327,  839,  199,  711,  455,  967,
	  39,  551,  295,  807,  167,  679,  423,  935,  103,  615,  359,  871,
	 231,  743,  487,  999,   23,  535,  279,  791,  151,  663,  407,  919,
	  87,  599,  343,  855,  215,  727,  471,  983,   55,  567,  311,  823,
	 183,  695,  439,  951,  119,  631,  375,  887,  247,  759,  503, 1015,
	  15,  527,  271,  783,  143,  655,  399,  911,   79,  591,  335,  847,
	 207,  719,  463,  975,   47,  559,  303,  815,  175,  687,  431,  943,
	 111,  623,  367,  879,  239,  751,  495, 1007,   31,  543,  287,  799,
	 159,  671,  415,  927,   95,  607,  351,  863,  223,  735,  479,  991,
	  63,  575,  319,  831,  191,  703,  447,  959,  127,  639,  383,  895,
	 255,  767,  511, 1023
};

/*
 * Compute the roots for NTT and inverse NTT (binary case). Input
 * parameter g is a primitive 2048-th root of 1 modulo p (i.e. g^1024 =
 * -1 mod p). This fills gm[] and igm[] with powers of g and 1/g:
 *   gm[rev(i)] = g^i mod p
 *   igm[rev(i)] = (1/g)^i mod p
 * where rev() is the "bit reversal" function over 10 bits. It fills
 * the arrays only up to N = 2^logn values.
 *
 * The values stored in gm[] and igm[] are in Montgomery representation.
 *
 * p must be a prime such that p = 1 mod 2048.
 */
static void
modp_mkgm2(uint32_t *restrict gm, uint32_t *restrict igm, unsigned logn,
	uint32_t g, uint32_t p, uint32_t p0i)
{
	size_t u, n;
	unsigned k;
	uint32_t ig, x1, x2, R2;

	n = (size_t)1 << logn;

	/*
	 * We want g such that g^(2N) = 1 mod p, but the provided
	 * generator has order 2048. We must square it a few times.
	 */
	R2 = modp_R2(p, p0i);
	g = modp_montymul(g, R2, p, p0i);
	for (k = logn; k < 10; k ++) {
		g = modp_montymul(g, g, p, p0i);
	}

	ig = modp_div(R2, g, p, p0i, modp_R(p));
	k = 10 - logn;
	x1 = x2 = modp_R(p);
	for (u = 0; u < n; u ++) {
		size_t v;

		v = REV10[u << k];
		gm[v] = x1;
		igm[v] = x2;
		x1 = modp_montymul(x1, g, p, p0i);
		x2 = modp_montymul(x2, ig, p, p0i);
	}
}

/*
 * Compute the NTT over a polynomial (binary case). Polynomial elements
 * are a[0], a[stride], a[2 * stride]...
 */
static void
modp_NTT2_ext(uint32_t *a, size_t stride, const uint32_t *gm, unsigned logn,
	uint32_t p, uint32_t p0i)
{
	size_t t, m, n;

	if (logn == 0) {
		return;
	}
	n = (size_t)1 << logn;
	t = n;
	for (m = 1; m < n; m <<= 1) {
		size_t ht, u, v1;

		ht = t >> 1;
		for (u = 0, v1 = 0; u < m; u ++, v1 += t) {
			uint32_t s;
			size_t v;
			uint32_t *r1, *r2;

			s = gm[m + u];
			r1 = a + v1 * stride;
			r2 = r1 + ht * stride;
			for (v = 0; v < ht; v ++, r1 += stride, r2 += stride) {
				uint32_t x, y;

				x = *r1;
				y = modp_montymul(*r2, s, p, p0i);
				*r1 = modp_add(x, y, p);
				*r2 = modp_sub(x, y, p);
			}
		}
		t = ht;
	}
}

/*
 * Compute the inverse NTT over a polynomial (binary case).
 */
static void
modp_iNTT2_ext(uint32_t *a, size_t stride, const uint32_t *igm, unsigned logn,
	uint32_t p, uint32_t p0i)
{
	size_t t, m, n, k;
	uint32_t ni;
	uint32_t *r;

	if (logn == 0) {
		return;
	}
	n = (size_t)1 << logn;
	t = 1;
	for (m = n; m > 1; m >>= 1) {
		size_t hm, dt, u, v1;

		hm = m >> 1;
		dt = t << 1;
		for (u = 0, v1 = 0; u < hm; u ++, v1 += dt) {
			uint32_t s;
			size_t v;
			uint32_t *r1, *r2;

			s = igm[hm + u];
			r1 = a + v1 * stride;
			r2 = r1 + t * stride;
			for (v = 0; v < t; v ++, r1 += stride, r2 += stride) {
				uint32_t x, y;

				x = *r1;
				y = *r2;
				*r1 = modp_add(x, y, p);
				*r2 = modp_montymul(
					modp_sub(x, y, p), s, p, p0i);;
			}
		}
		t = dt;
	}

	/*
	 * We need 1/n in Montgomery representation, i.e. R/n. Since
	 * 1 <= logn <= 10, R/n is an integer; morever, R/n <= 2^30 < p,
	 * thus a simple shift will do.
	 * a modular reduction.
	 */
	ni = (uint32_t)1 << (31 - logn);
	for (k = 0, r = a; k < n; k ++, r += stride) {
		*r = modp_montymul(*r, ni, p, p0i);
	}
}

/*
 * Simplified macros for NTT and iNTT (binary case) when the elements
 * are consecutive in RAM.
 */
#define modp_NTT2(a, gm, logn, p, p0i)   modp_NTT2_ext(a, 1, gm, logn, p, p0i)
#define modp_iNTT2(a, igm, logn, p, p0i) modp_iNTT2_ext(a, 1, igm, logn, p, p0i)

/*
 * Compute the roots for NTT and inverse NTT (ternary case).
 *
 * Degree is 1.5*2^logn if 'full' is 1; otherwise, 'full' is 0 and the
 * degree is 2^logn.
 *
 * Input parameter g is a primitive 2304-th root of 1 modulo p (i.e.
 * g^1152 = -1 mod p).
 *
 * In the full case, for n = 768:
 *
 *  - Tables gm[] and igm[] have size 512 entries each.
 *
 *  - gm[256..511] contains the values g^k for k = 1 or 5 mod 6 and
 *    k < 768.
 *
 *  - For 1 <= j < 256, gm[j] contains the square of gm[2*j].
 *
 *  - gm[0] is a copy of gm[1].
 *
 *  - For j >= 1, igm[j] is the inverse of gm[j].
 *
 *  - igm[0] is the inverse of 2*gm[1]-1.
 *
 * For smaller degrees, everything is scaled down accordingly, and g
 * is repeatedly squared.
 *
 * In the partial case, tables gm[] and igm[] have size 2^logn, and
 * are the prefixes of the table for the full case for logn+1.
 */
static void
modp_mkgm3(uint32_t *restrict gm, uint32_t *restrict igm,
	unsigned logn, unsigned full,
	uint32_t g, uint32_t p, uint32_t p0i)
{
	size_t u;
	unsigned k;
	uint32_t R, R2, w, ig;

	R = modp_R(p);
	R2 = modp_R2(p, p0i);

	/*
	 * Square g as needed for the requested degree, and convert it
	 * to Montgomery representation. Also set ig = 1/g, also in
	 * Montgomery representation.
	 */
	g = modp_montymul(g, R2, p, p0i);
	k = logn;
	if (!full) {
		g = modp_montymul(g, modp_montymul(g, g, p, p0i), p, p0i);
		k ++;
	}
	while (k ++ < 9) {
		g = modp_montymul(g, g, p, p0i);
	}
	ig = modp_div(R2, g, p, p0i, modp_R(p));

	/*
	 * Fill the last row, using bit-reversal order.
	 */
	if (logn == 1) {
		gm[1] = g;
		igm[1] = ig;
	} else {
		uint32_t x, ix, g2, g4, ig2, ig4;
		size_t b;

		x = g;
		ix = ig;
		g2 = modp_montymul(g, g, p, p0i);
		g4 = modp_montymul(g2, g2, p, p0i);
		ig2 = modp_montymul(ig, ig, p, p0i);
		ig4 = modp_montymul(ig2, ig2, p, p0i);
		k = 11 - logn;
		b = (size_t)1 << (logn - 1);
		for (u = 0; u < b; u += 2) {
			gm[b + REV10[u << k]] = x;
			igm[b + REV10[u << k]] = ix;
			x = modp_montymul(x, g4, p, p0i);
			ix = modp_montymul(ix, ig4, p, p0i);
			gm[b + REV10[(u + 1) << k]] = x;
			igm[b + REV10[(u + 1) << k]] = ix;
			x = modp_montymul(x, g2, p, p0i);
			ix = modp_montymul(ix, ig2, p, p0i);
		}
	}

	/*
	 * If the table is full, then the next-to-last row contains the
	 * cubes of the last row.
	 */
	k = logn - 1;
	if (full) {
		k --;
		for (u = (size_t)1 << k; u < ((size_t)1 << (k + 1)); u ++) {
			uint32_t y, z;

			y = gm[u << 1];
			z = igm[u << 1];
			y = modp_montymul(y,
				modp_montymul(y, y, p, p0i), p, p0i);
			z = modp_montymul(z,
				modp_montymul(z, z, p, p0i), p, p0i);
			gm[u] = y;
			igm[u] = z;
		}
	}

	/*
	 * Fill other rows, with squares of the next one.
	 */
	for (u = ((size_t)1 << k) - 1; u > 0; u --) {
		size_t v;

		v = u << 1;
		gm[u] = modp_montymul(gm[v], gm[v], p, p0i);
		igm[u] = modp_montymul(igm[v], igm[v], p, p0i);
	}

	/*
	 * Comute top elements.
	 */
	gm[0] = gm[1];
	w = gm[1];
	igm[0] = modp_div(R2, modp_sub(modp_add(w, w, p), R, p), p, p0i, R);
}

/*
 * Compute the NTT over a polynomial (ternary case). If full is 1, then
 * the degree 1.5*2^logn; otherwise, the degree is 2^logn.
 */
static void
modp_NTT3_ext(uint32_t *a, size_t stride, const uint32_t *gm,
	unsigned logn, unsigned full, uint32_t p, uint32_t p0i)
{
	size_t n, hn, u, r, m, t;
	uint32_t w;
	uint32_t *r1, *r2;

	if (logn == 0) {
		return;
	}
	n = MKN(logn, full);
	hn = n >> 1;

	/*
	 * First pass: NTT over individual degree-1 polynomials modulo
	 * X^2-X+1. Roots are w (such that w != -1, and w^3 = -1) and w^5.
	 * Note that w^2 - w + 1 = 0, thus:
	 *
	 *  a(w) = a0 + a1*w
	 *  a(w^5) = a(-w^2)
	 *         = a0 + a1*(-w + 1)
	 *         = a0 + a1 - a1*w
	 */
	w = gm[1];
	for (u = 0, r1 = a, r2 = a + hn * stride;
		u < hn; u ++, r1 += stride, r2 += stride)
	{
		uint32_t a0, a1, b;

		a0 = *r1;
		a1 = *r2;
		b = modp_montymul(a1, w, p, p0i);
		*r1 = modp_add(a0, b, p);
		*r2 = modp_sub(modp_add(a0, a1, p), b, p);
	}

	/*
	 * Intermediate passes, for doubling the degree repeatedly.
	 */
	t = hn;
	for (m = 2; t > (1 + (full << 1)); m <<= 1) {
		size_t ht, u1, v1;

		ht = t >> 1;
		for (u1 = 0, v1 = 0; u1 < m; u1 ++, v1 += t) {
			size_t v;
			uint32_t s;

			s = gm[m + u1];
			r1 = a + v1 * stride;
			r2 = r1 + ht * stride;
			for (v = 0; v < ht; v ++, r1 += stride, r2 += stride) {
				uint32_t x, y;

				x = *r1;
				y = *r2;
				y = modp_montymul(y, s, p, p0i);
				*r1 = modp_add(x, y, p);
				*r2 = modp_sub(x, y, p);
			}
		}
		t = ht;
	}

	/*
	 * Final pass, to triple the degree.
	 */
	if (full) {
		w = modp_montymul(gm[1], gm[1], p, p0i);
		for (u = 0, r = (size_t)1 << (logn - 1), r1 = a;
			u < n; u += 3, r ++, r1 += 3 * stride)
		{
			uint32_t fA, fB, fC, fB0, fB1, fB2, fC0, fC1, fC2;
			uint32_t x, x2;

			x = gm[r];
			x2 = modp_montymul(x, x, p, p0i);
			fA = *r1;
			fB = *(r1 + stride);
			fC = *(r1 + 2 * stride);
			fB0 = modp_montymul(fB, x, p, p0i);
			fB1 = modp_montymul(fB0, w, p, p0i);
			fB2 = modp_montymul(fB1, w, p, p0i);
			fC0 = modp_montymul(fC, x2, p, p0i);
			fC1 = modp_montymul(fC0, w, p, p0i);
			fC2 = modp_montymul(fC1, w, p, p0i);
			*r1 = modp_add(fA,
				modp_add(fB0, fC0, p), p);
			*(r1 + stride) = modp_add(fA,
				modp_add(fB1, fC2, p), p);
			*(r1 + 2 * stride) = modp_add(fA,
				modp_add(fB2, fC1, p), p);
		}
	}
}

/*
 * Compute the inverse NTT over a polynomial (ternary case). If full is
 * 1, then the degree 1.5*2^logn; otherwise, the degree is 2^logn.
 */
static void
modp_iNTT3_ext(uint32_t *a, size_t stride, const uint32_t *igm,
	unsigned logn, unsigned full, uint32_t p, uint32_t p0i)
{
	size_t n, hn, u, r, m, t;
	uint32_t w, ni, R, *r1, *r2;

	if (logn == 0) {
		return;
	}
	n = MKN(logn, full);
	hn = n >> 1;

	/*
	 * Steps here correspond to the steps in modp_NTT3_ext(), in
	 * reverse order. However, computations leave a cumulative
	 * multiplicative factor, that must be cancelled out at the end.
	 */

	/*
	 * Divide degree by 3.
	 */
	if (full) {
		w = modp_montymul(igm[1], igm[1], p, p0i);
		for (u = 0, r = (size_t)1 << (logn - 1), r1 = a;
			u < n; u += 3, r ++, r1 += 3 * stride)
		{
			uint32_t f0, f1, f2, f11, f12, f21, f22;
			uint32_t x, x2;

			x = igm[r];
			x2 = modp_montymul(x, x, p, p0i);
			f0 = *r1;
			f1 = *(r1 + stride);
			f2 = *(r1 + 2 * stride);
			f11 = modp_montymul(f1, w, p, p0i);
			f12 = modp_montymul(f11, w, p, p0i);
			f21 = modp_montymul(f2, w, p, p0i);
			f22 = modp_montymul(f21, w, p, p0i);
			*r1 = modp_add(f0, modp_add(f1, f2, p), p);
			*(r1 + stride) = modp_montymul(x,
				modp_add(f0, modp_add(f11, f22, p), p), p, p0i);
			*(r1 + 2 * stride) = modp_montymul(x2,
				modp_add(f0, modp_add(f12, f21, p), p), p, p0i);
		}
	}

	/*
	 * Intermediate steps. The 't' and 'm' values have the same
	 * semantics as in NTT3, except that they are processed in
	 * reverse order. Note the invariant: t*m = n.
	 */
	t = 2 + (full << 2);
	for (m = (size_t)1 << (logn - 1 - full); t < n; m >>= 1) {
		size_t ht, u1, v1;

		ht = t >> 1;
		for (u1 = 0, v1 = 0; u1 < m; u1 ++, v1 += t) {
			size_t v;
			uint32_t s;

			s = igm[m + u1];
			r1 = a + v1 * stride;
			r2 = r1 + ht * stride;
			for (v = 0; v < ht; v ++, r1 += stride, r2 += stride) {
				uint32_t x, y;

				x = *r1;
				y = *r2;
				*r1 = modp_add(x, y, p);
				*r2 = modp_montymul(
					modp_sub(x, y, p), s, p, p0i);
			}
		}
		t <<= 1;
	}

	/*
	 * Final step: inverse NTT for polynomials modulo X^2-X+1.
	 */
	w = igm[0];
	for (u = 0, r1 = a, r2 = a + hn * stride;
		u < hn; u ++, r1 += stride, r2 += stride)
	{
		uint32_t a0, a1, b, c;

		a0 = *r1;
		a1 = *r2;
		b = modp_add(a0, a1, p);
		c = modp_montymul(w, modp_sub(a0, a1, p), p, p0i);
		*r1 = modp_sub(b, c, p);
		*r2 = modp_add(c, c, p);
	}

	/*
	 * Corrective factor: all values must be divided by n.
	 */
	R = modp_R(p);
	ni = modp_div(R, (uint32_t)n, p, p0i, R);
	for (u = 0, r1 = a; u < n; u ++, r1 += stride) {
		*r1 = modp_montymul(*r1, ni, p, p0i);
	}
}

/*
 * Simplified macros for NTT and iNTT (ternary case) when the elements
 * are consecutive in RAM.
 */
#define modp_NTT3(a, gm, logn, full, p, p0i) \
	modp_NTT3_ext(a, 1, gm, logn, full, p, p0i)
#define modp_iNTT3(a, igm, logn, full, p, p0i) \
	modp_iNTT3_ext(a, 1, igm, logn, full, p, p0i)

/*
 * Given polynomial f in NTT representation modulo p, compute f' of degree
 * less than N/2 such that f' = f0^2 - X*f1^2, where f0 and f1 are
 * polynomials of degree less than N/2 such that f = f0(X^2) + X*f1(X^2).
 *
 * The new polynomial is written "in place" over the first N/2 elements
 * of f.
 *
 * If applied logn times successively on a given polynomial, the resulting
 * degree-0 polynomial is the resultant of f and X^N+1 modulo p.
 *
 * This function applies only to the binary case; it is invoked from
 * solve_NTRU_binary_depth1().
 */
static void
modp_poly_rec_res(uint32_t *f, unsigned logn,
	uint32_t p, uint32_t p0i, uint32_t R2)
{
	size_t hn, u;

	hn = (size_t)1 << (logn - 1);
	for (u = 0; u < hn; u ++) {
		uint32_t w0, w1;

		w0 = f[(u << 1) + 0];
		w1 = f[(u << 1) + 1];
		f[u] = modp_montymul(modp_montymul(w0, w1, p, p0i), R2, p, p0i);
	}
}

/* ==================================================================== */
/*
 * Custom bignum implementation.
 *
 * This is a very reduced set of functionalities. We need to do the
 * following operations:
 *
 *  - Rebuild the resultant and the polynomial coefficients from their
 *    values modulo small primes (of length 31 bits each).
 *
 *  - Compute an extended GCD between the two computed resultants.
 *
 *  - Extract top bits and add scaled values during the successive steps
 *    of Babai rounding.
 *
 * When rebuilding values using CRT, we must also recompute the product
 * of the small prime factors. We always do it one small factor at a
 * time, so the "complicated" operations can be done modulo the small
 * prime with the modp_* functions. CRT coefficients (inverses) can be
 * precomputed.
 *
 * All values are positive until the last step: when the polynomial
 * coefficients have been rebuilt, we normalize them around 0. But then,
 * only additions and subtractions on the upper few bits are needed
 * afterwards.
 *
 * We keep big integers as arrays of 31-bit words (in uint32_t values);
 * the top bit of each uint32_t is kept equal to 0. Using 31-bit words
 * makes it easier to track carries. When negative values are used,
 * two's complement is used.
 */

/*
 * Add integer b to integer a. Both integers are supposed to have the
 * same size, and the result should fit in that size as well. The carry
 * is returned. Source arrays a and b MUST be distinct.
 */
static uint32_t
zint_add(uint32_t *restrict a, const uint32_t *restrict b, size_t len)
{
	size_t u;
	uint32_t cc;

	cc = 0;
	for (u = 0; u < len; u ++) {
		uint32_t w;

		w = a[u] + b[u] + cc;
		a[u] = w & 0x7FFFFFFF;
		cc = w >> 31;
	}
	return cc;
}

/*
 * Subtract integer b from integer a. Both integers are supposed to have
 * the same size. The carry (0 or 1) is returned. Source arrays a and b
 * MUST be distinct.
 */
static uint32_t
zint_sub(uint32_t *restrict a, const uint32_t *restrict b, size_t len)
{
	size_t u;
	uint32_t cc;

	cc = 0;
	for (u = 0; u < len; u ++) {
		uint32_t w;

		w = a[u] - b[u] - cc;
		a[u] = w & 0x7FFFFFFF;
		cc = w >> 31;
	}
	return cc;
}

/*
 * Mutiply the provided big integer m with a small value x.
 * This function assumes that x < 2^31. The carry word is returned.
 */
static uint32_t
zint_mul_small(uint32_t *m, size_t mlen, uint32_t x)
{
	size_t u;
	uint32_t cc;

	cc = 0;
	for (u = 0; u < mlen; u ++) {
		uint64_t z;

		z = (uint64_t)m[u] * (uint64_t)x + cc;
		m[u] = (uint32_t)z & 0x7FFFFFFF;
		cc = (uint32_t)(z >> 31);
	}
	return cc;
}

/*
 * Reduce a big integer d modulo a small integer p.
 * Rules:
 *  d is unsigned
 *  p is prime
 *  2^30 < p < 2^31
 *  p0i = -(1/p) mod 2^31
 *  R2 = 2^62 mod p
 */
static uint32_t
zint_mod_small_unsigned(const uint32_t *d, size_t dlen,
	uint32_t p, uint32_t p0i, uint32_t R2)
{
	uint32_t x;
	size_t u;

	/*
	 * Algorithm: we inject words one by one, starting with the high
	 * word. Each step is:
	 *  - multiply x by 2^31
	 *  - add new word
	 */
	x = 0;
	u = dlen;
	while (u -- > 0) {
		uint32_t w;

		x = modp_montymul(x, R2, p, p0i);
		w = d[u] - p;
		w += p & -(w >> 31);
		x = modp_add(x, w, p);
	}
	return x;
}

/*
 * Similar to zint_mod_small_unsigned(), except that d may be signed.
 * Extra parameter is Rx = 2^(31*dlen) mod p.
 */
static uint32_t
zint_mod_small_signed(const uint32_t *d, size_t dlen,
	uint32_t p, uint32_t p0i, uint32_t R2, uint32_t Rx)
{
	uint32_t z;

	if (dlen == 0) {
		return 0;
	}
	z = zint_mod_small_unsigned(d, dlen, p, p0i, R2);
	z = modp_sub(z, Rx & -(d[dlen - 1] >> 30), p);
	return z;
}

/*
 * Add y*s to x. x and y initially have length 'len' words; the new x
 * has length 'len+1' words. 's' must fit on 31 bits.
 */
static void
zint_add_mul_small(uint32_t *restrict x,
	const uint32_t *restrict y, size_t len, uint32_t s)
{
	size_t u;
	uint32_t cc;

	cc = 0;
	for (u = 0; u < len; u ++) {
		uint32_t xw, yw;
		uint64_t z;

		xw = x[u];
		yw = y[u];
		z = (uint64_t)yw * (uint64_t)s + (uint64_t)xw + (uint64_t)cc;
		x[u] = (uint32_t)z & 0x7FFFFFFF;
		cc = (uint32_t)(z >> 31);
	}
	x[len] = cc;
}

/*
 * Right-shift an _unsigned_ integer by one bit. The least significant
 * bit is returned. The new integer length is returned.
 */
static uint32_t
zint_rshift1(uint32_t *d, size_t len)
{
	uint32_t cc;
	size_t k;

	cc = 0;
	k = len;
	while (k -- > 0) {
		uint32_t w;

		w = d[k];
		d[k] = (w >> 1) | (cc << 30);
		cc = w & 1;
	}
	return cc;
}

/*
 * Halve integer x modulo integer p. The modulus p MUST be odd.
 */
static void
zint_rshift1_mod(uint32_t *restrict x, const uint32_t *restrict p, size_t len)
{
	uint32_t hi;

	if ((x[0] & 1) != 0) {
		hi = zint_add(x, p, len);
	} else {
		hi = 0;
	}
	zint_rshift1(x, len);
	x[len - 1] |= hi << 30;
}

/*
 * Subtract y from x, modulo p.
 */
static void
zint_sub_mod(uint32_t *restrict x, const uint32_t *restrict y,
	const uint32_t *restrict p, size_t len)
{
	if (zint_sub(x, y, len)) {
		zint_add(x, p, len);
	}
}

/*
 * Compare a with b. Both integers are unsigned and have the same encoded
 * length.
 */
static int
zint_ucmp(const uint32_t *a, const uint32_t *b, size_t len)
{
	while (len -- > 0) {
		uint32_t wa, wb;

		wa = a[len];
		wb = b[len];
		if (wa < wb) {
			return -1;
		}
		if (wa > wb) {
			return 1;
		}
	}
	return 0;
}

/*
 * Normalize a modular integer around 0: if x > p/2, then x is replaced
 * with x - p (signed encoding with two's complement); otherwise, x is
 * untouched. The two integers x and p are encoded over the same length.
 */
static void
zint_norm_zero(uint32_t *restrict x, const uint32_t *restrict p, size_t len)
{
	uint32_t cc;
	size_t u;

	cc = 0;
	u = len;
	while (u -- > 0) {
		uint32_t w;

		w = (p[u] >> 1) | (cc << 30);
		cc = p[u] & 1;
		if (x[u] < w) {
			return;
		}
		if (x[u] > w) {
			zint_sub(x, p, len);
			return;
		}
	}
}

/*
 * Rebuild integers from their RNS representation. There are 'num'
 * integers, and each consists in 'xlen' words. 'xx' points at that
 * first word of the first integer; subsequent integers are accessed
 * by adding 'xstride' repeatedly.
 *
 * The words of an integer are the RNS representation of that integer,
 * using the provided 'primes' are moduli. This function replaces
 * each integer with its multi-word value (little-endian order).
 *
 * If "normalize_signed" is non-zero, then the returned value is
 * normalized to the -m/2..m/2 interval (where m is the product of all
 * small prime moduli); two's complement is used for negative values.
 */
static void
zint_rebuild_CRT(uint32_t *restrict xx, size_t xlen, size_t xstride,
	size_t num, const small_prime *primes, int normalize_signed,
	uint32_t *restrict tmp)
{
	size_t u;
	uint32_t *x;

	tmp[0] = primes[0].p;
	for (u = 1; u < xlen; u ++) {
		/*
		 * At the entry of each loop iteration:
		 *  - the first u words of each array have been
		 *    reassembled;
		 *  - the first u words of tmp[] contains the
		 * product of the prime moduli processed so far.
		 *
		 * We call 'q' the product of all previous primes.
		 */
		uint32_t p, p0i, s, R2;
		size_t v;

		p = primes[u].p;
		s = primes[u].s;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);

		for (v = 0, x = xx; v < num; v ++, x += xstride) {
			uint32_t xp, xq, xr;
			/*
			 * xp = the integer x modulo the prime p for this
			 *      iteration
			 * xq = (x mod q) mod p
			 */
			xp = x[u];
			xq = zint_mod_small_unsigned(x, u, p, p0i, R2);

			/*
			 * New value is (x mod q) + q * (s * (xp - xq) mod p)
			 */
			xr = modp_montymul(s, modp_sub(xp, xq, p), p, p0i);
			zint_add_mul_small(x, tmp, u, xr);
		}

		/*
		 * Update product of primes in tmp[].
		 */
		tmp[u] = zint_mul_small(tmp, u, p);
	}

	/*
	 * Normalize the reconstructed values around 0.
	 */
	if (normalize_signed) {
		for (u = 0, x = xx; u < num; u ++, x += xstride) {
			zint_norm_zero(x, tmp, xlen);
		}
	}
}

/*
 * Compute exact length of an integer (i.e. reduce it to remove high
 * words of value 0).
 */
static size_t
zint_exact_length(const uint32_t *x, size_t xlen)
{
	while (xlen > 0) {
		if (x[xlen - 1] != 0) {
			return xlen;
		}
		xlen --;
	}
	return xlen;
}

/*
 * Replace a with (a*xa+b*xb)/(2^31) and b with (a*ya+b*yb)/(2^31).
 * The low bits are dropped (the caller should compute the coefficients
 * such that these dropped bits are all zeros). If either or both
 * yields a negative value, then the value is negated.
 *
 * Returned value is:
 *  0  both values were positive
 *  1  new a had to be negated
 *  2  new b had to be negated
 *  3  both new a and new b had to be negated
 *
 * Coefficients xa, xb, ya and yb may use the full signed 32-bit range.
 */
static int
zint_co_reduce(uint32_t *a, uint32_t *b, size_t len,
	int32_t xa, int32_t xb, int32_t ya, int32_t yb)
{
	size_t u;
	int32_t cca, ccb;
	int r;

	cca = 0;
	ccb = 0;
	for (u = 0; u < len; u ++) {
		int32_t wa, wb;
		int64_t za, zb;
		uint32_t tta, ttb;

		wa = (int32_t)a[u];
		wb = (int32_t)b[u];
		za = (int64_t)wa * xa + (int64_t)wb * xb + cca;
		zb = (int64_t)wa * ya + (int64_t)wb * yb + ccb;
		if (u > 0) {
			a[u - 1] = (uint32_t)za & 0x7FFFFFFF;
			b[u - 1] = (uint32_t)zb & 0x7FFFFFFF;
		}
		tta = (uint32_t)((uint64_t)za >> 31);
		ttb = (uint32_t)((uint64_t)zb >> 31);
		cca = *(int32_t *)&tta;
		ccb = *(int32_t *)&ttb;
	}
	a[len - 1] = (uint32_t)cca;
	b[len - 1] = (uint32_t)ccb;
	r = 0;
	if (cca < 0) {
		uint32_t c;

		c = 1;
		for (u = 0; u < len; u ++) {
			uint32_t w;

			w = c + ~a[u];
			a[u] = w & 0x7FFFFFFF;
			c = (~w) >> 31;
		}
		r |= 1;
	}
	if (ccb < 0) {
		uint32_t c;

		c = 1;
		for (u = 0; u < len; u ++) {
			uint32_t w;

			w = c + ~b[u];
			b[u] = w & 0x7FFFFFFF;
			c = (~w) >> 31;
		}
		r |= 2;
	}

	return r;
}

/*
 * Replace a with (a*xa+b*xb)/(2^31) mod m, and b with
 * (a*ya+b*yb)/(2^31) mod m. Modulus m must be odd; m0i = -1/m[0] mod 2^31.
 */
static void
zint_co_reduce_mod(uint32_t *a, uint32_t *b, const uint32_t *m, size_t len,
	uint32_t m0i, int32_t xa, int32_t xb, int32_t ya, int32_t yb)
{
	size_t u;
	uint32_t fx, fy;
	int64_t cca, ccb;

	/*
	 * These are actually four combined Montgomery multiplications.
	 */
	fx = ((a[0] * (uint32_t)xa + b[0] * (uint32_t)xb) * m0i) & 0x7FFFFFFF;
	fy = ((a[0] * (uint32_t)ya + b[0] * (uint32_t)yb) * m0i) & 0x7FFFFFFF;
	cca = 0;
	ccb = 0;
	for (u = 0; u < len; u ++) {
		uint32_t wa, wb;
		int64_t za, zb;
		uint64_t tta, ttb;

		wa = a[u];
		wb = b[u];
		za = (int64_t)wa * (int64_t)xa + (int64_t)wb * (int64_t)xb;
		zb = (int64_t)wa * (int64_t)ya + (int64_t)wb * (int64_t)yb;
		za += cca;
		zb += ccb;
		za += (uint64_t)m[u] * (uint64_t)fx;
		zb += (uint64_t)m[u] * (uint64_t)fy;
		if (u > 0) {
			a[u - 1] = (uint32_t)za & 0x7FFFFFFF;
			b[u - 1] = (uint32_t)zb & 0x7FFFFFFF;
		}

		/*
		 * Weird code below is a sign-extension. We want to
		 * perform an arithmetic shift, but the C standard does
		 * not guarantee that right-shifting signed negative
		 * values performs an arithmetic shift (it's
		 * "implementation-defined").
		 */
#define M   ((uint64_t)1 << 32)
		tta = (uint64_t)za >> 31;
		ttb = (uint64_t)zb >> 31;
		tta = (tta ^ M) - M;
		ttb = (ttb ^ M) - M;
		cca = *(int64_t *)&tta;
		ccb = *(int64_t *)&ttb;
#undef M
	}
	a[len - 1] = (uint32_t)cca & 0x7FFFFFFF;
	b[len - 1] = (uint32_t)ccb & 0x7FFFFFFF;

	/*
	 * For each value a and b:
	 *  - if negative, add modulus
	 *  - if positive and not lower than modulus, subtract modulus
	 */
	if (cca < 0) {
		zint_add(a, m, len);
	} else {
		if (zint_ucmp(a, m, len) >= 0) {
			zint_sub(a, m, len);
		}
	}
	if (ccb < 0) {
		zint_add(b, m, len);
	} else {
		if (zint_ucmp(b, m, len) >= 0) {
			zint_sub(b, m, len);
		}
	}
}

/*
 * Replace a with (a+k*b)/(2^31). If the result it negative, then it is
 * negated and 1 is returned; otherwise, 0 is returned.
 */
static int
zint_reduce(uint32_t *a, const uint32_t *b, size_t len, int32_t k)
{
	size_t u;
	int32_t cc;

	cc = 0;
	for (u = 0; u < len; u ++) {
		int32_t wa, wb;
		int64_t z;
		uint32_t tt;

		wa = (int32_t)a[u];
		wb = (int32_t)b[u];
		z = (int64_t)wb * k + (int64_t)wa + cc;
		if (u > 0) {
			a[u - 1] = (uint32_t)z & 0x7FFFFFFF;
		}
		tt = (uint32_t)((uint64_t)z >> 31);
		cc = *(int32_t *)&tt;
	}
	a[len - 1] = (uint32_t)cc;
	if (cc < 0) {
		uint32_t c;

		c = 1;
		for (u = 0; u < len; u ++) {
			uint32_t w;

			w = c + ~a[u];
			a[u] = w & 0x7FFFFFFF;
			c = (~w) >> 31;
		}
		return 1;
	} else {
		return 0;
	}
}

/*
 * Replace a with (a+k*b)/(2^31) mod m.
 * Modulus m must be odd; m0i = -1/m[0] mod 2^31.
 */
static void
zint_reduce_mod(uint32_t *a, const uint32_t *b, const uint32_t *m,
	size_t len, uint32_t m0i, int32_t k)
{
	size_t u;
	uint32_t f;
	int32_t cc;

	f = ((a[0] + b[0] * (uint32_t)k) * m0i) & 0x7FFFFFFF;
	cc = 0;
	for (u = 0; u < len; u ++) {
		uint32_t wa, wb;
		int64_t z;
		uint32_t tt;

		wa = a[u];
		wb = b[u];
		z = (int64_t)wa + (int64_t)wb * (int64_t)k + cc;
		z += (uint64_t)m[u] * (uint64_t)f;
		if (u > 0) {
			a[u - 1] = (uint32_t)z & 0x7FFFFFFF;
		}
		tt = (uint32_t)((uint64_t)z >> 31);
		cc = *(int32_t *)&tt;
	}
	a[len - 1] = (uint32_t)cc & 0x7FFFFFFF;

	/*
	 * - if negative, add modulus
	 * - if positive and not lower than modulus, subtract modulus
	 */
	if (cc < 0) {
		zint_add(a, m, len);
	} else {
		if (zint_ucmp(a, m, len) >= 0) {
			zint_sub(a, m, len);
		}
	}
}

/*
 * Compute a GCD between two positive big integers x and y. The two
 * integers must be odd. Returned value is 1 if the GCD is 1, 0
 * otherwise. When 1 is returned, arrays u and v are filled with values
 * such that:
 *   0 <= u <= y
 *   0 <= v <= x
 *   x*u - y*v = 1
 * x[] and y[] are unmodified. Both input values must have the same
 * encoded length. Temporary array must be large enough to accommodate 4
 * extra values of that length. Arrays u, v and tmp may not overlap with
 * each other, or with either x or y.
 */
static int
zint_bezout(uint32_t *restrict u, uint32_t *restrict v,
	const uint32_t *restrict x, const uint32_t *restrict y,
	size_t len, uint32_t *restrict tmp)
{
	uint32_t *u0, *u1, *v0, *v1, *a, *b;
	size_t xlen, ylen, alen, blen, mlen;
	uint32_t x0i, y0i;

	/*
	 * Algorithm is an extended binary GCD. We maintain 6 values
	 * a, b, u0, u1, v0 and v1 with the following invariants:
	 *
	 *  a = x*u0 - y*v0
	 *  b = x*u1 - y*v1
	 *  0 <= u0 < y
	 *  0 <= v0 < x
	 *  0 <= u1 <= y
	 *  0 <= v1 <= x
	 *
	 * Initial values are:
	 *
	 *  a = x   u0 = 1   v0 = 0
	 *  b = y   u1 = y   v1 = x-1
	 *
	 * Each iteration reduces either a or b, and maintain the
	 * invariants. Algorithm stops when a = b, at which point their
	 * common value is GCD(a,b) and (u0,v0) (or (u1,v1)) contains
	 * the values (u,v) we want to return.
	 *
	 * We must handle specially the cases of x = 1 or y = 1, which
	 * make the solution trivial. If x > 1 and y > 1, and GCD(x,y) = 1,
	 * then there will be a solution (u,v) such that 0 < u < y and
	 * 0 < v < x (it can be shown that u = 1/x mod y and v = -1/y mod x).
	 */

	u0 = u;
	v0 = v;
	u1 = tmp;
	v1 = u1 + len;
	a = v1 + len;
	b = a + len;

	/*
	 * Compute actual lengths of x and y.
	 */
	xlen = zint_exact_length(x, len);
	ylen = zint_exact_length(y, len);

	/*
	 * Filter out bad values:
	 *   x and y must not be zero.
	 *   x and y must be odd.
	 */
	if (xlen == 0 || ylen == 0 || (x[0] & y[0] & 1) == 0) {
		return 0;
	}

	/*
	 * Initialize a, b, u0, u1, v0 and v1.
	 *  a = x   u0 = 1   v0 = 0
	 *  b = y   u1 = y   v1 = x-1
	 * Note that x is odd, so computing x-1 is easy.
	 */
	memcpy(a, x, xlen * sizeof *x);
	memcpy(b, y, ylen * sizeof *y);
	alen = xlen;
	blen = ylen;
	u0[0] = 1;
	memset(u0 + 1, 0, (ylen - 1) * sizeof *u0);
	memset(v0, 0, xlen * sizeof *v0);
	memcpy(u1, y, ylen * sizeof *u1);
	memcpy(v1, x, xlen * sizeof *v1);
	v1[0] &= ~(uint32_t)1;

	/*
	 * We also zero out the upper unused words of the returned array
	 * u and v (caller expects it).
	 */
	memset(u + ylen, 0, (len - ylen) * sizeof *u);
	memset(v + xlen, 0, (len - xlen) * sizeof *v);

	/*
	 * We zero out the upper unused words of a and b as well, so that
	 * we may subtract one from the other with a common length.
	 */
	mlen = alen < blen ? blen : alen;
	memset(a + alen, 0, (mlen - alen) * sizeof *a);
	memset(b + blen, 0, (mlen - blen) * sizeof *b);

	/*
	 * If x = 1 then the current values in u and v are just fine
	 * and we can return them (because u0 and u are the same array,
	 * and similarly v0 and v).
	 * If y = 1, then the values in u1 and v1 must be returned.
	 */
	if (xlen == 1 && x[0] == 1) {
		return 1;
	}
	if (ylen == 1 && y[0] == 1) {
		memcpy(u, u1, ylen * sizeof *u);
		memcpy(v, v1, xlen * sizeof *v);
		return 1;
	}

	x0i = modp_ninv31(x[0]);
	y0i = modp_ninv31(y[0]);

	/*
	 * We are now all set for the main algorithm.
	 */
	for (;;) {
		int r;

		/*
		 * If either word is large enough, we use the
		 * accelerated approximation.
		 */
		if (alen >= 3 || blen >= 3) {
			size_t len;
			uint64_t a_hi, b_hi;
			uint32_t a_lo, b_lo;
			uint32_t uxa, uya, uxb, uyb;
			int i, r;

			len = alen < blen ? blen : alen;

			/*
			 * Get the top and low bits of each value.
			 */
			a_hi = ((uint64_t)a[len - 1] << 31) | a[len - 2];
			b_hi = ((uint64_t)b[len - 1] << 31) | b[len - 2];
			a_lo = a[0];
			b_lo = b[0];
			uxa = 1;
			uxb = 0;
			uya = 0;
			uyb = 1;
			for (i = 0; i < 31; i ++) {
				uint32_t m;

				m = (uint32_t)1 << i;
				if ((a_lo & m) == 0) {
					a_hi >>= 1;
					b_lo <<= 1;
					uya <<= 1;
					uyb <<= 1;
				} else if ((b_lo & m) == 0) {
					b_hi >>= 1;
					a_lo <<= 1;
					uxa <<= 1;
					uxb <<= 1;
				} else if (a_hi > b_hi) {
					a_hi -= b_hi;
					a_lo -= b_lo;
					uxa -= uya;
					uxb -= uyb;
					a_hi >>= 1;
					b_lo <<= 1;
					uya <<= 1;
					uyb <<= 1;
				} else {
					b_hi -= a_hi;
					b_lo -= a_lo;
					uya -= uxa;
					uyb -= uxb;
					b_hi >>= 1;
					a_lo <<= 1;
					uxa <<= 1;
					uxb <<= 1;
				}
			}

			/*
			 * It may happen that one of the factors is
			 * equal to 2^31. In that case, we must use a
			 * specialized function, because that value will
			 * not fit in an int32_t.
			 */
			if (uxa == 0x80000000) {
				int32_t ya;

				if (uxb != 0 || uyb != 1) {
					return 0;
				}
				ya = *(int32_t *)&uya;
				if (zint_reduce(b, a, len, ya)) {
					ya = -ya;
				}
				zint_reduce_mod(u1, u0, y, ylen, y0i, ya);
				zint_reduce_mod(v1, v0, x, xlen, x0i, ya);
			} else if (uyb == 0x80000000) {
				int32_t xb;

				if (uya != 0 || uxa != 1) {
					return 0;
				}
				xb = *(int32_t *)&uxb;
				if (zint_reduce(a, b, len, xb)) {
					xb = -xb;
				}
				zint_reduce_mod(u0, u1, y, ylen, y0i, xb);
				zint_reduce_mod(v0, v1, x, xlen, x0i, xb);
			} else {
				int32_t xa, xb, ya, yb;

				xa = *(int32_t *)&uxa;
				xb = *(int32_t *)&uxb;
				ya = *(int32_t *)&uya;
				yb = *(int32_t *)&uyb;

				r = zint_co_reduce(a, b, len, xa, xb, ya, yb);
				if ((r & 1) != 0) {
					xa = -xa;
					xb = -xb;
				}
				if ((r & 2) != 0) {
					ya = -ya;
					yb = -yb;
				}
				zint_co_reduce_mod(u0, u1, y, ylen, y0i,
					xa, xb, ya, yb);
				zint_co_reduce_mod(v0, v1, x, xlen, x0i,
					xa, xb, ya, yb);
			}
			alen = zint_exact_length(a, alen);
			blen = zint_exact_length(b, blen);

			continue;
		}

		/*
		 * If a is even, divide it by 2 and adjust u0 and v0.
		 */
		if ((a[0] & 1) == 0) {
			zint_rshift1(a, alen);
			alen = zint_exact_length(a, alen);
			zint_rshift1_mod(u0, y, ylen);
			zint_rshift1_mod(v0, x, xlen);
			continue;
		}

		/*
		 * If b is even, divide it by 2 and adjust u1 and v1.
		 */
		if ((b[0] & 1) == 0) {
			zint_rshift1(b, blen);
			blen = zint_exact_length(b, blen);
			zint_rshift1_mod(u1, y, ylen);
			zint_rshift1_mod(v1, x, xlen);
			continue;
		}

		/*
		 * Compare a to b. If equal, then the algorithm
		 * terminates.
		 */
		if (alen < blen) {
			r = -1;
		} else if (alen > blen) {
			r = 1;
		} else {
			r = zint_ucmp(a, b, alen);
			if (r == 0) {
				/*
				 * If a == b, then the algorithm terminate;
				 * they both contain the GCD of x and y.
				 * This is a success only if that GCD is 1.
				 * Arrays u and v are already filled with
				 * the proper results.
				 */
				return alen == 1 && a[0] == 1;
			}
		}

		/*
		 * If a > b, then set a <- a-b, and adjust u0 and v0
		 * accordingly. Analysis shows that we will be able to
		 * maintain 0 < u0 < y and 0 < v0 < x.
		 *
		 * If a < b, then set b <- b-a, and adjust u1 and v1
		 * accordingly. Analysis shows that we will be able to
		 * maintain 0 < u1 < y and 0 < v1 < x.
		 */
		if (r > 0) {
			zint_sub(a, b, alen);
			alen = zint_exact_length(a, alen);
			zint_sub_mod(u0, u1, y, ylen);
			zint_sub_mod(v0, v1, x, xlen);
		} else {
			zint_sub(b, a, blen);
			blen = zint_exact_length(b, blen);
			zint_sub_mod(u1, u0, y, ylen);
			zint_sub_mod(v1, v0, x, xlen);
		}
	}
}

/*
 * Compute bit length of a word. Input word x must have length at most 31
 * bits (i.e. top bit is cleared).
 */
unsigned
bitlength(uint32_t x)
{
	/*
	 * This algorithm is inspired from an algorithm devised by
	 * Robert Harley and explained in Hacker's Delight, 2nd edition
	 * (section 5.3).
	 *
	 * We first propagate the highest non-zero bit to the right, so
	 * that the value becomes equal to 2^bl-1; at that point, we thus
	 * have 32 possible values for x (0, and powers of 2 from 2^0 to
	 * 2^30). Then, we multiply the value with a specific constant
	 * that makes it so that the top 5 bits of the 32-bit result will
	 * contain 32 different values for the 32 possible values of x
	 * at this point. These top 5 bits thus contain a permutation of
	 * the 0..31 result we need; a table look-up implements the
	 * reverse permutation.
	 */
	static const unsigned vv[] = {
		 0, 31,  4,  5,  6, 10,  7, 15,
		11, 20,  8, 18, 16, 25, 12, 27,
		21, 30,  3,  9, 14, 19, 17, 24,
		26, 29,  2, 13, 23, 28,  1, 22
	};

	x |= x >> 1;
	x |= x >> 2;
	x |= x >> 4;
	x |= x >> 8;
	x |= x >> 16;
	return vv[(x * 0xF04653AE) >> 27];
}

/*
 * Get the bit length of a signed big integer: this is the minimum number
 * of bits required to hold the value, _without_ the signed bit (thus, -1
 * has bit length 0).
 */
static uint32_t
zint_signed_bit_length(const uint32_t *x, size_t xlen)
{
	uint32_t sign;

	if (xlen == 0) {
		return 0;
	}
	sign = (-(x[xlen - 1] >> 30)) >> 1;
	while (xlen > 0) {
		if (x[xlen - 1] != sign) {
			break;
		}
		xlen --;
	}
	if (xlen == 0) {
		return 0;
	}
	return (uint32_t)(xlen - 1) * 31 + bitlength(x[xlen - 1] ^ sign);
}

/*
 * Get the top 63 bits of a signed big integer, starting at the provided
 * index (in bits). The integer absolute value MUST fit in sc+63 bits.
 */
static int64_t
zint_get_top(const uint32_t *x, size_t xlen, uint32_t sc)
{
	uint64_t z;
	uint32_t sign, w0, w1, w2;
	uint32_t k, off;

	if (xlen == 0) {
		return 0;
	}

	/*
	 * The "sign word" is -1 for negative values, 0 for positive values.
	 */
	sign = -(x[xlen - 1] >> 30);

	k = sc / 31;
	off = sc - (31 * k);

	/*
	 * To obtain 63 bits, we always need exactly three words.
	 */
	if ((k + 2) < xlen) {
		w0 = x[k + 0];
		w1 = x[k + 1];
		w2 = x[k + 2] | (sign << 31);
	} else if ((k + 1) < xlen) {
		w0 = x[k + 0];
		w1 = x[k + 1];
		w2 = sign;
	} else if (k < xlen) {
		w0 = x[k + 0];
		w1 = sign;
		w2 = sign;
	} else {
		w0 = sign;
		w1 = sign;
		w2 = sign;
	}
	z = ((uint64_t)w0 >> off)
		| ((uint64_t)w1 << (31 - off))
		| ((uint64_t)w2 << (62 - off));

	/*
	 * Properties of the exact-width types (no padding, no trap
	 * representation, two's complement representation) means that
	 * we can use a cast on the in-memory representation to
	 * convert from unsigned to signed values, without incurring
	 * any undefined behaviour.
	 */
	return *(int64_t *)&z;
}

/*
 * Add k*y*2^sc to x. The result is assumed to fit in the array of
 * size xlen (truncation is applied if necessary).
 * Scale factor 'sc' is provided as sch and scl, such that:
 *   sch = sc / 31
 *   scl = sc % 31
 * xlen MUST NOT be lower than ylen.
 *
 * x[] and y[] are both signed integers, using two's complement for
 * negative values.
 */
static void
zint_add_scaled_mul_small(uint32_t *restrict x, size_t xlen,
	const uint32_t *restrict y, size_t ylen, int32_t k,
	uint32_t sch, uint32_t scl)
{
	size_t u;
	uint32_t ysign, tw;
	int32_t cc;

	if (ylen == 0) {
		return;
	}

	ysign = -(y[ylen - 1] >> 30) >> 1;
	tw = 0;
	cc = 0;
	for (u = sch; u < xlen; u ++) {
		size_t v;
		uint32_t wy, wys, ccu;
		uint64_t z;

		/*
		 * Get the next word of y (scaled).
		 */
		v = u - sch;
		wy = v < ylen ? y[v] : ysign;
		wys = ((wy << scl) & 0x7FFFFFFF) | tw;
		tw = wy >> (31 - scl);

		/*
		 * The expression below does not overflow.
		 */
		z = (int64_t)wys * (int64_t)k + (int64_t)x[u] + cc;
		x[u] = (uint32_t)z & 0x7FFFFFFF;

		/*
		 * Right-shifting the signed value z would yield
		 * implementation-defined results (arithmetic shift is
		 * not guaranteed). However, we can cast to unsigned,
		 * and get the next carry as an unsigned word. We can
		 * then convert it back to signed by using the guaranteed
		 * fact that 'int32_t' uses two's complement with no
		 * trap representation or padding bit, and with a layout
		 * compatible with that of 'uint32_t'.
		 */
		ccu = (uint32_t)((uint64_t)z >> 31);
		cc = *(int32_t *)&ccu;
	}
}

/*
 * Subtract y*2^sc from x. The result is assumed to fit in the array of
 * size xlen (truncation is applied if necessary).
 * Scale factor 'sc' is provided as sch and scl, such that:
 *   sch = sc / 31
 *   scl = sc % 31
 * xlen MUST NOT be lower than ylen.
 *
 * x[] and y[] are both signed integers, using two's complement for
 * negative values.
 */
static void
zint_sub_scaled(uint32_t *restrict x, size_t xlen,
	const uint32_t *restrict y, size_t ylen, uint32_t sch, uint32_t scl)
{
	size_t u;
	uint32_t ysign, tw;
	uint32_t cc;

	if (ylen == 0) {
		return;
	}

	ysign = -(y[ylen - 1] >> 30) >> 1;
	tw = 0;
	cc = 0;
	for (u = sch; u < xlen; u ++) {
		size_t v;
		uint32_t w, wy, wys;

		/*
		 * Get the next word of y (scaled).
		 */
		v = u - sch;
		wy = v < ylen ? y[v] : ysign;
		wys = ((wy << scl) & 0x7FFFFFFF) | tw;
		tw = wy >> (31 - scl);

		w = x[u] - wys - cc;
		x[u] = w & 0x7FFFFFFF;
		cc = w >> 31;
	}
}

/*
 * Convert a one-word signed big integer into a signed value.
 */
static inline int32_t
zint_one_to_plain(const uint32_t *x)
{
	uint32_t w;

	w = x[0];
	w |= (w & 0x40000000) << 1;
	return *(int32_t *)&w;
}

/* ==================================================================== */

/*
 * Get the maximum bitlength of coordinates for a polynomial.
 */
static uint32_t
poly_max_bitlength(const uint32_t *f, size_t flen, size_t fstride,
	unsigned logn, unsigned ter)
{
	size_t n, u;
	uint32_t maxbl;

	n = MKN(logn, ter);
	maxbl = 0;
	for (u = 0; u < n; u ++, f += fstride) {
		uint32_t bl;

		bl = zint_signed_bit_length(f, flen);
		if (bl > maxbl) {
			maxbl = bl;
		}
	}
	return maxbl;
}

/*
 * Convert a polynomial to floating-point values; the maximum bit length
 * of all coefficients is provided as 'maxbl' parameter. Returned values are
 * scaled down by 'scale' bits: if the integer value is z, this function
 * computes an approximation of z*2^(-scale).
 */
static void
poly_big_to_fp(fpr *d, const uint32_t *f, size_t flen, size_t fstride,
	unsigned logn, unsigned ter, uint32_t maxbl, uint32_t scale)
{
	size_t n, u;
	uint32_t off;

	n = MKN(logn, ter);
	off = maxbl < 63 ? 0 : maxbl - 63;
	for (u = 0; u < n; u ++, f += fstride) {
		d[u] = fpr_scaled(zint_get_top(f, flen, off),
			(int)(off - scale));
	}
}

/*
 * Convert a polynomial to small integers. Source values are supposed
 * to be one-word integers, signed over 31 bits. Returned value is 0
 * if any of the coefficients exceeds 2047 (in absolute value), or 1
 * on success.
 */
static int
poly_big_to_small(int16_t *d, const uint32_t *s, unsigned logn, unsigned ter)
{
	size_t n, u;

	n = MKN(logn, ter);
	for (u = 0; u < n; u ++) {
		int32_t z;

		z = zint_one_to_plain(s + u);
		if (z < -2047 || z > 2047) {
			return 0;
		}
		d[u] = (int16_t)z;
	}
	return 1;
}

/*
 * Subtract k*f from F, where F, f and k are polynomials modulo X^N+1.
 * Coefficients of polynomial k are small integers (signed values in the
 * -2^31..2^31 range) scaled by 2^sc.
 *
 * This function implements the basic quadratic multiplication algorithm,
 * which is efficient in space (no extra buffer needed) but slow at
 * high degree.
 */
static void
poly_sub_scaled(uint32_t *restrict F, size_t Flen, size_t Fstride,
	const uint32_t *restrict f, size_t flen, size_t fstride,
	const int32_t *restrict k, uint32_t sc,
	unsigned logn, unsigned full, unsigned ternary)
{
	size_t n, hn, u;
	uint32_t sch, scl;

	n = MKN(logn, full);
	hn = n >> 1;
	sch = sc / 31;
	scl = sc % 31;
	if (ternary) {
		size_t off1, off2, off3;

		off1 = hn * Fstride;
		off2 = n * Fstride;
		off3 = off1 + off2;
		for (u = 0; u < n; u ++) {
			int32_t kf;
			size_t v, j;
			const uint32_t *y;

			kf = -k[u];
			j = u * Fstride;
			y = f;
			for (v = 0; v < n; v ++, j += Fstride, y += fstride) {
				if (u + v < n) {
					zint_add_scaled_mul_small(
						F + j, Flen,
						y, flen, kf, sch, scl);
				} else if (u + v < (n + hn)) {
					zint_add_scaled_mul_small(
						F + j - off1, Flen,
						y, flen, kf, sch, scl);
					zint_add_scaled_mul_small(
						F + j - off2, Flen,
						y, flen, -kf, sch, scl);
				} else {
					zint_add_scaled_mul_small(
						F + j - off3, Flen,
						y, flen, -kf, sch, scl);
				}
			}
		}
	} else {
		for (u = 0; u < n; u ++) {
			int32_t kf;
			size_t v;
			uint32_t *x;
			const uint32_t *y;

			kf = -k[u];
			x = F + u * Fstride;
			y = f;
			for (v = 0; v < n; v ++) {
				zint_add_scaled_mul_small(
					x, Flen, y, flen, kf, sch, scl);
				if (u + v == n - 1) {
					x = F;
					kf = -kf;
				} else {
					x += Fstride;
				}
				y += fstride;
			}
		}
	}
}

/*
 * Subtract k*f from F. Coefficients of polynomial k are small integers
 * (signed values in the -2^31..2^31 range) scaled by 2^sc. This function
 * assumes that the degree is large, and integers relatively small.
 */
static void
poly_sub_scaled_ntt(uint32_t *restrict F, size_t Flen, size_t Fstride,
	const uint32_t *restrict f, size_t flen, size_t fstride,
	const int32_t *restrict k, uint32_t sc,
	unsigned logn, unsigned full, int ternary, uint32_t *restrict tmp)
{
	uint32_t *gm, *igm, *fk, *t1, *x;
	const uint32_t *y;
	size_t n, u, tlen;
	uint32_t sch, scl;
	const small_prime *primes;

	n = MKN(logn, full);
	tlen = flen + 1;
	gm = tmp;
	igm = gm + MKN(logn, 0);
	fk = igm + MKN(logn, 0);
	t1 = fk + n * tlen;

	primes = ternary ? PRIMES3 : PRIMES2;

	/*
	 * Compute k*f in fk[], in RNS notation.
	 */
	for (u = 0; u < tlen; u ++) {
		uint32_t p, p0i, R2, Rx;
		size_t v;

		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		Rx = modp_Rx(flen, p, p0i, R2);
		if (ternary) {
			modp_mkgm3(gm, igm, logn, full, primes[u].g, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[u].g, p, p0i);
		}

		for (v = 0; v < n; v ++) {
			t1[v] = modp_set(k[v], p);
		}
		if (ternary) {
			modp_NTT3(t1, gm, logn, full, p, p0i);
		} else {
			modp_NTT2(t1, gm, logn, p, p0i);
		}
		for (v = 0, y = f, x = fk + u;
			v < n; v ++, y += fstride, x += tlen)
		{
			*x = zint_mod_small_signed(y, flen, p, p0i, R2, Rx);
		}
		if (ternary) {
			modp_NTT3_ext(fk + u, tlen, gm, logn, full, p, p0i);
		} else {
			modp_NTT2_ext(fk + u, tlen, gm, logn, p, p0i);
		}
		for (v = 0, x = fk + u; v < n; v ++, x += tlen) {
			*x = modp_montymul(
				modp_montymul(t1[v], *x, p, p0i), R2, p, p0i);
		}
		if (ternary) {
			modp_iNTT3_ext(fk + u, tlen, igm, logn, full, p, p0i);
		} else {
			modp_iNTT2_ext(fk + u, tlen, igm, logn, p, p0i);
		}
	}

	/*
	 * Rebuild k*f.
	 */
	zint_rebuild_CRT(fk, tlen, tlen, n, primes, 1, t1);

	/*
	 * Subtract k*f, scaled, from F.
	 */
	sch = sc / 31;
	scl = sc % 31;
	for (u = 0, x = F, y = fk; u < n; u ++, x += Fstride, y += tlen) {
		zint_sub_scaled(x, Flen, y, tlen, sch, scl);
	}
}

/* ==================================================================== */

struct falcon_keygen_ {

	/* Base-2 logarithm of the degree. */
	unsigned logn;

	/* 1 for a ternary modulus, 0 for binary. */
	unsigned ternary;

	/* RNG:
	   seeded    non-zero when a 'replace' seed or system RNG was pushed
	   flipped   non-zero when flipped */
	shake_context rng;
	int seeded;
	int flipped;

	/* Temporary storage for key generation. 'tmp_len' is expressed
	   in 32-bit words. */
	uint32_t *tmp;
	size_t tmp_len;
};

/*
 * Get a random 8-byte integer from a SHAKE-based RNG. This function
 * ensures consistent interpretation of the SHAKE output so that
 * the same values will be obtained over different platforms, in case
 * a known seed is used.
 */
static inline uint64_t
get_rng_u64(shake_context *rng)
{
	/*
	 * On little-endian systems we just interpret the bytes "as is"
	 * (this is correct because the exact-width types such as
	 * 'uint64_t' are guaranteed to have no padding and no trap
	 * representation).
	 *
	 * On other systems we enforce little-endian representation.
	 */
#if FALCON_LE_U
	uint64_t r;

	shake_extract(rng, &r, sizeof r);
	return r;
#else
	unsigned char tmp[8];

	shake_extract(rng, tmp, sizeof tmp);
	return (uint64_t)tmp[0]
		| ((uint64_t)tmp[1] << 8)
		| ((uint64_t)tmp[2] << 16)
		| ((uint64_t)tmp[3] << 24)
		| ((uint64_t)tmp[4] << 32)
		| ((uint64_t)tmp[5] << 40)
		| ((uint64_t)tmp[6] << 48)
		| ((uint64_t)tmp[7] << 56);
#endif
}

/*
 * Table below incarnates a discrete Gaussian distribution:
 *    D(x) = exp(-(x^2)/(2*sigma^2))
 * where sigma = 1.17*sqrt(q/(2*N)), q = 12289, and N = 1024.
 * Element 0 of the table is P(x = 0).
 * For k > 0, element k is P(x >= k+1 | x > 0).
 * Probabilities are scaled up by 2^63.
 */
static const uint64_t gauss_1024_12289[] = {
	 1283868770400643928u,  6416574995475331444u,  4078260278032692663u,
	 2353523259288686585u,  1227179971273316331u,   575931623374121527u,
	  242543240509105209u,    91437049221049666u,    30799446349977173u,
	    9255276791179340u,     2478152334826140u,      590642893610164u,
	     125206034929641u,       23590435911403u,        3948334035941u,
	        586753615614u,          77391054539u,           9056793210u,
	           940121950u,             86539696u,              7062824u,
	              510971u,                32764u,                 1862u,
	                  94u,                    4u,                    0u
};

/*
 * Generate a random value with a Gaussian distribution centered on 0.
 * The RNG must be ready for extraction (already flipped).
 *
 * Distribution has standard deviation 1.17*sqrt(q/(2*N)). The
 * precomputed table is for N = 1024. Since the sum of two independent
 * values of standard deviation sigma has standard deviation
 * sigma*sqrt(2), then we can just generate more values and add them
 * together for lower dimensions.
 *
 * This function is only for the binary case.
 */
static int
mkgauss(falcon_keygen *fk, unsigned logn)
{
	unsigned u, g;
	int val;

	g = 1U << (10 - logn);
	val = 0;
	for (u = 0; u < g; u ++) {
		uint64_t r;
		int k, neg;

		r = get_rng_u64(&fk->rng);
		neg = (int)(r >> 63);
		r &= ~((uint64_t)1 << 63);
		if (r < gauss_1024_12289[0]) {
			continue;
		}
		r = get_rng_u64(&fk->rng);
		r &= ~((uint64_t)1 << 63);
		k = 1;
		while (gauss_1024_12289[k] > r) {
			k ++;
		}
		k *= (int)(1 - (neg << 1));
		val += k;
	}
	return val;
}

/*
 * The MAX_BL_SMALL*[] and MAX_BL_LARGE*[] contain the lengths, in 31-bit
 * words, of intermediate values in the computation:
 *
 *   MAX_BL_SMALL*[depth]: length for the input f and g at that depth
 *   MAX_BL_LARGE*[depth]: length for the unreduced F and G at that depth
 *
 * MAX_BL_SMALL2[] and MAX_BL_LARGE2[] are for the binary case, for depth
 * up to 10. MAX_BL_SMALL3[] and MAX_BL_LARGE3[] are for the ternary case.
 *
 * Rules:
 *
 *  - Within an array, values grow.
 *
 *  - The 'SMALL' array must have an entry for maximum depth, corresponding
 *    to the size of values used in the binary GCD. There is no such value
 *    for the 'LARGE' array (the binary GCD yields already reduced
 *    coefficients).
 *
 *  - MAX_BL_LARGE[depth] >= MAX_BL_SMALL[depth + 1].
 *
 *  - Values must be large enough to handle the common cases, with some
 *    margins.
 *
 * The following average lengths, in bits, have been measured on thousands
 * of random keys (fg = max length of the absolute value of coefficients
 * of f and g at that depth; FG = idem for the unreduced F and G; for the
 * maximum depth, F and G are the output of binary GCD, multiplied by q;
 * for each value, the average and standard deviation are provided).
 *
 * Binary case:
 *    depth: 10    fg: 6307.52 (24.48)    FG: 6319.66 (24.51)
 *    depth:  9    fg: 3138.35 (12.25)    FG: 9403.29 (27.55)
 *    depth:  8    fg: 1576.87 ( 7.49)    FG: 4703.30 (14.77)
 *    depth:  7    fg:  794.17 ( 4.98)    FG: 2361.84 ( 9.31)
 *    depth:  6    fg:  400.67 ( 3.10)    FG: 1188.68 ( 6.04)
 *    depth:  5    fg:  202.22 ( 1.87)    FG:  599.81 ( 3.87)
 *    depth:  4    fg:  101.62 ( 1.02)    FG:  303.49 ( 2.38)
 *    depth:  3    fg:   50.37 ( 0.53)    FG:  153.65 ( 1.39)
 *    depth:  2    fg:   24.07 ( 0.25)    FG:   78.20 ( 0.73)
 *    depth:  1    fg:   10.99 ( 0.08)    FG:   39.82 ( 0.41)
 *    depth:  0    fg:    4.00 ( 0.00)    FG:   19.61 ( 0.49)
 *
 * Ternary case:
 *    depth:  9    fg: 4975.81 (22.38)    FG: 4988.54 (22.43)
 *    depth:  8    fg: 2472.64 (11.20)    FG: 7409.66 (25.93)
 *    depth:  7    fg: 1243.34 ( 6.78)    FG: 3705.30 (13.66)
 *    depth:  6    fg:  626.61 ( 4.40)    FG: 1861.86 ( 8.50)
 *    depth:  5    fg:  316.34 ( 2.75)    FG:  937.68 ( 5.51)
 *    depth:  4    fg:  159.68 ( 1.61)    FG:  473.48 ( 3.45)
 *    depth:  3    fg:   80.16 ( 0.86)    FG:  239.82 ( 2.06)
 *    depth:  2    fg:   39.58 ( 0.51)    FG:  121.80 ( 1.14)
 *    depth:  1    fg:   18.98 ( 0.13)    FG:   61.93 ( 0.61)
 *    depth:  0    fg:    4.76 ( 0.42)    FG:   34.97 ( 0.28)
 *
 * Integers are actually represented either in binary notation over
 * 31-bit words (signed, using two's complement), or in RNS, modulo
 * many small primes. These small primes are close to, but slightly
 * lower than, 2^31. Use of RNS loses less than two bits, even for
 * the largest values.
 */

static const size_t MAX_BL_SMALL2[] = {
	1, 1, 2, 2, 4, 7, 14, 27, 53, 106, 212
};

static const size_t MAX_BL_LARGE2[] = {
	2, 2, 5, 7, 12, 22, 42, 80, 157, 310
};

static const size_t MAX_BL_SMALL3[] = {
	1, 1, 2, 3, 6, 12, 22, 42, 82, 166
};

static const size_t MAX_BL_LARGE3[] = {
	2, 3, 5, 9, 16, 32, 62, 123, 245
};

/*
 * Minimal recursion depth at which we rebuild intermediate values
 * when reconstructing f and g.
 */
#define DEPTH_INT_FG   4

/*
 * Compute size of temporary array for key generation.
 * Returned size is expressed in bytes.
 */
static size_t
temp_size(unsigned logn, int ternary)
{
#define ALIGN_FP(tt)   ((((tt) + sizeof(fpr) - 1) / sizeof(fpr)) * sizeof(fpr))
#define ALIGN_UW(tt)   ((((tt) + sizeof(uint32_t) - 1) \
                       / sizeof(uint32_t)) * sizeof(uint32_t))

	size_t gmax;
	unsigned depth;

	gmax = 0;

	/*
	 * Compute memory requirements for make_fg() at each depth.
	 */
	for (depth = 0; depth < logn; depth ++) {
		size_t cur;

		if (depth == 0 && ternary) {
			size_t n, dn, tn;

			n = (size_t)3 << (logn - 1);
			dn = (size_t)1 << logn;
			tn = (size_t)1 << (logn - 1);
			cur = (2 * tn + 2 * n + 2 * dn) * sizeof(uint32_t);
			gmax = cur > gmax ? cur : gmax;
		} else {
			size_t n, slen, tlen;

			n = (size_t)1 << (logn - depth);
			slen = ternary
				? MAX_BL_SMALL3[depth]
				: MAX_BL_SMALL2[depth];
			tlen = ternary
				? MAX_BL_SMALL3[depth + 1]
				: MAX_BL_SMALL2[depth + 1];
			cur = (n * tlen + 2 * n * slen + 3 * n)
				* sizeof(uint32_t);
			gmax = cur > gmax ? cur : gmax;
			cur = (n * tlen + 2 * n * slen + slen)
				* sizeof(uint32_t);
			gmax = cur > gmax ? cur : gmax;
		}
	}

	/*
	 * Compute memory requirements for each depth.
	 */
	for (depth = 0; depth <= logn; depth ++) {
		size_t cur, max;

		max = 0;
		if (depth == logn) {
			size_t slen;

			slen = ternary
				? MAX_BL_SMALL3[depth]
				: MAX_BL_SMALL2[depth];
			cur = 8 * slen * sizeof(uint32_t);
			max = cur > max ? cur : max;
		} else if (ternary && depth == 0 && logn > 2) {
			size_t n, tn, hn;

			n = (size_t)3 << (logn - 1);
			tn = (size_t)1 << (logn - 1);
			hn = n >> 1;
			cur = ALIGN_FP(2 * tn * sizeof(uint32_t))
				+ (2 * n + hn) * sizeof(fpr);
			max = cur > max ? cur : max;
			cur = (hn + 4 * n) * sizeof(fpr);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(2 * n * sizeof(uint32_t))
				+ 2 * n * sizeof(fpr);
			max = cur > max ? cur : max;
		} else if (!ternary && depth == 0 && logn > 2) {
			size_t n, hn;

			n = (size_t)1 << logn;
			hn = n >> 1;
			cur = 7 * n * sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(4 * n * sizeof(uint32_t))
				+ n * sizeof(fpr);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(3 * n * sizeof(uint32_t))
				+ (n + hn) * sizeof(fpr);
			max = cur > max ? cur : max;
		} else if (!ternary && depth == 1 && logn > 2) {
			size_t n, hn, slen, dlen, llen;

			n = (size_t)1 << (logn - 1);
			hn = n >> 1;
			slen = MAX_BL_SMALL2[depth];
			dlen = MAX_BL_SMALL2[depth + 1];
			llen = MAX_BL_LARGE2[depth];
			cur = (2 * hn * dlen + 2 * n * llen) * sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = (2 * n * llen + 2 * n * slen + 7 * n)
				* sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = (2 * n * llen + 2 * n * slen + llen)
				* sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = ALIGN_FP((2 * n * llen + 2 * n * slen)
				* sizeof(uint32_t))
				+ 2 * n * sizeof(fpr);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(2 * n * slen * sizeof(uint32_t))
				+ 4 * n * sizeof(fpr);
			max = cur > max ? cur : max;
			cur = (5 * n + hn) * sizeof(fpr);
			max = cur > max ? cur : max;
			cur = ALIGN_FP(2 * n * sizeof(uint32_t))
				+ 2 * n * sizeof(fpr);
			max = cur > max ? cur : max;
		} else {
			size_t n, hn, slen, llen, tmp1, tmp2;

			if (ternary && depth == 0 && logn == 2) {
				n = 6;
				hn = 2;
			} else {
				n = (size_t)1 << (logn - depth);
				hn = n >> 1;
			}
			if (ternary) {
				slen = MAX_BL_SMALL3[depth];
				llen = MAX_BL_LARGE3[depth];
			} else {
				slen = MAX_BL_SMALL2[depth];
				llen = MAX_BL_LARGE2[depth];
			}
			cur = (2 * n * llen + 2 * n * slen + 4 * n)
				* sizeof(uint32_t);
			max = cur > max ? cur : max;
			cur = (2 * n * llen + 2 * n * slen + llen)
				* sizeof(uint32_t);
			max = cur > max ? cur : max;
			tmp1 = ALIGN_UW(
				ALIGN_FP((2 * n * llen + 2 * n * slen)
					* sizeof(uint32_t))
				+ (2 * n + hn) * sizeof(fpr))
				+ n * sizeof(uint32_t);
			tmp2 = ALIGN_FP((2 * n * llen + 2 * n * slen)
				* sizeof(uint32_t))
				+ (3 * n + hn) * sizeof(fpr);
			cur = tmp1 > tmp2 ? tmp1 : tmp2;
			cur = ALIGN_FP(cur) + n * sizeof(fpr);
			max = cur > max ? cur : max;
			cur = ALIGN_UW(
				ALIGN_FP((2 * n * llen + 2 * n * slen)
					* sizeof(uint32_t))
				+ (2 * n + hn) * sizeof(fpr))
				+ (5 * n + n * slen) * sizeof(uint32_t);
			max = cur > max ? cur : max;
		}

		gmax = max > gmax ? max : gmax;
	}

	return gmax;

#undef ALIGN_FP
#undef ALIGN_UW
}

#if MEMCHECK
static const char MEMCHECK_MARK[] = "memcheck";
#endif

/* see falcon.h */
falcon_keygen *
falcon_keygen_new(unsigned logn, int ternary)
{
	falcon_keygen *fk;

	if (ternary) {
		if (logn < 3 || logn > 9) {
			return NULL;
		}
	} else {
		if (logn < 1 || logn > 10) {
			return NULL;
		}
	}
	fk = malloc(sizeof *fk);
	if (fk == NULL) {
		return NULL;
	}
	fk->logn = logn;
	fk->ternary = ternary;
	shake_init(&fk->rng, 512);
	fk->seeded = 0;
	fk->flipped = 0;

	fk->tmp_len = temp_size(logn, ternary);
#if MEMCHECK
	fk->tmp = malloc(fk->tmp_len + sizeof MEMCHECK_MARK);
#else
	fk->tmp = malloc(fk->tmp_len);
#endif
	if (fk->tmp == NULL) {
		free(fk);
		return NULL;
	}
#if MEMCHECK
	memcpy((unsigned char *)fk->tmp + fk->tmp_len,
		MEMCHECK_MARK, sizeof MEMCHECK_MARK);
#endif

	return fk;
}

/* see falcon.h */
void
falcon_keygen_free(falcon_keygen *fk)
{
	if (fk != NULL) {
#if CLEANSE
		cleanse(fk->tmp, fk->tmp_len);
#endif
#if MEMCHECK
		if (memcmp((unsigned char *)fk->tmp + fk->tmp_len,
			MEMCHECK_MARK, sizeof MEMCHECK_MARK) != 0)
		{
			fprintf(stderr,
				"buffer overflow! temp_size() is wrong\n");
			abort();
		}
#endif
		free(fk->tmp);
		free(fk);
	}
}

/* see falcon.h */
size_t
falcon_keygen_max_privkey_size(falcon_keygen *fk)
{
	/*
	 * Uncompressed private key is a one-byte header, followed by
	 * f, g, F and G, each represented as an array of 16-bit values.
	 */
	unsigned logn;
	size_t n;

	logn = fk->logn;
	n = fk->ternary ? ((size_t)3 << (logn - 1)) : ((size_t)1 << logn);
	return 1 + (n << 3);
}

/* see falcon.h */
size_t
falcon_keygen_max_pubkey_size(falcon_keygen *fk)
{
	/*
	 * Public key is a one-byte header, followed by the public
	 * vector h. Each element of h uses 14 bits in the binary case,
	 * 15 bits in the ternary case.
	 */
	unsigned logn;
	unsigned z;

	logn = fk->logn;
	z = fk->ternary ? (45U << (logn - 1)) : (14U << logn);
	return 1 + ((z + 7) >> 3);
}

/* see falcon.h */
void
falcon_keygen_set_seed(falcon_keygen *fk,
	const void *seed, size_t len, int replace)
{
	if (replace) {
		shake_init(&fk->rng, 512);
		shake_inject(&fk->rng, seed, len);
		fk->seeded = 1;
		fk->flipped = 0;
		return;
	}
	if (fk->flipped) {
		unsigned char tmp[32];

		shake_extract(&fk->rng, tmp, sizeof tmp);
		shake_init(&fk->rng, 512);
		shake_inject(&fk->rng, tmp, sizeof tmp);
		fk->flipped = 0;
	}
	shake_inject(&fk->rng, seed, len);
}

static int
rng_ready(falcon_keygen *fk)
{
	if (!fk->seeded) {
		unsigned char tmp[32];

		if (!falcon_get_seed(tmp, sizeof tmp)) {
			return 0;
		}
		falcon_keygen_set_seed(fk, tmp, sizeof tmp, 0);
		fk->seeded = 1;
	}
	if (!fk->flipped) {
		shake_flip(&fk->rng);
		fk->flipped = 1;
	}
	return 1;
}

/*
 * Compute squared norm of a short vector. Returned value is saturated to
 * 2^32-1 if it is not lower than 2^31.
 */
static uint32_t
poly_small_sqnorm(const int16_t *f, unsigned logn, unsigned ter)
{
	size_t n, u;
	uint32_t s, ng;

	n = MKN(logn, ter);
	s = 0;
	ng = 0;
	for (u = 0; u < n; u ++) {
		int32_t z;

		z = f[u];
		s += (uint32_t)(z * z);
		ng |= s;
	}
	return s | -(ng >> 31);
}

/*
 * Align (upwards) the provided 'data' pointer with regards to 'base'
 * so that the offset is a multiple of the size of 'fpr'.
 */
static fpr *
align_fpr(void *base, void *data)
{
	unsigned char *cb, *cd;
	size_t k, km;

	cb = base;
	cd = data;
	k = (size_t)(cd - cb);
	km = k % sizeof(fpr);
	if (km) {
		k += (sizeof(fpr)) - km;
	}
	return (fpr *)(cb + k);
}

/*
 * Align (upwards) the provided 'data' pointer with regards to 'base'
 * so that the offset is a multiple of the size of 'uint32_t'.
 */
static uint32_t *
align_u32(void *base, void *data)
{
	unsigned char *cb, *cd;
	size_t k, km;

	cb = base;
	cd = data;
	k = (size_t)(cd - cb);
	km = k % sizeof(uint32_t);
	if (km) {
		k += (sizeof(uint32_t)) - km;
	}
	return (uint32_t *)(cb + k);
}

/*
 * Convert a small vector to floating point.
 */
static void
poly_small_to_fp(fpr *x, const int16_t *f, unsigned logn, unsigned ter)
{
	size_t n, u;

	n = MKN(logn, ter);
	for (u = 0; u < n; u ++) {
		x[u] = fpr_of(f[u]);
	}
}

/*
 * Input: f,g of degree N = 2^logn; 'depth' is used only to get their
 * individual length. If 'ter' is 1, then this is for the ternary case.
 * This function is never invoked for the top-level of the ternary case,
 * though.
 *
 * Output: f',g' of degree N/2, with the length for 'depth+1'.
 *
 * Values are in RNS; input and/or output may also be in NTT.
 */
static void
make_fg_step(uint32_t *data, unsigned logn, unsigned depth, unsigned ter,
	int in_ntt, int out_ntt)
{
	size_t n, hn, u;
	size_t slen, tlen;
	uint32_t *fd, *gd, *fs, *gs, *gm, *igm, *t1;
	const small_prime *primes;

	n = (size_t)1 << logn;
	hn = n >> 1;
	if (ter) {
		slen = MAX_BL_SMALL3[depth];
		tlen = MAX_BL_SMALL3[depth + 1];
		primes = PRIMES3;
	} else {
		slen = MAX_BL_SMALL2[depth];
		tlen = MAX_BL_SMALL2[depth + 1];
		primes = PRIMES2;
	}

	/*
	 * Prepare room for the result.
	 */
	fd = data;
	gd = fd + hn * tlen;
	fs = gd + hn * tlen;
	gs = fs + n * slen;
	gm = gs + n * slen;
	igm = gm + n;
	t1 = igm + n;
	memmove(fs, data, 2 * n * slen * sizeof *data);

	/*
	 * First slen words: we use the input values directly, and apply
	 * inverse NTT as we go.
	 */
	for (u = 0; u < slen; u ++) {
		uint32_t p, p0i, R2;
		size_t v;
		uint32_t *x;

		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		if (ter) {
			modp_mkgm3(gm, igm, logn, 0, primes[u].g, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[u].g, p, p0i);
		}

		for (v = 0, x = fs + u; v < n; v ++, x += slen) {
			t1[v] = *x;
		}
		if (!in_ntt) {
			if (ter) {
				modp_NTT3(t1, gm, logn, 0, p, p0i);
			} else {
				modp_NTT2(t1, gm, logn, p, p0i);
			}
		}
		for (v = 0, x = fd + u; v < hn; v ++, x += tlen) {
			uint32_t w0, w1;

			w0 = t1[(v << 1) + 0];
			w1 = t1[(v << 1) + 1];
			*x = modp_montymul(
				modp_montymul(w0, w1, p, p0i), R2, p, p0i);
		}
		if (in_ntt) {
			if (ter) {
				modp_iNTT3_ext(fs + u, slen, igm,
					logn, 0, p, p0i);
			} else {
				modp_iNTT2_ext(fs + u, slen, igm,
					logn, p, p0i);
			}
		}

		for (v = 0, x = gs + u; v < n; v ++, x += slen) {
			t1[v] = *x;
		}
		if (!in_ntt) {
			if (ter) {
				modp_NTT3(t1, gm, logn, 0, p, p0i);
			} else {
				modp_NTT2(t1, gm, logn, p, p0i);
			}
		}
		for (v = 0, x = gd + u; v < hn; v ++, x += tlen) {
			uint32_t w0, w1;

			w0 = t1[(v << 1) + 0];
			w1 = t1[(v << 1) + 1];
			*x = modp_montymul(
				modp_montymul(w0, w1, p, p0i), R2, p, p0i);
		}
		if (in_ntt) {
			if (ter) {
				modp_iNTT3_ext(gs + u, slen, igm,
					logn, 0, p, p0i);
			} else {
				modp_iNTT2_ext(gs + u, slen, igm,
					logn, p, p0i);
			}
		}

		if (!out_ntt) {
			if (ter) {
				modp_iNTT3_ext(fd + u, tlen, igm,
					logn - 1, 0, p, p0i);
				modp_iNTT3_ext(gd + u, tlen, igm,
					logn - 1, 0, p, p0i);
			} else {
				modp_iNTT2_ext(fd + u, tlen, igm,
					logn - 1, p, p0i);
				modp_iNTT2_ext(gd + u, tlen, igm,
					logn - 1, p, p0i);
			}
		}
	}

	/*
	 * Since the fs and gs words have been de-NTTized, we can use the
	 * CRT to rebuild the values.
	 */
	zint_rebuild_CRT(fs, slen, slen, n, primes, 1, gm);
	zint_rebuild_CRT(gs, slen, slen, n, primes, 1, gm);

	/*
	 * Remaining words: use modular reductions to extract the values.
	 */
	for (u = slen; u < tlen; u ++) {
		uint32_t p, p0i, R2, Rx;
		size_t v;
		uint32_t *x;

		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		Rx = modp_Rx(slen, p, p0i, R2);
		if (ter) {
			modp_mkgm3(gm, igm, logn, 0, primes[u].g, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[u].g, p, p0i);
		}
		for (v = 0, x = fs; v < n; v ++, x += slen) {
			t1[v] = zint_mod_small_signed(x, slen, p, p0i, R2, Rx);
		}
		if (ter) {
			modp_NTT3(t1, gm, logn, 0, p, p0i);
		} else {
			modp_NTT2(t1, gm, logn, p, p0i);
		}
		for (v = 0, x = fd + u; v < hn; v ++, x += tlen) {
			uint32_t w0, w1;

			w0 = t1[(v << 1) + 0];
			w1 = t1[(v << 1) + 1];
			*x = modp_montymul(
				modp_montymul(w0, w1, p, p0i), R2, p, p0i);
		}
		for (v = 0, x = gs; v < n; v ++, x += slen) {
			t1[v] = zint_mod_small_signed(x, slen, p, p0i, R2, Rx);
		}
		if (ter) {
			modp_NTT3(t1, gm, logn, 0, p, p0i);
		} else {
			modp_NTT2(t1, gm, logn, p, p0i);
		}
		for (v = 0, x = gd + u; v < hn; v ++, x += tlen) {
			uint32_t w0, w1;

			w0 = t1[(v << 1) + 0];
			w1 = t1[(v << 1) + 1];
			*x = modp_montymul(
				modp_montymul(w0, w1, p, p0i), R2, p, p0i);
		}

		if (!out_ntt) {
			if (ter) {
				modp_iNTT3_ext(fd + u, tlen, igm,
					logn - 1, 0, p, p0i);
				modp_iNTT3_ext(gd + u, tlen, igm,
					logn - 1, 0, p, p0i);
			} else {
				modp_iNTT2_ext(fd + u, tlen, igm,
					logn - 1, p, p0i);
				modp_iNTT2_ext(gd + u, tlen, igm,
					logn - 1, p, p0i);
			}
		}
	}
}

/*
 * Input: f,g of degree N = 1.5*2^logn (normal representation).
 *
 * Output: f',g' of degree N/3, with the length for depth 1. Output
 * may be in NTT.
 *
 * Values are in RNS.
 */
static void
make_fg_ternary_top(uint32_t *data, unsigned logn, int out_ntt)
{
	/*
	 * Let f = f0(x^3) + x*f1(x^3) + x^2*f2(x^3).
	 * We define the field norm N(f) as the derminant of the
	 * map y |-> y*f (from the sub-field of degree N/3 to the
	 * field of degree N); this yields:
	 *
	 *   N(f) = f0^3 + f1^3*x + f2^3*x^2 - 3*f0*f1*f2*x
	 *
	 * For w such that w^3 = 1, but w != 1:
	 *
	 *   c1(f) = f(x*w) = f0(x^3) + w*f1(x^3)*x + w^2*f2(x^3)*x^2
	 *   c2(f) = f(x*w^2) = f0(x^3) + w^2*f1(x^3)*x + w*f2(x^3)*x^2
	 *
	 * It can be verified that:
	 *
	 *   N(f)(x^3) = f*c1(f)*c2(f)
	 *
	 * If c(f) = c1(f)*c2(f), then:
	 *
	 *   c(f) = (f0^2)(x^3)
	 *        - (f0*f1)(x^3) * x
	 *        + (f1^2 - f0*f2)(x^3) * x^2
	 *        - (f1*f2)(x^3) * x^3
	 *        + (f2^2)(x^3) * x^4
	 *
	 * Therefore, if the coefficients of f are integers, then so
	 * are the coefficients of c(f).
	 *
	 * Thus, the NTRU equation:
	 *   f*G - g*F = q
	 * can be solved recursively: we get F' and G' such that:
	 *   N(f)*G' - N(g)*F' = q
	 * and we then set:
	 *   F = F'(x^3) * c(g)
	 *   G = G'(x^3) * c(f)
	 *
	 * In this function, we simply compute N(f) and N(g). Since the
	 * coefficients of f and g are very small, all computations can
	 * be done modulo a single small prime.
	 *
	 * Moreover, in NTT representation, we have:
	 *
	 *   N(f)(x^3) = f(x)*c1(f)(x)*c2(f)(x)
	 *             = f(x)*f(x*w)*f(x*w^2)
	 *
	 * which allows us to compute the coefficients of N(f) by simply
	 * multiplying together the coefficients of f.
	 */

	size_t n, dn, tn, u, v;
	uint32_t *gm, *igm, *fd, *gd, *fs, *gs;
	uint32_t p, p0i, R2, R3;

	n = MKN(logn, 1);
	dn = MKN(logn, 0);
	tn = MKN(logn - 1, 0);
	fd = data;
	gd = fd + tn;
	fs = gd + tn;
	gs = fs + n;
	gm = gs + n;
	igm = gm + dn;
	memmove(fs, data, n * 2 * sizeof *data);

	p = PRIMES3[0].p;
	p0i = modp_ninv31(p);
	R2 = modp_R2(p, p0i);

	modp_mkgm3(gm, igm, logn, 1, PRIMES3[0].g, p, p0i);
	modp_NTT3(fs, gm, logn, 1, p, p0i);
	modp_NTT3(gs, gm, logn, 1, p, p0i);

	R3 = modp_montymul(R2, R2, p, p0i);

	for (u = 0, v = 0; u < n; u += 3, v ++) {
		fd[v] = modp_montymul(R3, modp_montymul(fs[u],
			modp_montymul(fs[u + 1], fs[u + 2], p, p0i),
			p, p0i), p, p0i);
		gd[v] = modp_montymul(R3, modp_montymul(gs[u],
			modp_montymul(gs[u + 1], gs[u + 2], p, p0i),
			p, p0i), p, p0i);
	}
	if (!out_ntt) {
		modp_iNTT3(fd, igm, logn - 1, 0, p, p0i);
		modp_iNTT3(gd, igm, logn - 1, 0, p, p0i);
	}
}

/*
 * Compute f and g at a specific depth, in RNS notation.
 *
 * Returned values are stored in the data[] array, at slen words per integer.
 *
 * Conditions:
 *   0 <= depth <= logn
 *
 * Space use in data[]: enough room for any two successive values (f', g',
 * f and g).
 */
static void
make_fg(uint32_t *data, const int16_t *f, const int16_t *g,
	unsigned logn, unsigned ter, unsigned depth, int out_ntt)
{
	size_t n, u;
	uint32_t *ft, *gt, p0;
	unsigned d;
	const small_prime *primes;

	n = MKN(logn, ter);
	ft = data;
	gt = ft + n;
	primes = ter ? PRIMES3 : PRIMES2;
	p0 = primes[0].p;
	for (u = 0; u < n; u ++) {
		ft[u] = modp_set(f[u], p0);
		gt[u] = modp_set(g[u], p0);
	}

	if (depth == 0 && out_ntt) {
		uint32_t *gm, *igm;
		uint32_t p, p0i;

		p = primes[0].p;
		p0i = modp_ninv31(p);
		gm = gt + n;
		igm = gm + MKN(logn, 0);
		if (ter) {
			modp_mkgm3(gm, igm, logn, 1, primes[0].g, p, p0i);
			modp_NTT3(ft, gm, logn, 1, p, p0i);
			modp_NTT3(gt, gm, logn, 1, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[0].g, p, p0i);
			modp_NTT2(ft, gm, logn, p, p0i);
			modp_NTT2(gt, gm, logn, p, p0i);
		}
		return;
	}

	if (ter) {
		make_fg_ternary_top(data, logn, depth > 1 || out_ntt);
		for (d = 1; d < depth; d ++) {
			make_fg_step(data, logn - d, d, 1,
				1, (d + 1) < depth || out_ntt);
		}
	} else {
		for (d = 0; d < depth; d ++) {
			make_fg_step(data, logn - d, d, 0,
				d != 0, (d + 1) < depth || out_ntt);
		}
	}
}

/*
 * Solving the NTRU equation, deepest level: compute the resultants of
 * f and g with X^N+1, and use binary GCD. The F and G values are
 * returned in fk->tmp.
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_deepest(falcon_keygen *fk, const int16_t *f, const int16_t *g)
{
	unsigned logn;
	size_t len;
	uint32_t *Fp, *Gp, *fp, *gp, *t1, q;
	const small_prime *primes;

	logn = fk->logn;
	if (fk->ternary) {
		len = MAX_BL_SMALL3[logn];
		primes = PRIMES3;
	} else {
		len = MAX_BL_SMALL2[logn];
		primes = PRIMES2;
	}

	Fp = fk->tmp;
	Gp = Fp + len;
	fp = Gp + len;
	gp = fp + len;
	t1 = gp + len;

	make_fg(fp, f, g, logn, fk->ternary, logn, 0);

	/*
	 * We use the CRT to rebuild the resultants as big integers.
	 * There are two such big integers.
	 */
	zint_rebuild_CRT(fp, len, len, 2, primes, 0, t1);

	/*
	 * Apply the binary GCD. The zint_bezout() function works only
	 * if both inputs are odd.
	 */
	if (!zint_bezout(Gp, Fp, fp, gp, len, t1)) {
		return 0;
	}

	/*
	 * Multiply the two values by the target value q. Values must
	 * fit in the destination arrays.
	 */
	q = fk->ternary ? 18433 : 12289;
	if (zint_mul_small(Fp, len, q) != 0
		|| zint_mul_small(Gp, len, q) != 0)
	{
		return 0;
	}

	return 1;
}

/*
 * Solving the NTRU equation, intermediate level. Upon entry, the F and G
 * from the previous level should be in the fk->tmp array.
 * This function MAY be invoked for the top-level (in which case depth = 0).
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_intermediate(falcon_keygen *fk,
	const int16_t *f, const int16_t *g, unsigned depth)
{
	/*
	 * In this function, 'logn' is the log2 of the degree for
	 * this step. If N = 2^logn, then:
	 *  - the F and G values already in fk->tmp (from the deeper
	 *    levels) have degree N/2;
	 *  - this function should return F and G of degree N.
	 */
	unsigned logn_top, logn, full;
	size_t n, hn, slen, dlen, llen, FGlen, u;
	uint32_t *Fd, *Gd, *Ft, *Gt, *ft, *gt, *t1;
	fpr *rt1, *rt2, *rt3, *rt4, *rt5;
	uint32_t maxbl_f, maxbl_g, maxbl_fg, maxbl_FG, prev_maxbl_FG;
	uint32_t *x, *y;
	int32_t *k;
	const small_prime *primes;

	logn_top = fk->logn;
	logn = logn_top - depth;

	/*
	 * In the ternary case _and_ top-level, n is a multiple of 3,
	 * and hn = n/3. Otherwise, n is a power of 2, and hn = n/2.
	 */
	if (fk->ternary && depth == 0) {
		full = 1;
		n = (size_t)3 << (logn - 1);
		hn = (size_t)1 << (logn - 1);
	} else {
		full = 0;
		n = (size_t)1 << logn;
		hn = n >> 1;
	}

	/*
	 * slen = size for our input f and g; also size of the reduced
	 *        F and G we return (degree N)
	 *
	 * dlen = size of the F and G obtained from the deeper level
	 *        (degree N/2 or N/3)
	 *
	 * llen = size for intermediary F and G before reduction (degree N)
	 *
	 * We build our non-reduced F and G as two independent halves each,
	 * of degree N/2 (F = F0 + X*F1, G = G0 + X*G1).
	 */
	if (fk->ternary) {
		slen = MAX_BL_SMALL3[depth];
		dlen = MAX_BL_SMALL3[depth + 1];
		llen = MAX_BL_LARGE3[depth];
		primes = PRIMES3;
	} else {
		slen = MAX_BL_SMALL2[depth];
		dlen = MAX_BL_SMALL2[depth + 1];
		llen = MAX_BL_LARGE2[depth];
		primes = PRIMES2;
	}

	/*
	 * Fd and Gd are the F and G from the deeper level.
	 */
	Fd = fk->tmp;
	Gd = Fd + dlen * hn;

	/*
	 * Compute the input f and g for this level. Note that we get f
	 * and g in RNS + NTT representation.
	 */
	ft = Gd + dlen * hn;
	make_fg(ft, f, g, logn_top, fk->ternary, depth, 1);

	/*
	 * Move the newly computed f and g to make room for our candidate
	 * F and G (unreduced).
	 */
	Ft = fk->tmp;
	Gt = Ft + n * llen;
	t1 = Gt + n * llen;
	memmove(t1, ft, 2 * n * slen * sizeof *ft);
	ft = t1;
	gt = ft + slen * n;
	t1 = gt + slen * n;

	/*
	 * Move Fd and Gd _after_ f and g.
	 */
	memmove(t1, Fd, 2 * hn * dlen * sizeof *Fd);
	Fd = t1;
	Gd = Fd + hn * dlen;

	/*
	 * We reduce Fd and Gd modulo all the small primes we will need,
	 * and store the values in Ft and Gt (only n/2 values in each).
	 */
	for (u = 0; u < llen; u ++) {
		uint32_t p, p0i, R2, Rx;
		size_t v;
		uint32_t *xs, *ys, *xd, *yd;

		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		Rx = modp_Rx(dlen, p, p0i, R2);
		for (v = 0, xs = Fd, ys = Gd, xd = Ft + u, yd = Gt + u;
			v < hn;
			v ++, xs += dlen, ys += dlen, xd += llen, yd += llen)
		{
			*xd = zint_mod_small_signed(xs, dlen, p, p0i, R2, Rx);
			*yd = zint_mod_small_signed(ys, dlen, p, p0i, R2, Rx);
		}
	}

	/*
	 * We do not need Fd and Gd after that point.
	 */

	/*
	 * Compute our F and G modulo sufficiently many small primes.
	 */
	for (u = 0; u < llen; u ++) {
		uint32_t p, p0i, R2;
		uint32_t *gm, *igm, *fx, *gx, *Fp, *Gp;
		size_t v;

		/*
		 * All computations are done modulo p.
		 */
		p = primes[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);

		/*
		 * If we processed slen words, then f and g have been
		 * de-NTTized, and are in RNS; we can rebuild them.
		 */
		if (u == slen) {
			zint_rebuild_CRT(ft, slen, slen, n, primes, 1, t1);
			zint_rebuild_CRT(gt, slen, slen, n, primes, 1, t1);
		}

		gm = t1;
		if (full) {
			igm = gm + ((size_t)1 << logn);
			fx = igm + ((size_t)1 << logn);
		} else {
			gm = t1;
			igm = gm + n;
			fx = igm + n;
		}
		gx = fx + n;

		if (fk->ternary) {
			modp_mkgm3(gm, igm, logn, full, primes[u].g, p, p0i);
		} else {
			modp_mkgm2(gm, igm, logn, primes[u].g, p, p0i);
		}

		if (u < slen) {
			size_t v;

			for (v = 0, x = ft + u, y = gt + u;
				v < n; v ++, x += slen, y += slen)
			{
				fx[v] = *x;
				gx[v] = *y;
			}
			if (fk->ternary) {
				modp_iNTT3_ext(ft + u, slen, igm,
					logn, full, p, p0i);
				modp_iNTT3_ext(gt + u, slen, igm,
					logn, full, p, p0i);
			} else {
				modp_iNTT2_ext(ft + u, slen, igm,
					logn, p, p0i);
				modp_iNTT2_ext(gt + u, slen, igm,
					logn, p, p0i);
			}
		} else {
			uint32_t Rx;
			size_t v;

			Rx = modp_Rx(slen, p, p0i, R2);
			for (v = 0, x = ft, y = gt;
				v < n; v ++, x += slen, y += slen)
			{
				fx[v] = zint_mod_small_signed(x, slen,
					p, p0i, R2, Rx);
				gx[v] = zint_mod_small_signed(y, slen,
					p, p0i, R2, Rx);
			}
			if (fk->ternary) {
				modp_NTT3(fx, gm, logn, full, p, p0i);
				modp_NTT3(gx, gm, logn, full, p, p0i);
			} else {
				modp_NTT2(fx, gm, logn, p, p0i);
				modp_NTT2(gx, gm, logn, p, p0i);
			}
		}

		/*
		 * Get F' and G' modulo p and in NTT representation
		 * (they have degree n/2 or n/3). These values were
		 * computed in a previous step, and stored in Ft and Gt.
		 */
		Fp = gx + n;
		Gp = Fp + hn;
		for (v = 0, x = Ft + u, y = Gt + u;
			v < hn; v ++, x += llen, y += llen)
		{
			Fp[v] = *x;
			Gp[v] = *y;
		}
		if (fk->ternary) {
			modp_NTT3(Fp, gm, logn - 1, 0, p, p0i);
			modp_NTT3(Gp, gm, logn - 1, 0, p, p0i);
		} else {
			modp_NTT2(Fp, gm, logn - 1, p, p0i);
			modp_NTT2(Gp, gm, logn - 1, p, p0i);
		}

		/*
		 * Compute our F and G modulo p.
		 *
		 * General case:
		 *
		 *   we divide degree by d = 2 or 3
		 *   f'(x^d) = N(f)(x^d) = f * adj(f)
		 *   g'(x^d) = N(g)(x^d) = g * adj(g)
		 *   f'*G' - g'*F' = q
		 *   F = F'(x^d) * adj(g)
		 *   G = G'(x^d) * adj(f)
		 *
		 * We compute things in the NTT. We group roots of phi
		 * such that all roots x in a group share the same x^d.
		 * If the roots in a group are x_1, x_2... x_d, then:
		 *
		 *   N(f)(x_1^d) = f(x_1)*f(x_2)*...*f(x_d)
		 *
		 * Thus, we have:
		 *
		 *   G(x_1) = f(x_2)*f(x_3)*...*f(x_d)*G'(x_1^d)
		 *   G(x_2) = f(x_1)*f(x_3)*...*f(x_d)*G'(x_1^d)
		 *   ...
		 *   G(x_d) = f(x_1)*f(x_2)*...*f(x_{d-1})*G'(x_1^d)
		 *
		 * In all cases, we can thus compute F and G in NTT
		 * representation by a few simple multiplications.
		 * Moreover, in our chosen NTT representation, roots
		 * from the same group are consecutive in RAM.
		 */
		if (full) {
			uint32_t R3;
			size_t v2;

			R3 = modp_montymul(R2, R2, p, p0i);
			for (v = 0, v2 = 0, x = Ft + u, y = Gt + u; v < n;
				v += 3, v2 ++, x += 3 * llen, y += 3 * llen)
			{
				uint32_t ftA, ftB, ftC, gtA, gtB, gtC;
				uint32_t mFp, mGp;

				ftA = fx[v + 0];
				ftB = fx[v + 1];
				ftC = fx[v + 2];
				gtA = gx[v + 0];
				gtB = gx[v + 1];
				gtC = gx[v + 2];
				mFp = modp_montymul(Fp[v2], R3, p, p0i);
				mGp = modp_montymul(Gp[v2], R3, p, p0i);
				x[0] = modp_montymul(mFp,
					modp_montymul(gtB, gtC, p, p0i),
					p, p0i);
				x[llen] = modp_montymul(mFp,
					modp_montymul(gtC, gtA, p, p0i),
					p, p0i);
				x[2 * llen] = modp_montymul(mFp,
					modp_montymul(gtA, gtB, p, p0i),
					p, p0i);
				y[0] = modp_montymul(mGp,
					modp_montymul(ftB, ftC, p, p0i),
					p, p0i);
				y[llen] = modp_montymul(mGp,
					modp_montymul(ftC, ftA, p, p0i),
					p, p0i);
				y[2 * llen] = modp_montymul(mGp,
					modp_montymul(ftA, ftB, p, p0i),
					p, p0i);
			}
		} else {
			for (v = 0, x = Ft + u, y = Gt + u; v < hn;
				v ++, x += (llen << 1), y += (llen << 1))
			{
				uint32_t ftA, ftB, gtA, gtB;
				uint32_t mFp, mGp;

				ftA = fx[(v << 1) + 0];
				ftB = fx[(v << 1) + 1];
				gtA = gx[(v << 1) + 0];
				gtB = gx[(v << 1) + 1];
				mFp = modp_montymul(Fp[v], R2, p, p0i);
				mGp = modp_montymul(Gp[v], R2, p, p0i);
				x[0] = modp_montymul(gtB, mFp, p, p0i);
				x[llen] = modp_montymul(gtA, mFp, p, p0i);
				y[0] = modp_montymul(ftB, mGp, p, p0i);
				y[llen] = modp_montymul(ftA, mGp, p, p0i);
			}
		}
		if (fk->ternary) {
			modp_iNTT3_ext(Ft + u, llen, igm, logn, full, p, p0i);
			modp_iNTT3_ext(Gt + u, llen, igm, logn, full, p, p0i);
		} else {
			modp_iNTT2_ext(Ft + u, llen, igm, logn, p, p0i);
			modp_iNTT2_ext(Gt + u, llen, igm, logn, p, p0i);
		}
	}

	/*
	 * Rebuild F and G with the CRT.
	 */
	zint_rebuild_CRT(Ft, llen, llen, n, primes, 1, t1);
	zint_rebuild_CRT(Gt, llen, llen, n, primes, 1, t1);

	/*
	 * At that point, Ft, Gt, ft and gt are consecutive in RAM (in that
	 * order).
	 */

	/*
	 * Apply Babai reduction to bring back F and G to size slen.
	 *
	 * We use the FFT to compute successive approximations of the
	 * reduction coefficient. We first isolate the top bits of
	 * the coefficients of f and g, and convert them to floating
	 * point; with the FFT, we compute adj(f), adj(g), and
	 * 1/(f*adj(f)+g*adj(g)).
	 *
	 * Then, we repeatedly apply the following:
	 *
	 *   - Get the top bits of the coefficients of F and G into
	 *     floating point, and use the FFT to compute:
	 *        (F*adj(f)+G*adj(g))/(f*adj(f)+g*adj(g))
	 *
	 *   - Convert back that value into normal representation, and
	 *     round it to the nearest integers, yielding a polynomial k.
	 *     Proper scaling is applied to f, g, F and G so that the
	 *     coefficients fit on 32 bits (signed).
	 *
	 *   - Subtract k*f from F and k*g from G.
	 *
	 * The process is repeated as long as it works, i.e. it decreases
	 * the maximum bit length of coefficients of F and G. This will
	 * normally bring down F and G down from llen to slen words at
	 * most.
	 */

	/*
	 * Memory layout:
	 *  - We need to compute and keep adj(f), adj(g), and
	 *    1/(f*adj(f)+g*adj(g)) (sizes N, N and N/2 fp numbers,
	 *    respectively).
	 *  - At each iteration we need two extra fp buffer (N fp values),
	 *    and produce a k (N 32-bit words). k will be shared with one
	 *    of the fp buffers.
	 *  - To compute k*f and k*g efficiently (with the NTT), we need
	 *    some extra room; we reuse the space of the temporary buffers.
	 *
	 * Arrays of 'fpr' are obtained from the temporary array itself.
	 * We ensure that the base is at a properly aligned offset (the
	 * source array fk->tmp was obtained with malloc(), and is thus
	 * already aligned).
	 */

	rt3 = align_fpr(fk->tmp, t1);
	rt4 = rt3 + n;
	rt5 = rt4 + n;
	rt1 = rt5 + (n >> 1);
	k = (int32_t *)align_u32(fk->tmp, rt1);
	rt2 = align_fpr(fk->tmp, k + n);
	if (rt2 < (rt1 + n)) {
		rt2 = rt1 + n;
	}
	t1 = (uint32_t *)k + n;

	/*
	 * Get the maximum bit lengths of f and g. f and g are scaled
	 * down by maxbl_fg bits, so that values will be below 1.
	 */
	maxbl_f = poly_max_bitlength(ft, slen, slen, logn, full);
	maxbl_g = poly_max_bitlength(gt, slen, slen, logn, full);
	maxbl_fg = maxbl_f < maxbl_g ? maxbl_g : maxbl_f;

	/*
	 * Compute 1/(f*adj(f)+g*adj(g)) in rt5. We also keep adj(f)
	 * and adj(g) in rt3 and rt4, respectively.
	 */
	poly_big_to_fp(rt3, ft, slen, slen, logn, full, maxbl_fg, maxbl_fg);
	poly_big_to_fp(rt4, gt, slen, slen, logn, full, maxbl_fg, maxbl_fg);

	if (fk->ternary) {
		falcon_FFT3(rt3, logn, full);
		falcon_FFT3(rt4, logn, full);
		falcon_poly_invnorm2_fft3(rt5, rt3, rt4, logn, full);
		falcon_poly_adj_fft3(rt3, logn, full);
		falcon_poly_adj_fft3(rt4, logn, full);
	} else {
		falcon_FFT(rt3, logn);
		falcon_FFT(rt4, logn);
		falcon_poly_invnorm2_fft(rt5, rt3, rt4, logn);
		falcon_poly_adj_fft(rt3, logn);
		falcon_poly_adj_fft(rt4, logn);
	}

	/*
	 * Reduce F and G repeatedly while the processing works.
	 */
	prev_maxbl_FG = (uint32_t)-1;
	FGlen = llen;
	for (;;) {
		uint32_t maxbl_F, maxbl_G, scale_FG, scale_k;
		uint64_t max_kx;

		/*
		 * Get current maximum bit length of F and G. Adjust
		 * the world length accordingly (keeping room for a
		 * dozen extra bits for intermediate computations).
		 */
		maxbl_F = poly_max_bitlength(Ft, FGlen, llen, logn, full);
		maxbl_G = poly_max_bitlength(Gt, FGlen, llen, logn, full);
		maxbl_FG = maxbl_F < maxbl_G ? maxbl_G : maxbl_F;
		while ((FGlen * 31) >= (maxbl_FG + 43)) {
			FGlen --;
		}

		/*
		 * We stop when F and G have been made smaller than
		 * f and g, or when the last reduction round did not
		 * manage to reduce the maximum bit length.
		 */
		if (maxbl_FG <= maxbl_fg || maxbl_FG >= prev_maxbl_FG) {
			break;
		}
		prev_maxbl_FG = maxbl_FG;

		/*
		 * We aim at getting the coefficients of k on 30 bits;
		 * we'll scale them down afterwards if required.
		 */
		scale_FG = maxbl_FG < 30 ? 0 : maxbl_FG - 30;
		poly_big_to_fp(rt1, Ft, FGlen, llen,
			logn, full, maxbl_FG, scale_FG);
		poly_big_to_fp(rt2, Gt, FGlen, llen,
			logn, full, maxbl_FG, scale_FG);

		if (fk->ternary) {
			falcon_FFT3(rt1, logn, full);
			falcon_FFT3(rt2, logn, full);
			falcon_poly_mul_fft3(rt1, rt3, logn, full);
			falcon_poly_mul_fft3(rt2, rt4, logn, full);
			falcon_poly_add_fft3(rt2, rt1, logn, full);
			falcon_poly_mul_autoadj_fft3(rt2, rt5, logn, full);
			falcon_iFFT3(rt2, logn, full);
		} else {
			falcon_FFT(rt1, logn);
			falcon_FFT(rt2, logn);
			falcon_poly_mul_fft(rt1, rt3, logn);
			falcon_poly_mul_fft(rt2, rt4, logn);
			falcon_poly_add_fft(rt2, rt1, logn);
			falcon_poly_mul_autoadj_fft(rt2, rt5, logn);
			falcon_iFFT(rt2, logn);
		}

		/*
		 * Get the maximum coefficient of k, then adjust scaling
		 * so that they all fit on 31 bits.
		 */
		max_kx = 0;
		for (u = 0; u < n; u ++) {
			int64_t kx;

			kx = fpr_rint(rt2[u]);
			if (kx < 0) {
				kx = -kx;
			}
			if ((uint64_t)kx > max_kx) {
				max_kx = kx;
			}
		}
		if (max_kx >= ((uint64_t)1 << 62)) {
			return 0;
		}
		scale_k = bitlength((uint32_t)(max_kx >> 31));

		/*
		 * We need to scale down k by at least scale_k bits. The
		 * final scale will be: scale_FG + scale_k - maxbl_fg;
		 * we also need this value to be nonnegative.
		 */
		if (scale_k + scale_FG < maxbl_fg) {
			scale_k = maxbl_fg - scale_FG;
			if (scale_k > 62) {
				break;
			}
		}

		scale_FG += scale_k;

		/*
		 * Get the coefficients of k as int32_t.
		 */
		for (u = 0; u < n; u ++) {
			int64_t kx, ks;

			kx = fpr_rint(rt2[u]);
			if (kx < 0) {
				ks = -(int32_t)((-kx) >> scale_k);
			} else {
				ks = (int32_t)(kx >> scale_k);
			}
			k[u] = ks;
		}

		/*
		 * If we are at low depth, then we use the NTT to
		 * compute k*f and k*g.
		 */
		if (depth <= DEPTH_INT_FG) {
			poly_sub_scaled_ntt(Ft, FGlen, llen, ft, slen, slen,
				k, scale_FG - maxbl_fg,
				logn, full, fk->ternary, t1);
			poly_sub_scaled_ntt(Gt, FGlen, llen, gt, slen, slen,
				k, scale_FG - maxbl_fg,
				logn, full, fk->ternary, t1);
		} else {
			poly_sub_scaled(Ft, FGlen, llen, ft, slen, slen,
				k, scale_FG - maxbl_fg,
				logn, full, fk->ternary);
			poly_sub_scaled(Gt, FGlen, llen, gt, slen, slen,
				k, scale_FG - maxbl_fg,
				logn, full, fk->ternary);
		}
	}

	/*
	 * If we could not reduce F and G so that they fit in slen, then
	 * this is a failure.
	 */
	if (maxbl_FG > (slen * 31)) {
		return 0;
	}

	/*
	 * Compress encoding of all values to 'slen' words (this is the
	 * expected output format).
	 */
	for (u = 0, x = fk->tmp, y = fk->tmp;
		u < (n << 1); u ++, x += slen, y += llen)
	{
		memmove(x, y, slen * sizeof *y);
	}

	/*
	 * Values might actually be shorter, in which case we must
	 * sign-extend them (caller expects it).
	 */
	if (FGlen < slen) {
		for (u = 0, x = fk->tmp; u < (n << 1); u ++, x += slen) {
			uint32_t sign;
			size_t v;

			sign = -(x[FGlen - 1] >> 30) >> 1;
			for (v = FGlen; v < slen; v ++) {
				x[v] = sign;
			}
		}
	}

	return 1;
}

/*
 * Solving the NTRU equation, binary case, depth = 1. Upon entry, the
 * F and G from the previous level should be in the fk->tmp array.
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_binary_depth1(falcon_keygen *fk,
	const int16_t *f, const int16_t *g)
{
	/*
	 * The first half of this function is a copy of the corresponding
	 * part in solve_NTRU_intermediate(), for the reconstruction of
	 * the unreduced F and G. The second half (Babai reduction) is
	 * done differently, because the unreduced F and G fit in 53 bits
	 * of precision, allowing a much simpler process with lower RAM
	 * usage.
	 */
	unsigned depth, logn_top, logn;
	size_t n_top, n, hn, slen, dlen, llen, u;
	uint32_t *Fd, *Gd, *Ft, *Gt, *ft, *gt, *t1;
	fpr *rt1, *rt2, *rt3, *rt4, *rt5, *rt6;
	uint32_t maxbl_f, maxbl_g, maxbl_fg, maxbl_F, maxbl_G, maxbl_FG;
	uint32_t *x, *y;

	depth = 1;
	logn_top = fk->logn;
	n_top = (size_t)1 << logn_top;
	logn = logn_top - depth;
	n = (size_t)1 << logn;
	hn = n >> 1;

	/*
	 * Equations are:
	 *
	 *   f' = f0^2 - X^2*f1^2
	 *   g' = g0^2 - X^2*g1^2
	 *   F' and G' are a solution to f'G' - g'F' = q (from deeper levels)
	 *   F = F'*(g0 - X*g1)
	 *   G = G'*(f0 - X*f1)
	 *
	 * f0, f1, g0, g1, f', g', F' and G' are all "compressed" to
	 * degree N/2 (their odd-indexed coefficients are all zero).
	 */

	/*
	 * slen = size for our input f and g; also size of the reduced
	 *        F and G we return (degree N)
	 *
	 * dlen = size of the F and G obtained from the deeper level
	 *        (degree N/2)
	 *
	 * llen = size for intermediary F and G before reduction (degree N)
	 *
	 * We build our non-reduced F and G as two independent halves each,
	 * of degree N/2 (F = F0 + X*F1, G = G0 + X*G1).
	 */
	slen = MAX_BL_SMALL2[depth];
	dlen = MAX_BL_SMALL2[depth + 1];
	llen = MAX_BL_LARGE2[depth];

	/*
	 * Fd and Gd are the F and G from the deeper level. Ft and Gt
	 * are the destination arrays for the unreduced F and G.
	 */
	Fd = fk->tmp;
	Gd = Fd + dlen * hn;
	Ft = Gd + dlen * hn;
	Gt = Ft + llen * n;

	/*
	 * We reduce Fd and Gd modulo all the small primes we will need,
	 * and store the values in Ft and Gt.
	 */
	for (u = 0; u < llen; u ++) {
		uint32_t p, p0i, R2, Rx;
		size_t v;
		uint32_t *xs, *ys, *xd, *yd;

		p = PRIMES2[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);
		Rx = modp_Rx(dlen, p, p0i, R2);
		for (v = 0, xs = Fd, ys = Gd, xd = Ft + u, yd = Gt + u;
			v < hn;
			v ++, xs += dlen, ys += dlen, xd += llen, yd += llen)
		{
			*xd = zint_mod_small_signed(xs, dlen, p, p0i, R2, Rx);
			*yd = zint_mod_small_signed(ys, dlen, p, p0i, R2, Rx);
		}
	}

	/*
	 * Now Fd and Gd are not needed anymore; we can squeeze them out.
	 */
	memmove(fk->tmp, Ft, llen * n * sizeof(uint32_t));
	Ft = fk->tmp;
	memmove(Ft + llen * n, Gt, llen * n * sizeof(uint32_t));
	Gt = Ft + llen * n;
	ft = Gt + llen * n;
	gt = ft + slen * n;

	t1 = gt + slen * n;

	/*
	 * Compute our F and G modulo sufficiently many small primes.
	 */
	for (u = 0; u < llen; u ++) {
		uint32_t p, p0i, R2;
		uint32_t *gm, *igm, *fx, *gx, *Fp, *Gp;
		unsigned e;
		size_t v;

		/*
		 * All computations are done modulo p.
		 */
		p = PRIMES2[u].p;
		p0i = modp_ninv31(p);
		R2 = modp_R2(p, p0i);

		/*
		 * We recompute things from the source f and g, of full
		 * degree. However, we will need only the n first elements
		 * of the inverse NTT table (igm); the call to modp_mkgm()
		 * below will fill n_top elements in igm[] (thus overflowing
		 * into fx[]) but later code will overwrite these extra
		 * elements.
		 */
		gm = t1;
		igm = gm + n_top;
		fx = igm + n;
		gx = fx + n_top;
		modp_mkgm2(gm, igm, logn_top, PRIMES2[u].g, p, p0i);

		/*
		 * Set ft and gt to f and g modulo p, respectively.
		 */
		for (v = 0; v < n_top; v ++) {
			fx[v] = modp_set(f[v], p);
			gx[v] = modp_set(g[v], p);
		}

		/*
		 * Convert to NTT and compute our f and g.
		 */
		modp_NTT2(fx, gm, logn_top, p, p0i);
		modp_NTT2(gx, gm, logn_top, p, p0i);
		for (e = logn_top; e > logn; e --) {
			modp_poly_rec_res(fx, e, p, p0i, R2);
			modp_poly_rec_res(gx, e, p, p0i, R2);
		}

		/*
		 * From that point onward, we only need tables for
		 * degree n, so we can save some space.
		 */
		if (depth > 0) {
			memmove(gm + n, igm, n * sizeof *igm);
			igm = gm + n;
			memmove(igm + n, fx, n * sizeof *ft);
			fx = igm + n;
			memmove(fx + n, gx, n * sizeof *gt);
			gx = fx + n;
		}

		/*
		 * Get F' and G' modulo p and in NTT representation
		 * (they have degree n/2). These values were computed
		 * in a previous step, and stored in Ft and Gt.
		 */
		Fp = gx + n;
		Gp = Fp + hn;
		for (v = 0, x = Ft + u, y = Gt + u;
			v < hn; v ++, x += llen, y += llen)
		{
			Fp[v] = *x;
			Gp[v] = *y;
		}
		modp_NTT2(Fp, gm, logn - 1, p, p0i);
		modp_NTT2(Gp, gm, logn - 1, p, p0i);

		/*
		 * Compute our F and G modulo p.
		 *
		 * Equations are:
		 *
		 *   f'(x^2) = N(f)(x^2) = f * adj(f)
		 *   g'(x^2) = N(g)(x^2) = g * adj(g)
		 *
		 *   f'*G' - g'*F' = q
		 *
		 *   F = F'(x^2) * adj(g)
		 *   G = G'(x^2) * adj(f)
		 *
		 * The NTT representation of f is f(w) for all w which
		 * are roots of phi. In the binary case, as well as in
		 * the ternary case for all depth except the deepest,
		 * these roots can be grouped in pairs (w,-w), and we
		 * then have:
		 *
		 *   f(w) = adj(f)(-w)
		 *   f(-w) = adj(f)(w)
		 *
		 * and w^2 is then a root for phi at the half-degree.
		 *
		 * At the deepest level in the ternary case, this still
		 * holds, in the following sense: the roots of x^2-x+1
		 * are (w,-w^2) (for w^3 = -1, and w != -1), and we
		 * have:
		 *
		 *   f(w) = adj(f)(-w^2)
		 *   f(-w^2) = adj(f)(w)
		 *
		 * In all case, we can thus compute F and G in NTT
		 * representation by a few simple multiplications.
		 * Moreover, the two roots for each pair are consecutive
		 * in our bit-reversal encoding.
		 */
		for (v = 0, x = Ft + u, y = Gt + u;
			v < hn; v ++, x += (llen << 1), y += (llen << 1))
		{
			uint32_t ftA, ftB, gtA, gtB;
			uint32_t mFp, mGp;

			ftA = fx[(v << 1) + 0];
			ftB = fx[(v << 1) + 1];
			gtA = gx[(v << 1) + 0];
			gtB = gx[(v << 1) + 1];
			mFp = modp_montymul(Fp[v], R2, p, p0i);
			mGp = modp_montymul(Gp[v], R2, p, p0i);
			x[0] = modp_montymul(gtB, mFp, p, p0i);
			x[llen] = modp_montymul(gtA, mFp, p, p0i);
			y[0] = modp_montymul(ftB, mGp, p, p0i);
			y[llen] = modp_montymul(ftA, mGp, p, p0i);
		}
		modp_iNTT2_ext(Ft + u, llen, igm, logn, p, p0i);
		modp_iNTT2_ext(Gt + u, llen, igm, logn, p, p0i);

		/*
		 * Also save ft and gt (only up to size slen).
		 */
		if (u < slen) {
			modp_iNTT2(fx, igm, logn, p, p0i);
			modp_iNTT2(gx, igm, logn, p, p0i);
			for (v = 0, x = ft + u, y = gt + u;
				v < n; v ++, x += slen, y += slen)
			{
				*x = fx[v];
				*y = gx[v];
			}
		}
	}

	/*
	 * Rebuild f, g, F and G with the CRT. Note that the elements of F
	 * and G are consecutive, and thus can be rebuilt in a single
	 * loop; similarly, the elements of f and g are consecutive.
	 */
	zint_rebuild_CRT(Ft, llen, llen, n << 1, PRIMES2, 1, t1);
	zint_rebuild_CRT(ft, slen, slen, n << 1, PRIMES2, 1, t1);

	/*
	 * Here starts the Babai reduction, specialized for depth = 1.
	 *
	 * Candidates F and G (from Ft and Gt), and base f and g (ft and gt),
	 * are converted to floating point. There is no scaling, and a
	 * single pass is sufficient.
	 */

	/*
	 * Get maximum bit length for ft and gt, and for Ft and Gt.
	 */
	maxbl_f = poly_max_bitlength(ft, slen, slen, logn, 0);
	maxbl_g = poly_max_bitlength(gt, slen, slen, logn, 0);
	maxbl_fg = maxbl_f < maxbl_g ? maxbl_g : maxbl_f;

	maxbl_F = poly_max_bitlength(Ft, llen, llen, logn, 0);
	maxbl_G = poly_max_bitlength(Gt, llen, llen, logn, 0);
	maxbl_FG = maxbl_F < maxbl_G ? maxbl_G : maxbl_F;

	if (maxbl_fg > 53 || maxbl_FG > 53) {
		return 0;
	}

	/*
	 * Convert F and G into floating point (rt1 and rt2).
	 */
	rt1 = align_fpr(fk->tmp, gt + slen * n);
	rt2 = rt1 + n;
	poly_big_to_fp(rt1, Ft, llen, llen, logn, 0, maxbl_FG, 0);
	poly_big_to_fp(rt2, Gt, llen, llen, logn, 0, maxbl_FG, 0);

	/*
	 * Integer representation of F and G is no longer needed, we
	 * can remove it.
	 */
	memmove(fk->tmp, ft, 2 * slen * n * sizeof *ft);
	ft = fk->tmp;
	gt = ft + slen * n;
	rt3 = align_fpr(fk->tmp, gt + slen * n);
	memmove(rt3, rt1, 2 * n * sizeof *rt1);
	rt1 = rt3;
	rt2 = rt1 + n;
	rt3 = rt2 + n;
	rt4 = rt3 + n;

	/*
	 * Convert f and g into floating point (rt3 and rt4).
	 */
	poly_big_to_fp(rt3, ft, slen, slen, logn, 0, maxbl_fg, 0);
	poly_big_to_fp(rt4, gt, slen, slen, logn, 0, maxbl_fg, 0);

	/*
	 * Remove unneeded ft and gt.
	 */
	memmove(fk->tmp, rt1, 4 * n * sizeof *rt1);
	rt1 = (fpr *)fk->tmp;
	rt2 = rt1 + n;
	rt3 = rt2 + n;
	rt4 = rt3 + n;

	/*
	 * We now have:
	 *   rt1 = F
	 *   rt2 = G
	 *   rt3 = f
	 *   rt4 = g
	 * in that order in RAM. We convert all of them to FFT.
	 */
	falcon_FFT(rt1, logn);
	falcon_FFT(rt2, logn);
	falcon_FFT(rt3, logn);
	falcon_FFT(rt4, logn);

	/*
	 * Compute:
	 *   rt5 = F*adj(f) + G*adj(g)
	 *   rt6 = 1 / (f*adj(f) + g*adj(g))
	 * (Note that rt6 is half-length.)
	 */
	rt5 = rt4 + n;
	rt6 = rt5 + n;
	falcon_poly_add_muladj_fft(rt5, rt1, rt2, rt3, rt4, logn);
	falcon_poly_invnorm2_fft(rt6, rt3, rt4, logn);

	/*
	 * Compute:
	 *   rt5 = (F*adj(f)+G*adj(g)) / (f*adj(f)+g*adj(g))
	 */
	falcon_poly_mul_autoadj_fft(rt5, rt6, logn);

	/*
	 * Compute k as the rounded version of rt5.
	 */
	falcon_iFFT(rt5, logn);
	for (u = 0; u < n; u ++) {
		rt5[u] = fpr_of(fpr_rint(rt5[u]));
	}
	falcon_FFT(rt5, logn);

	/*
	 * Subtract k*f from F, and k*g from G.
	 */
	falcon_poly_mul_fft(rt3, rt5, logn);
	falcon_poly_mul_fft(rt4, rt5, logn);
	falcon_poly_sub_fft(rt1, rt3, logn);
	falcon_poly_sub_fft(rt2, rt4, logn);
	falcon_iFFT(rt1, logn);
	falcon_iFFT(rt2, logn);

	/*
	 * Convert back F and G to integers, and return.
	 */
	Ft = fk->tmp;
	Gt = Ft + n;
	rt3 = align_fpr(fk->tmp, Gt + n);
	memmove(rt3, rt1, 2 * n * sizeof *rt1);
	rt1 = rt3;
	rt2 = rt1 + n;
	for (u = 0; u < n; u ++) {
		Ft[u] = (uint32_t)fpr_rint(rt1[u]);
		Gt[u] = (uint32_t)fpr_rint(rt2[u]);
	}

	return 1;
}

/*
 * Solving the NTRU equation, top level. Upon entry, the F and G
 * from the previous level should be in the fk->tmp array.
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_binary_depth0(falcon_keygen *fk,
	const int16_t *f, const int16_t *g)
{
	unsigned logn;
	size_t n, hn, u;
	uint32_t p, p0i, R2;
	uint32_t *Fp, *Gp, *t1, *t2, *t3, *t4, *t5;
	uint32_t *gm, *igm, *ft, *gt;
	fpr *rt2, *rt3;

	logn = fk->logn;
	n = (size_t)1 << logn;
	hn = n >> 1;

	/*
	 * Equations are:
	 *
	 *   f' = f0^2 - X^2*f1^2
	 *   g' = g0^2 - X^2*g1^2
	 *   F' and G' are a solution to f'G' - g'F' = q (from deeper levels)
	 *   F = F'*(g0 - X*g1)
	 *   G = G'*(f0 - X*f1)
	 *
	 * f0, f1, g0, g1, f', g', F' and G' are all "compressed" to
	 * degree N/2 (their odd-indexed coefficients are all zero).
	 *
	 * Everything should fit in 31-bit integers, hence we can just use
	 * the first small prime p = 2147473409.
	 */
	p = PRIMES2[0].p;
	p0i = modp_ninv31(p);
	R2 = modp_R2(p, p0i);

	Fp = fk->tmp;
	Gp = Fp + hn;
	ft = Gp + hn;
	gt = ft + n;
	gm = gt + n;
	igm = gm + n;

	modp_mkgm2(gm, igm, logn, PRIMES2[0].g, p, p0i);

	/*
	 * Convert F' anf G' in NTT representation.
	 */
	for (u = 0; u < hn; u ++) {
		Fp[u] = modp_set(zint_one_to_plain(Fp + u), p);
		Gp[u] = modp_set(zint_one_to_plain(Gp + u), p);
	}
	modp_NTT2(Fp, gm, logn - 1, p, p0i);
	modp_NTT2(Gp, gm, logn - 1, p, p0i);

	/*
	 * Load f and g and convert them to NTT representation.
	 */
	for (u = 0; u < n; u ++) {
		ft[u] = modp_set(f[u], p);
		gt[u] = modp_set(g[u], p);
	}
	modp_NTT2(ft, gm, logn, p, p0i);
	modp_NTT2(gt, gm, logn, p, p0i);

	/*
	 * Build the unreduced F,G in ft and gt.
	 */
	for (u = 0; u < n; u += 2) {
		uint32_t ftA, ftB, gtA, gtB;
		uint32_t mFp, mGp;

		ftA = ft[u + 0];
		ftB = ft[u + 1];
		gtA = gt[u + 0];
		gtB = gt[u + 1];
		mFp = modp_montymul(Fp[u >> 1], R2, p, p0i);
		mGp = modp_montymul(Gp[u >> 1], R2, p, p0i);
		ft[u + 0] = modp_montymul(gtB, mFp, p, p0i);
		ft[u + 1] = modp_montymul(gtA, mFp, p, p0i);
		gt[u + 0] = modp_montymul(ftB, mGp, p, p0i);
		gt[u + 1] = modp_montymul(ftA, mGp, p, p0i);
	}
	modp_iNTT2(ft, igm, logn, p, p0i);
	modp_iNTT2(gt, igm, logn, p, p0i);

	Gp = Fp + n;
	t1 = Gp + n;
	memmove(Fp, ft, 2 * n * sizeof *ft);

	/*
	 * We now need to apply the Babai reduction. At that point,
	 * we have F and G in two n-word arrays.
	 *
	 * We can compute F*adj(f)+G*adj(g) and f*adj(f)+g*adj(g)
	 * modulo p, using the NTT. We still move memory around in
	 * order to save RAM.
	 */
	t2 = t1 + n;
	t3 = t2 + n;
	t4 = t3 + n;
	t5 = t4 + n;

	/*
	 * Compute the NTT tables in t1 and t2. We do not keep t2
	 * (we'll recompute it later on).
	 */
	modp_mkgm2(t1, t2, logn, PRIMES2[0].g, p, p0i);

	/*
	 * Convert F and G to NTT.
	 */
	modp_NTT2(Fp, t1, logn, p, p0i);
	modp_NTT2(Gp, t1, logn, p, p0i);

	/*
	 * Load f and adj(f) in t4 and t5, and convert them to NTT
	 * representation.
	 */
	t4[0] = t5[0] = modp_set(f[0], p);
	for (u = 1; u < n; u ++) {
		t4[u] = modp_set(f[u], p);
		t5[n - u] = modp_set(-f[u], p);
	}
	modp_NTT2(t4, t1, logn, p, p0i);
	modp_NTT2(t5, t1, logn, p, p0i);

	/*
	 * Compute F*adj(f) in t2, and f*adj(f) in t3.
	 */
	for (u = 0; u < n; u ++) {
		uint32_t w;

		w = modp_montymul(t5[u], R2, p, p0i);
		t2[u] = modp_montymul(w, Fp[u], p, p0i);
		t3[u] = modp_montymul(w, t4[u], p, p0i);
	}

	/*
	 * Load g and adj(g) in t4 and t5, and convert them to NTT
	 * representation.
	 */
	t4[0] = t5[0] = modp_set(g[0], p);
	for (u = 1; u < n; u ++) {
		t4[u] = modp_set(g[u], p);
		t5[n - u] = modp_set(-g[u], p);
	}
	modp_NTT2(t4, t1, logn, p, p0i);
	modp_NTT2(t5, t1, logn, p, p0i);

	/*
	 * Add G*adj(g) to t2, and g*adj(g) to t3.
	 */
	for (u = 0; u < n; u ++) {
		uint32_t w;

		w = modp_montymul(t5[u], R2, p, p0i);
		t2[u] = modp_add(t2[u],
			modp_montymul(w, Gp[u], p, p0i), p);
		t3[u] = modp_add(t3[u],
			modp_montymul(w, t4[u], p, p0i), p);
	}

	/*
	 * Convert back t2 and t3 to normal representation (normalized
	 * around 0), and then
	 * move them to t1 and t2. We first need to recompute the
	 * inverse table for NTT.
	 */
	modp_mkgm2(t1, t4, logn, PRIMES2[0].g, p, p0i);
	modp_iNTT2(t2, t4, logn, p, p0i);
	modp_iNTT2(t3, t4, logn, p, p0i);
	for (u = 0; u < n; u ++) {
		t1[u] = (uint32_t)modp_norm(t2[u], p);
		t2[u] = (uint32_t)modp_norm(t3[u], p);
	}

	/*
	 * At that point, array contents are:
	 *
	 *   F (NTT representation) (Fp)
	 *   G (NTT representation) (Gp)
	 *   F*adj(f)+G*adj(g) (t1)
	 *   f*adj(f)+g*adj(g) (t2)
	 *
	 * We want to divide t1 by t2. The result is not integral; it
	 * must be rounded. We thus need to use the FFT.
	 */

	/*
	 * Get f*adj(f)+g*adj(g) in FFT representation. Since this
	 * polynomial is auto-adjoint, all its coordinates in FFT
	 * representation are actually real, so we can truncate off
	 * the imaginary parts.
	 */
	rt3 = align_fpr(fk->tmp, t3);
	for (u = 0; u < n; u ++) {
		rt3[u] = fpr_of(((int32_t *)t2)[u]);
	}
	falcon_FFT(rt3, logn);
	rt2 = align_fpr(fk->tmp, t2);
	memmove(rt2, rt3, hn * sizeof *rt3);

	/*
	 * Convert F*adj(f)+G*adj(g) in FFT representation.
	 */
	rt3 = rt2 + hn;
	for (u = 0; u < n; u ++) {
		rt3[u] = fpr_of(((int32_t *)t1)[u]);
	}
	falcon_FFT(rt3, logn);

	/*
	 * Compute (F*adj(f)+G*adj(g))/(f*adj(f)+g*adj(g)) and get
	 * its rounded normal representation in t1.
	 */
	falcon_poly_div_autoadj_fft(rt3, rt2, logn);
	falcon_iFFT(rt3, logn);
	for (u = 0; u < n; u ++) {
		t1[u] = modp_set((int32_t)fpr_rint(rt3[u]), p);
	}

	/*
	 * RAM contents are now:
	 *
	 *   F (NTT representation) (Fp)
	 *   G (NTT representation) (Gp)
	 *   k (t1)
	 *
	 * We want to compute F-k*f, and G-k*g.
	 */
	t2 = t1 + n;
	t3 = t2 + n;
	t4 = t3 + n;
	t5 = t4 + n;
	modp_mkgm2(t2, t3, logn, PRIMES2[0].g, p, p0i);
	for (u = 0; u < n; u ++) {
		t4[u] = modp_set(f[u], p);
		t5[u] = modp_set(g[u], p);
	}
	modp_NTT2(t1, t2, logn, p, p0i);
	modp_NTT2(t4, t2, logn, p, p0i);
	modp_NTT2(t5, t2, logn, p, p0i);
	for (u = 0; u < n; u ++) {
		uint32_t kw;

		kw = modp_montymul(t1[u], R2, p, p0i);
		Fp[u] = modp_sub(Fp[u],
			modp_montymul(kw, t4[u], p, p0i), p);
		Gp[u] = modp_sub(Gp[u],
			modp_montymul(kw, t5[u], p, p0i), p);
	}
	modp_iNTT2(Fp, t3, logn, p, p0i);
	modp_iNTT2(Gp, t3, logn, p, p0i);
	for (u = 0; u < n; u ++) {
		Fp[u] = (uint32_t)modp_norm(Fp[u], p);
		Gp[u] = (uint32_t)modp_norm(Gp[u], p);
	}

	return 1;
}

/*
 * Solving the NTRU equation, top level, ternary case. Upon entry, the
 * F and G from the previous level should be in the fk->tmp array.
 *
 * Returned value: 1 on success, 0 on error.
 */
static int
solve_NTRU_ternary_depth0(falcon_keygen *fk,
	const int16_t *f, const int16_t *g)
{
	unsigned logn;
	size_t n, tn, hn, sn, u, v;
	uint32_t *Fp, *Gp, *t1;
	fpr *rt1, *rt2, *rt3, *rt4, *rt5;

	logn = fk->logn;
	n = (size_t)3 << (logn - 1);
	tn = (size_t)1 << (logn - 1);
	hn = n >> 1;
	sn = tn >> 1;

	/*
	 * The F' and G' from the upper level should fit on one word per
	 * value, since MAX_BL_SMALL3[1] == 1. However, intermediate
	 * values won't fit, and we will need to use floating point.
	 */
	Fp = fk->tmp;
	Gp = Fp + tn;
	t1 = Gp + tn;

	/*
	 * Load f and g into floating-point registers, and compute
	 * 1/(f*adj(f)+g*adj(g)) (in FFT representation).
	 */
	rt1 = align_fpr(fk->tmp, t1);
	rt2 = rt1 + n;
	rt3 = rt2 + n;
	poly_small_to_fp(rt1, f, logn, 1);
	poly_small_to_fp(rt2, g, logn, 1);
	falcon_FFT3(rt1, logn, 1);
	falcon_FFT3(rt2, logn, 1);
	falcon_poly_invnorm2_fft3(rt3, rt1, rt2, logn, 1);

	/*
	 * We discard f and g for now.
	 */
	memmove(rt1, rt3, hn * sizeof *rt3);
	rt5 = rt1;

	/*
	 * We load F' and G' into rt1 and rt2 (in FFT representation).
	 */
	rt1 = rt5 + hn;
	rt2 = rt1 + tn;
	for (u = 0; u < tn; u ++) {
		rt1[u] = fpr_of(zint_one_to_plain(Fp + u));
		rt2[u] = fpr_of(zint_one_to_plain(Gp + u));
	}
	falcon_FFT3(rt1, logn - 1, 0);
	falcon_FFT3(rt2, logn - 1, 0);

	/*
	 * We don't need the non-fp F' and G' now.
	 */
	memmove(fk->tmp, rt5, (hn + tn * 2) * sizeof(*rt1));
	rt5 = (fpr *)fk->tmp;
	rt1 = rt5 + hn;
	rt2 = rt1 + tn;

	/*
	 * We have 1/(f*adj(f)+g*adj(g)), F' and G' in RAM, in that
	 * order (rt5, rt1 and rt2, with hn, tn and tn slots, respectively).
	 *
	 * Load f and g in rt3 and rt4, in FFT representation.
	 */
	rt3 = rt2 + tn;
	rt4 = rt3 + n;
	poly_small_to_fp(rt3, f, logn, 1);
	poly_small_to_fp(rt4, g, logn, 1);
	falcon_FFT3(rt3, logn, 1);
	falcon_FFT3(rt4, logn, 1);

	/*
	 * Build candidate F and G in rt3 and rt4.
	 */
	for (u = 0, v = 0; u < hn; u += 3, v ++) {

#define FPC_MUL(d_re, d_im, a_re, a_im, b_re, b_im)   do { \
		fpr fpct_a_re, fpct_a_im; \
		fpr fpct_b_re, fpct_b_im; \
		fpr fpct_d_re, fpct_d_im; \
		fpct_a_re = (a_re); \
		fpct_a_im = (a_im); \
		fpct_b_re = (b_re); \
		fpct_b_im = (b_im); \
		fpct_d_re = fpr_sub( \
			fpr_mul(fpct_a_re, fpct_b_re), \
			fpr_mul(fpct_a_im, fpct_b_im)); \
		fpct_d_im = fpr_add( \
			fpr_mul(fpct_a_re, fpct_b_im), \
			fpr_mul(fpct_a_im, fpct_b_re)); \
		(d_re) = fpct_d_re; \
		(d_im) = fpct_d_im; \
	} while (0)

		fpr Fre, Fim, Gre, Gim;
		fpr f1re, f1im, f2re, f2im, f3re, f3im;
		fpr g1re, g1im, g2re, g2im, g3re, g3im;
		fpr re, im;

		/*
		 * Let x1, x2 and x3 be three roots of phi that share the
		 * same cube x1^3. Then we have:
		 *
		 *   G(x1) = f(x2)*f(x3)*G'(x1^3)
		 *   G(x2) = f(x3)*f(x1)*G'(x1^3)
		 *   G(x3) = f(x1)*f(x2)*G'(x1^3)
		 *
		 * f(x1), f(x2) and f(x3) are consecutive in our FFT
		 * representation.
		 */
		Fre = rt1[v];
		Fim = rt1[v + sn];
		Gre = rt2[v];
		Gim = rt2[v + sn];
		f1re = rt3[u + 0];
		f1im = rt3[u + 0 + hn];
		f2re = rt3[u + 1];
		f2im = rt3[u + 1 + hn];
		f3re = rt3[u + 2];
		f3im = rt3[u + 2 + hn];
		g1re = rt4[u + 0];
		g1im = rt4[u + 0 + hn];
		g2re = rt4[u + 1];
		g2im = rt4[u + 1 + hn];
		g3re = rt4[u + 2];
		g3im = rt4[u + 2 + hn];

		FPC_MUL(re, im, f2re, f2im, f3re, f3im);
		FPC_MUL(rt4[u + 0], rt4[u + 0 + hn], re, im, Gre, Gim);
		FPC_MUL(re, im, f3re, f3im, f1re, f1im);
		FPC_MUL(rt4[u + 1], rt4[u + 1 + hn], re, im, Gre, Gim);
		FPC_MUL(re, im, f1re, f1im, f2re, f2im);
		FPC_MUL(rt4[u + 2], rt4[u + 2 + hn], re, im, Gre, Gim);
		FPC_MUL(re, im, g2re, g2im, g3re, g3im);
		FPC_MUL(rt3[u + 0], rt3[u + 0 + hn], re, im, Fre, Fim);
		FPC_MUL(re, im, g3re, g3im, g1re, g1im);
		FPC_MUL(rt3[u + 1], rt3[u + 1 + hn], re, im, Fre, Fim);
		FPC_MUL(re, im, g1re, g1im, g2re, g2im);
		FPC_MUL(rt3[u + 2], rt3[u + 2 + hn], re, im, Fre, Fim);

#undef FPC_MUL
	}

	/*
	 * We can discard F' and G' now. We rename F and G as rt1 and
	 * rt2, respectively. They are in FFT representation.
	 */
	memmove(rt1, rt3, 2 * n * sizeof *rt3);
	rt2 = rt1 + n;
	rt3 = rt2 + n;
	rt4 = rt3 + n;

	/*
	 * Memory contents:
	 *   rt5   hn slots   1/(f*adj(f)+g*adj(g))
	 *   rt1   n slots    F
	 *   rt2   n slots    G
	 *   rt3   n slots    free
	 *   rt4   n slots    free
	 *
	 * We load f and g into rt3 and rt4 (FFT).
	 */
	poly_small_to_fp(rt3, f, logn, 1);
	poly_small_to_fp(rt4, g, logn, 1);
	falcon_FFT3(rt3, logn, 1);
	falcon_FFT3(rt4, logn, 1);

	/*
	 * Compute (F*adj(f)+G*adj(g))/(f*adj(f)+g*adj(g)) in rt3.
	 */
	falcon_poly_adj_fft3(rt3, logn, 1);
	falcon_poly_adj_fft3(rt4, logn, 1);
	falcon_poly_mul_fft3(rt3, rt1, logn, 1);
	falcon_poly_mul_fft3(rt4, rt2, logn, 1);
	falcon_poly_add_fft3(rt3, rt4, logn, 1);
	falcon_poly_mul_autoadj_fft3(rt3, rt5, logn, 1);

	/*
	 * Round the contents of rt3 to get k, converted back into FFT.
	 */
	falcon_iFFT3(rt3, logn, 1);
	for (u = 0; u < n; u ++) {
		rt3[u] = fpr_of(fpr_rint(rt3[u]));
	}
	falcon_FFT3(rt3, logn, 1);

	/*
	 * Subtract k*f from F, and k*g from G.
	 */
	poly_small_to_fp(rt4, f, logn, 1);
	falcon_FFT3(rt4, logn, 1);
	falcon_poly_mul_fft3(rt4, rt3, logn, 1);
	falcon_poly_sub_fft3(rt1, rt4, logn, 1);
	poly_small_to_fp(rt4, g, logn, 1);
	falcon_FFT3(rt4, logn, 1);
	falcon_poly_mul_fft3(rt4, rt3, logn, 1);
	falcon_poly_sub_fft3(rt2, rt4, logn, 1);

	/*
	 * Convert back the final F and G from FFT.
	 */
	falcon_iFFT3(rt1, logn, 1);
	falcon_iFFT3(rt2, logn, 1);

	Fp = fk->tmp;
	Gp = Fp + n;
	t1 = Gp + n;
	rt5 = align_fpr(fk->tmp, t1);
	memmove(rt5, rt1, 2 * n * sizeof *rt1);
	rt1 = rt5;
	rt2 = rt1 + n;
	for (u = 0; u < n; u ++) {
		Fp[u] = (uint32_t)fpr_rint(rt1[u]);
		Gp[u] = (uint32_t)fpr_rint(rt2[u]);
	}

	return 1;
}

/*
 * Solve the NTRU equation. Returned value is 1 on success, 0 on error.
 */
static int
solve_NTRU(falcon_keygen *fk, int16_t *F, int16_t *G,
	const int16_t *f, const int16_t *g)
{
	unsigned logn;
	size_t n, u;
	uint32_t *ft, *gt, *Ft, *Gt, *gm;
	uint32_t p, p0i, r;
	const small_prime *primes;

	logn = fk->logn;
	n = MKN(logn, fk->ternary);

	if (!solve_NTRU_deepest(fk, f, g)) {
		return 0;
	}

	/*
	 * For logn <= 2, we need to use solve_NTRU_intermediate()
	 * directly, because coefficients are a bit too large and
	 * do not fit the hypotheses in solve_NTRU_binary_depth0()
	 * or solve_NTRU_ternary_depth0().
	 */
	if (logn <= 2) {
		unsigned depth;

		depth = logn;
		while (depth -- > 0) {
			if (!solve_NTRU_intermediate(fk, f, g, depth)) {
				return 0;
			}
		}
	} else {
		unsigned depth;

		depth = logn;
		if (fk->ternary) {
			while (depth -- > 1) {
				if (!solve_NTRU_intermediate(fk, f, g, depth)) {
					return 0;
				}
			}
			if (!solve_NTRU_ternary_depth0(fk, f, g)) {
				return 0;
			}
		} else {
			while (depth -- > 2) {
				if (!solve_NTRU_intermediate(fk, f, g, depth)) {
					return 0;
				}
			}
			if (!solve_NTRU_binary_depth1(fk, f, g)) {
				return 0;
			}
			if (!solve_NTRU_binary_depth0(fk, f, g)) {
				return 0;
			}
		}
	}

	/*
	 * Final F and G are in fk->tmp, one word per coefficient
	 * (signed value over 31 bits).
	 */
	if (!poly_big_to_small(F, fk->tmp, logn, fk->ternary)
		|| !poly_big_to_small(G, fk->tmp + n, logn, fk->ternary))
	{
		return 0;
	}

	/*
	 * Verify that the NTRU equation is fulfilled. Since all elements
	 * have short lengths, verifying modulo a small prime p works, and
	 * allows using the NTT.
	 */
	ft = fk->tmp;
	gt = ft + n;
	Ft = gt + n;
	Gt = Ft + n;
	gm = Gt + n;

	primes = fk->ternary ? PRIMES3 : PRIMES2;
	p = primes[0].p;
	p0i = modp_ninv31(p);
	if (fk->ternary) {
		modp_mkgm3(gm, ft, logn, 1, primes[0].g, p, p0i);
	} else {
		modp_mkgm2(gm, ft, logn, primes[0].g, p, p0i);
	}
	for (u = 0; u < n; u ++) {
		ft[u] = modp_set(f[u], p);
		gt[u] = modp_set(g[u], p);
		Ft[u] = modp_set(F[u], p);
		Gt[u] = modp_set(G[u], p);
	}
	if (fk->ternary) {
		modp_NTT3(ft, gm, logn, 1, p, p0i);
		modp_NTT3(gt, gm, logn, 1, p, p0i);
		modp_NTT3(Ft, gm, logn, 1, p, p0i);
		modp_NTT3(Gt, gm, logn, 1, p, p0i);
		r = modp_montymul(18433, 1, p, p0i);
	} else {
		modp_NTT2(ft, gm, logn, p, p0i);
		modp_NTT2(gt, gm, logn, p, p0i);
		modp_NTT2(Ft, gm, logn, p, p0i);
		modp_NTT2(Gt, gm, logn, p, p0i);
		r = modp_montymul(12289, 1, p, p0i);
	}
	for (u = 0; u < n; u ++) {
		uint32_t z;

		z = modp_sub(modp_montymul(ft[u], Gt[u], p, p0i),
			modp_montymul(gt[u], Ft[u], p, p0i), p);
		if (z != r) {
			return 0;
		}
	}

	return 1;
}

/*
 * Generate a random polynomial with a Gaussian distribution. This function
 * also makes sure that the resultant of the polynomial with phi is odd.
 *
 * This function is only for the binary case. 
 */
static void
poly_small_mkgauss(falcon_keygen *fk, int16_t *f, unsigned logn)
{
	size_t n, u;
	unsigned mod2;

	n = MKN(logn, 0);
	mod2 = 0;
	for (u = 0; u < n; u ++) {
		int s;

	restart:
		s = mkgauss(fk, logn);
		if (u == n - 1) {
			if ((mod2 ^ (unsigned)(s & 1)) == 0) {
				goto restart;
			}
		} else {
			mod2 ^= (unsigned)(s & 1);
		}
		f[u] = s;
	}
}

/* see falcon.h */
int
falcon_keygen_make(falcon_keygen *fk, int comp,
	void *privkey, size_t *privkey_len,
	void *pubkey, size_t *pubkey_len)
{
	/*
	 * Algorithm is the following:
	 *
	 *  - Generate f and g with the Gaussian distribution.
	 *
	 *  - If either Res(f,phi) or Res(g,phi) is even, try again.
	 *
	 *  - If ||(f,g)|| is too large, try again.
	 *
	 *  - If ||B~_{f,g}|| is too large, try again.
	 *
	 *  - If f is not invertible mod phi mod q, try again.
	 *
	 *  - Compute h = g/f mod phi mod q.
	 *
	 *  - Solve the NTRU equation fG - gF = q; if the solving fails,
	 *    try again. Usual failure condition is when Res(f,phi)
	 *    and Res(g,phi) are not prime to each other.
	 */
	unsigned logn, ter;
	size_t n, u;
	int16_t f[1024], g[1024], F[1024], G[1024];
	uint16_t h[1024];
	size_t klen, skoff;
	unsigned char *skbuf;
	int16_t *ske[4];
	int i;

	logn = fk->logn;
	ter = fk->ternary;
	n = MKN(logn, ter);

	/*
	 * Make sure the RNG is properly seeded and ready to output bits.
	 */
	if (!rng_ready(fk)) {
		return 0;
	}

	/*
	 * We need to generate f and g randomly, until we find values
	 * such that the norm of (g,-f), and of the orthogonalized
	 * vector, are satisfying. The orthogonalized vector is:
	 *   (q*adj(f)/(f*adj(f)+g*adj(g)), q*adj(g)/(f*adj(f)+g*adj(g)))
	 * (it is actually the (N+1)-th row of the Gram-Schmidt basis).
	 *
	 * In the binary case, coefficients of f and g are generated
	 * independently of each other, with a discrete Gaussian
	 * distribution of standard deviation 1.17*sqrt(q/(2*N)). Then,
	 * the two vectors have expected norm 1.17*sqrt(q), which is
	 * also our acceptance bound: we require both vectors to be no
	 * larger than that (this will be satisfied about 1/4th of the
	 * time, thus we expect sampling new (f,g) about 4 times for that
	 * step).
	 *
	 * In the ternary case, we need a spheroid in the FFT representation,
	 * thus we use a rounded Gaussian in that representation. Standard
	 * deviation is then sigma = sqrt(q/sqrt(8)). The vector norms
	 * are computed over the FFT representation, with common bound
	 * 2*sqrt(N)*sigma.
	 *
	 * In both cases, we require that Res(f,phi) and Res(g,phi) are
	 * both odd (the NTRU equation solver requires it).
	 */
	for (;;) {
		if (ter) {
			fpr *rt1, *rt2, *rt3;
			size_t hn;
			fpr sigma, norm, bound;

			hn = n >> 1;

			/*
			 * Generate f and g in FFT representation (in rt1
			 * and rt2, respectively); we must then convert
			 * them back to non-FFT to apply rounding.
			 */
			rt1 = (fpr *)fk->tmp;
			rt2 = rt1 + n;
			rt3 = rt2 + n;
			sigma = fpr_sqrt(fpr_div(fpr_of(18433),
				fpr_sqrt(fpr_of(8))));
			for (u = 0; u < hn; u ++) {
				uint32_t a, b;
				uint64_t c;

				c = get_rng_u64(&fk->rng);
				a = (uint32_t)c;
				b = (uint32_t)(c >> 32);
				fpr_gauss(&rt1[u], &rt1[u + hn], sigma, a, b);
				c = get_rng_u64(&fk->rng);
				a = (uint32_t)c;
				b = (uint32_t)(c >> 32);
				fpr_gauss(&rt2[u], &rt2[u + hn], sigma, a, b);
			}
			falcon_iFFT3(rt1, logn, 1);
			falcon_iFFT3(rt2, logn, 1);
			for (u = 0; u < n; u ++) {
				f[u] = (int16_t)fpr_rint(rt1[u]);
				g[u] = (int16_t)fpr_rint(rt2[u]);
			}

			if (mod2_res_ternary(f, logn) == 0) {
				continue;
			}
			if (mod2_res_ternary(g, logn) == 0) {
				continue;
			}

			/*
			 * Convert back to FFT to compute norms. Bound on
			 * the squared norm of (g,-f) (in FFT representation)
			 * is 4*N*q/sqrt(8).
			 *
			 * Note that our FFT contains only half the values,
			 * so we must double the sum.
			 */
			bound = fpr_div(fpr_of(73732L * (long)n),
				fpr_sqrt(fpr_of(8)));

			poly_small_to_fp(rt1, f, logn, 1);
			poly_small_to_fp(rt2, g, logn, 1);
			falcon_FFT3(rt1, logn, 1);
			falcon_FFT3(rt2, logn, 1);
			norm = fpr_of(0);
			for (u = 0; u < n; u ++) {
				norm = fpr_add(norm, fpr_sqr(rt1[u]));
				norm = fpr_add(norm, fpr_sqr(rt2[u]));
			}
			norm = fpr_double(norm);

			if (!fpr_lt(norm, bound)) {
				continue;
			}

			/*
			 * Orthogonalized vector.
			 */
			falcon_poly_invnorm2_fft3(rt3, rt1, rt2, logn, 1);
			falcon_poly_adj_fft3(rt1, logn, 1);
			falcon_poly_adj_fft3(rt2, logn, 1);
			falcon_poly_mulconst_fft3(rt1, fpr_of(18433), logn, 1);
			falcon_poly_mulconst_fft3(rt2, fpr_of(18433), logn, 1);
			falcon_poly_mul_autoadj_fft3(rt1, rt3, logn, 1);
			falcon_poly_mul_autoadj_fft3(rt2, rt3, logn, 1);
			norm = fpr_of(0);
			for (u = 0; u < n; u ++) {
				norm = fpr_add(norm, fpr_sqr(rt1[u]));
				norm = fpr_add(norm, fpr_sqr(rt2[u]));
			}
			norm = fpr_double(norm);

			if (!fpr_lt(norm, bound)) {
				continue;
			}
		} else {
			fpr *rt1, *rt2, *rt3;
			fpr bnorm;
			uint32_t normf, normg, norm;

			/*
			 * The poly_small_mkgauss() function makes sure
			 * that the sum of coefficients is 1 modulo 2
			 * (i.e. the resultant of the polynomial with phi
			 * will be odd).
			 */
			poly_small_mkgauss(fk, f, logn);
			poly_small_mkgauss(fk, g, logn);

			/*
			 * Bound is 1.17*sqrt(q). We compute the squared
			 * norms. With q = 12289, the squared bound is:
			 *   (1.17^2)* 12289 = 16822.4121
			 * Since f and g are integral, the squared norm
			 * of (g,-f) is an integer.
			 */
			normf = poly_small_sqnorm(f, logn, ter);
			normg = poly_small_sqnorm(g, logn, ter);
			norm = (normf + normg) | -((normf | normg) >> 31);
			if (norm >= 16823) {
				continue;
			}

			/*
			 * We compute the orthogonalized vector norm.
			 */
			rt1 = (fpr *)fk->tmp;
			rt2 = rt1 + n;
			rt3 = rt2 + n;
			poly_small_to_fp(rt1, f, logn, 0);
			poly_small_to_fp(rt2, g, logn, 0);
			falcon_FFT(rt1, logn);
			falcon_FFT(rt2, logn);
			falcon_poly_invnorm2_fft(rt3, rt1, rt2, logn);
			falcon_poly_adj_fft(rt1, logn);
			falcon_poly_adj_fft(rt2, logn);
			falcon_poly_mulconst_fft(rt1, fpr_of(12289), logn);
			falcon_poly_mulconst_fft(rt2, fpr_of(12289), logn);
			falcon_poly_mul_autoadj_fft(rt1, rt3, logn);
			falcon_poly_mul_autoadj_fft(rt2, rt3, logn);
			falcon_iFFT(rt1, logn);
			falcon_iFFT(rt2, logn);
			bnorm = fpr_of(0);
			for (u = 0; u < n; u ++) {
				bnorm = fpr_add(bnorm, fpr_sqr(rt1[u]));
				bnorm = fpr_add(bnorm, fpr_sqr(rt2[u]));
			}
			if (!fpr_lt(bnorm, fpr_div(
				fpr_of(168224121), fpr_of(10000))))
			{
				continue;
			}
		}

		/*
		 * Compute public key h = g/f mod X^N+1 mod q. If this
		 * fails, we must restart.
		 */
		if (!falcon_compute_public(h, f, g, logn, ter)) {
			continue;
		}

		/*
		 * Solve the NTRU equation to get F and G.
		 */
		if (!solve_NTRU(fk, F, G, f, g)) {
			continue;
		}

		/*
		 * Key pair is generated.
		 */
		break;
	}

	/*
	 * Encode private key.
	 */
	klen = *privkey_len;
	skbuf = privkey;
	if (klen < 1) {
		return 0;
	}
	skbuf[0] = (ter << 7) + (comp << 5) + logn;
	skoff = 1;
	ske[0] = f;
	ske[1] = g;
	ske[2] = F;
	ske[3] = G;
	for (i = 0; i < 4; i ++) {
		size_t elen;

		elen = falcon_encode_small(skbuf + skoff, klen - skoff,
			comp, ter ? 18433 : 12289, ske[i], logn);
		if (elen == 0) {
			return 0;
		}
		skoff += elen;
	}
	*privkey_len = skoff;

	/*
	 * Encode public key.
	 */
	klen = *pubkey_len;
	if (klen < 1) {
		return 0;
	}
	((unsigned char *)pubkey)[0] = (ter << 7) + logn;
	if (ter) {
		klen = falcon_encode_18433(
			(unsigned char *)pubkey + 1, klen - 1, h, logn);
	} else {
		klen = falcon_encode_12289(
			(unsigned char *)pubkey + 1, klen - 1, h, logn);
	}
	if (klen == 0) {
		return 0;
	}
	*pubkey_len = klen + 1;

	/*
	 * Success!
	 */
	return 1;
}
